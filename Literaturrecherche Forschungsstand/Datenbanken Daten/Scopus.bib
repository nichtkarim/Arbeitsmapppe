% This file was created with Citavi 7.0.9.1

@proceedings{Ahi.2025,
 abstract = {As the amount of data continues to grow, with images becoming larger in terms of bytes and details across scientific, photography, industrial, medical, gaming, augmented reality (AR), virtual reality (VR), autonomous systems, and digital content creation domains, and as generative AI (Gen AI) and large language models (LLMs) gain popularity, the computational demands on modern systems have reached unprecedented levels. In this work, we introduce optimized, GPU-parallelized image processing algorithms that significantly reduce computation requirements, improving both processing speed and scalability. Additionally, in our work, edge computing plays a critical role in reducing latency and bandwidth consumption, enabling real-time decision-making by processing data at the edge, closer to the source. Scalable cloud architectures further support this approach by providing elastic, high-throughput processing capabilities for data-intensive tasks. Moreover, in many applications such as medical imaging, autonomous vehicle perception, satellite image analysis, high-precision manufacturing, robotics, and real-time anomaly detection, image review by humans is not only error-prone but also time-consuming, often limiting scalability and response times. To address this, we present a human-in-the-loop (HITL) automation framework, coupled with a UX-centric, GUI-based system, that reduces human workload by 82{\%}, making high-throughput image review feasible even at the scale required for cutting-edge applications like medical imaging, digital marketplaces, platform integrity, semiconductor manufacturing, autonomous systems, precision agriculture, and industrial defect detection. This framework leverages GPU-accelerated computer vision, edge computing, and scalable cloud infrastructure to optimize data processing across the entire cycle, from initial capture to real-time analysis and decision-making. To demonstrate this approach, we utilize challenging images characterized by low signal-to-noise ratios (SNR), defects, focus variations, and contrast inconsistencies. For this purpose, we selected a dataset of nanometer-resolution images, including ultra-high-resolution scanning electron microscope (SEM) images. These images, captured at the physical limits of SEM technology, contain nanometer-scale details essential for device performance but are characterized by extreme noise, focus variations, and high pixel density. This makes them ideal for evaluating the limits of real-time, high-precision image processing algorithms. Even though these high-variability images exhibit extremely low SNR, they are critical for lithography process control, defect detection, and optical proximity correction (OPC) modeling in advanced semiconductor manufacturing. Traditional review methods, such as manual inspection and critical dimension (CD)-based modeling, are not only slow and prone to human error but also limited to localized measurements, often missing critical pattern variations that impact device performance. As the industry moves toward contour-based modeling, which requires analyzing entire images to capture edge roughness, line width variation, and pattern fidelity, there is a growing demand for fully automated, GPU-accelerated, cloud-scalable AI-driven solutions capable of processing this highly complex data efficiently. In our work, the use case of nanometer-resolution SEM images provides a compelling demonstration of the framework's capabilities in handling extremely complex data. Additionally, this paper presents a novel GPU-accelerated machine learning (ML) and AI-powered digital image processing framework for automated image and data refinement and defect detection. The system generates high-resolution pattern fidelity and defect maps by leveraging structural similarity with AI-enhanced adaptive reference models. Key features include AI-driven extrema counting, sharpness metrics, noise level evaluation, and line edge roughness (LER) and line width roughness (LWR) analysis. These features are extracted to cluster images into quality-based groups, enabling real-time defect classification through cloud-scalable hierarchical clustering that surpasses CD-based methods in both accuracy and efficiency. A critical limitation of conventional filtering is its reliance on multiple images per process condition (exposure and focus) to identify outliers. This paper addresses this challenge by introducing an AI-powered clustering approach capable of detecting failures, even when only a single image is available per process window condition, eliminating the need for rule-based filtering. This method integrates AI-driven LER and LWR evaluation to ensure robust clustering across varying process conditions, improving both detection accuracy and operational efficiency. To further streamline image and data analysis, the framework includes a GPU-accelerated, edge computing, cloud-integrated graphical user interface (GUI) for real-time, high-performance computing (HPC)-optimized data and image analysis, feature extraction, classification, edge detection, segmentation, data cleaning, measurement, anomaly detection, and defect identification. This solution, integrated into Calibre SEMSuite{\texttrademark}, supports multi-cloud deployment for enhanced scalability, usability, and performance, providing users with a powerful tool for fully automated, AI-driven image classification, making high-throughput image review feasible even at the scale required for cutting-edge applications. By integrating these advanced capabilities, the proposed framework not only addresses the computational challenges of modern AI-driven image processing but also significantly reduces human intervention, paving the way for scalable, real-time AI processing in diverse applications such as medical imaging, autonomous vehicle perception, satellite image analysis, high-precision manufacturing, robotics, and real-time anomaly detection. {\copyright} 2025 SPIE.},
 year = {2025},
 title = {AI-Powered End-to-End Product Lifecycle: UX-Centric Human-in-the-Loop System Boosting Reviewer Productivity by 82{\%} and Accelerating Decision-Making via Real-Time Anomaly Detection and Data Refinement with GPU-Accelerated Computer Vision, Edge Computing, and Scalable Cloud},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007150138&doi=10.1117%2f12.3052252&partnerID=40&md5=febde7180cdc9bd8b9ff8d2acc336a8f},
 keywords = {Cutting;Data refinements;Decisions makings;Defect detection;Edge computing;GPU-accelerated;High-throughput;Human-in-the-loop;Image correlation;Image processing algorithm;Medical imaging;Medical robotics;Mobile edge computing;Photointerpretation;Precision agriculture;Real- time;Real-time anomaly detections;Virtualization},
 volume = {13426},
 publisher = {SPIE},
 editor = {Ahi, K. and Mansour, S. and Wu, S. and Fenger, G. and Ayya, A. S. and Opitz, J. and {Zine El Abidine}, N. and Hatem, H. and Essam, A. and {El Dessouki}, A. and Sriram, S. and Biswas, S. and Bhamidipati, S. and Pereira, M. and Fekry, M.-A. and Fawzi, R. and Samir, H. and Nalakath, M. D. and Mabrouk, O. and Sendelbach, M. J. and Schuch, N. G.},
 doi = {10.1117/12.3052252}
}


@inproceedings{Rasool.,
 abstract = {Large language models (LLMs) enable state-of-the-art semantic capabilities to be added to software systems such as semantic search of unstructured documents and text generation. However, these models are computationally expensive. At scale, the cost of serving thousands of users increases massively affecting also user experience. To address this problem, semantic caches are used to check for answers to similar queries (that may have been phrased differently) without hitting the LLM service. Due to the nature of these semantic cache techniques that rely on query embeddings, there is a high chance of errors impacting user confidence in the system. Adopting semantic cache techniques usually requires testing the effectiveness of a semantic cache (accurate cache hits and misses) which requires a labelled test set of similar queries and responses which is often unavailable. In this paper, we present VaryGen, an approach for using LLMs for test input generation that produces similar questions from unstructured text documents. Our novel approach uses the reasoning capabilities of LLMs to 1) adapt queries to the domain, 2) synthesise subtle variations to queries, and 3) evaluate the synthesised test dataset. We evaluated our approach in the domain of a student question and answer system by qualitatively analysing 100 generated queries and result pairs, and conducting an empirical case study with an open source semantic cache. Our results show that query pairs satisfy human expectations of similarity and our generated data demonstrates failure cases of a semantic cache. Additionally, we also evaluate our approach on Qasper dataset. This work is an important first step into test input generation for semantic applications and presents considerations for practitioners when calibrating a semantic cache. {\copyright} 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
 author = {Rasool, Z. and Barnett, S. and Willie, D. and Kurniawan, S. and Balugo, S. and Thudumu, S. and Abdelrazek, M.},
 title = {LLMS for test input generation for semantic applications},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196548201&doi=10.1145%2f3644815.3644948&partnerID=40&md5=6dd5aaf6d58f72396a4fcb1ee9007b99},
 keywords = {Computational linguistics;Language model;Large Language Model;Natural language processing systems;Open source software;query evaluation;Query processing;question answering;semantic cache;Semantics;Software-systems;State of the art;Statistical tests;test input generation;Test inputs;Unstructured texts},
 pages = {160--165-160--165},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3644815.3644948}
}


@article{Rangaswamy.2025,
 abstract = {The proceedings contain 41 papers. The special focus in this conference is on Human-Computer Interaction Design and Research. The topics include: Fogg Behavioural Model Based Cybersecurity Awareness Framework: An Empirical Analysis; could You Hear That? Identifying Marathi Phrases Suitable for~Aural Transcription Tasks; IDCText: An Application for~Conducting Text Input Research Studies in~Indian Languages; comparative Evaluation of~Speech Interfaces of~Conversational Agents in~Hindi; exploring the~Impact of~Foot-Based Haptic Feedback on~User Experience in~Virtual Reality Navigation; investigating Contextual Factors in~Technology-Based Solutions Designed to~Support Health and~Fitness Routines for~Older Adults: A Systematic Review; Is ChatGPT Ready for~Indian-Language Speakers? Findings From a~Preliminary Mixed Methods Study; using Graph Analysis for~Evaluating Usability of~Software-Based Keyboard for~Password Creation; Spatial Audio Training for Visually Impaired Users Navigation in VR: An Analytical Approach; culturally Relevant Novel Interaction Methods for Immersive Video Streaming Experience in Virtual Reality; allerGuard: An Innovative mHealth Solution for Food Allergy Management in India; visual Feedback Interface for~Audio Communication Over Lossy and~High Delay Networks.},
 author = {Rangaswamy, N. and Sim, G. R. and Borah, P. P.},
 year = {2025},
 title = {15th Indian Conference on Human-Computer Interaction Design and Research, IndiaHCI 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219192908&partnerID=40&md5=36010a409a1f2ba49ac7865856550ed3},
 volume = {2338 CCIS},
 issn = {18650929},
 journal = {Communications in Computer and Information Science}
}


@article{Rangaswamy.2025b,
 abstract = {The proceedings contain 41 papers. The special focus in this conference is on Human-Computer Interaction Design and Research. The topics include: Fogg Behavioural Model Based Cybersecurity Awareness Framework: An Empirical Analysis; could You Hear That? Identifying Marathi Phrases Suitable for~Aural Transcription Tasks; IDCText: An Application for~Conducting Text Input Research Studies in~Indian Languages; comparative Evaluation of~Speech Interfaces of~Conversational Agents in~Hindi; exploring the~Impact of~Foot-Based Haptic Feedback on~User Experience in~Virtual Reality Navigation; investigating Contextual Factors in~Technology-Based Solutions Designed to~Support Health and~Fitness Routines for~Older Adults: A Systematic Review; Is ChatGPT Ready for~Indian-Language Speakers? Findings From a~Preliminary Mixed Methods Study; using Graph Analysis for~Evaluating Usability of~Software-Based Keyboard for~Password Creation; Spatial Audio Training for Visually Impaired Users Navigation in VR: An Analytical Approach; culturally Relevant Novel Interaction Methods for Immersive Video Streaming Experience in Virtual Reality; allerGuard: An Innovative mHealth Solution for Food Allergy Management in India; visual Feedback Interface for~Audio Communication Over Lossy and~High Delay Networks.},
 author = {Rangaswamy, N. and Sim, G. R. and Borah, P. P.},
 year = {2025},
 title = {15th Indian Conference on Human-Computer Interaction Design and Research, IndiaHCI 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219213492&partnerID=40&md5=c15be417b2721d7d2cba312c1c56575e},
 volume = {2337 CCIS},
 issn = {18650929},
 journal = {Communications in Computer and Information Science}
}


@inproceedings{Rajendran.,
 abstract = {Modern software systems demand continuous evolution to maintain performance, scalability, and security. Traditional single-agent AI-driven code refactoring approaches are often limited in addressing the multi-faceted constraints (e.g., performance, security, maintainability) that emerge during complex software design tasks. In this paper, we propose a novel Multi-Agent Large Language Model (LLM) Environment for automated software design and refactoring. Our conceptual framework comprises specialized LLM 'experts,' each trained or fine-tuned on a different aspect of software engineering (performance optimization, security hardening, UI/UX, maintainability). These agents collaborate in a cooperative or competitive fashion-using coordination protocols akin to consensus or auction mechanisms-to synthesize design insights and refactoring recommendations. We present formal definitions of agent interactions (including mathematical notation for termination conditions), a sequence diagram demonstrating agent collaboration, a complexity analysis of the coordination mechanism, and an expanded reference list. Preliminary experimental design is outlined to demonstrate how multi-agent interactions may resolve conflicting design goals more effectively than a single-agent approach. Our aim is to provide a roadmap for integrating multi-agent LLMs into the software development lifecycle, thereby improving development efficiency, reducing technical debt, and enhancing software quality. {\copyright} 2025 IEEE.},
 author = {Rajendran, V. and Besiahgari, D. and Patil, S. C. and Chandrashekaraiah, M. and Challagulla, V.},
 title = {A Multi-Agent LLM Environment for Software Design and Refactoring: A Conceptual Framework},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004581815&doi=10.1109%2fSoutheastCon56624.2025.10971563&partnerID=40&md5=78b116398c34c8c74d3d2841f6b2cad3},
 keywords = {Agent specialization;Application programs;Auction mechanisms;Auctions mechanisms;Autonomous agents;Code quality;Computer aided software engineering;Computer operating systems;Computer software maintenance;Computer software selection and evaluation;Consensus protocols;Formal Methods;Intelligent agents;Language model;Large Language Model;Large language models;Multi agent;Multi-agent systems;Multiagent systems (MASs);Search engines;Software design;Software packages;Software quality;Software refactoring;Software reliability;Specialisation},
 pages = {488--493-488--493},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/SoutheastCon56624.2025.10971563}
}


@inproceedings{Rafly.,
 abstract = {Kampung Batik Laweyan, a historic neighborhood in Surakarta, Indonesia, is renowned for its rich cultural heritage and tradition of batik textile production. With a history spanning several centuries, this area has become a vibrant hub for batik artisans and enthusiasts, showcasing intricate designs and craftsmanship that reflect local identity. The development of a mobile UI/UX application aimed at enhancing tourism in Kampung Batik Laweyan employs a Multi-User Centered Design (MUCD) methodology. The project unfolds in two iterations, beginning with a Minimum Viable Product (MVP) followed by the collection of feedback from primary user groups, including local business operators, residents, and tourists. Data collection involves interviews with local authorities, observations of the Micro, Small, and Medium Enterprises (MSME) environment in Laweyan, and an evaluation of current tourism marketing strategies. This comprehensive approach ensures that the application effectively caters to the diverse needs of its users. By integrating location-based gamification and a Large Language Model (LLM), the application not only enhances user engagement but also promotes the cultural and economic potential of the region. The System Usability Scale (SUS) assessment reveals an average score of 72.5, indicating a {\textquotedbl}good{\textquotedbl}level of usability, with qualitative feedback affirming its intuitive design and potential for further mobile app development. {\copyright} 2024 IEEE.},
 author = {Rafly, M. T. and Arisandi, D. and Tony, T. and Pranata, E. B. and Siwi, S. H. and Priyomarsono, N. W.},
 title = {Multi User Centered Design (MUCD) in Mobile UI/UX Development for Kampung Batik Laweyan},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002473927&doi=10.1109%2fICITSI65188.2024.10929148&partnerID=40&md5=307f8ab9ba60425c0eb1c7e7fa912991},
 keywords = {Architectural design;Cultural traditions;Economic and social effects;Gamification;History;Indonesia;Integrated circuit design;Kampung Batik Laweyan;Leisure;Marketing;mobile application;Mobile applications;Multi-user centered design;Multi-User Centered Design (MUCD);Multiusers;Neighbourhood;Product development;Textile industry;Tourism;tourism enhancement;UI/UX design;Usability Engineering;User centered design;User-centred},
 pages = {354--360-354--360},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/ICITSI65188.2024.10929148}
}


@article{Qazi.2024,
 abstract = {COVID-19 pandemic restrictions limited all social activities to curtail the spread of the virus. The foremost and most prime sector among those affected were schools, colleges, and universities. The education system of entire nations had shifted to online education during this time. Many shortcomings of Learning Management Systems (LMSs) were detected to support education in an online mode that spawned the research in Artificial Intelligence (AI) based tools that are being developed by the research community to improve the effectiveness of LMSs. This paper presents a detailed survey of the different enhancements to LMSs, which are led by key advances in the area of AI to enhance the real-time and non-real-time user experience. The AI-based enhancements proposed to the LMSs start from the Application layer and Presentation layer in the form of flipped classroom models for the efficient learning environment and appropriately designed UI/UX for efficient utilization of LMS utilities and resources, including AI-based chatbots. Session layer enhancements are also required, such as AI-based online proctoring and user authentication using Biometrics. These extend to the Transport layer to support real-time and rate adaptive encrypted video transmission for user security/privacy and satisfactory working of AI-algorithms. It also needs the support of the Networking layer for IP-based geolocation features, the Virtual Private Network (VPN) feature, and the support of Software-Defined Networks (SDN) for optimum Quality of Service (QoS). Finally, in addition to these, non-real-time user experience is enhanced by other AI-based enhancements such as Plagiarism detection algorithms and Data Analytics. {\copyright} 2024 Tech Science Press. All rights reserved.},
 author = {Qazi, S. and Kadri, M. B. and Naveed, M. and Khawaja, B. A. and Khan, S. Z. and Alam, M. M. and Su'ud, M. M.},
 year = {2024},
 title = {AI-Driven Learning Management Systems: Modern Developments, Challenges and Future Trends during the Age of ChatGPT},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201391014&doi=10.32604%2fcmc.2024.048893&partnerID=40&md5=d978573cd61bce15c518b96e496e77b6},
 keywords = {Application Layer;Artificial intelligence;Artificial Intelligence (AI);Chatbots;ChatGPT;Convolutional neural network;convolutional neural networks;Internet of thing;Internet of Things (IoT);Language processing;Learning management system;Learning management systems;Natural language processing;Natural languages;Network layers;Network security;online education;On-line education;Quality of service},
 pages = {3289--3314-3289--3314},
 volume = {80},
 number = {2},
 issn = {15462218},
 journal = {Computers, Materials and Continua},
 doi = {10.32604/cmc.2024.048893}
}


@article{Ponce.2025,
 abstract = {Smart cities are complex urban environments that rely on advanced technology and data analytics to enhance city services' quality of life, sustainability, and efficiency. As these cities continue to evolve, there is a growing need for a structured framework to evaluate and integrate products that align with smart city objectives. This paper introduces the Pentagon Framework, a comprehensive evaluation method designed to ensure that products and their materials meet the specific needs of smart cities. The framework focuses on five key features--smart, sustainable, sensing, social, and safe--collectively called the Penta-S concept. These features provide a structured approach to categorizing and assessing products, ensuring alignment with the city's goals for efficiency, sustainability, and user experience. The Smart City Pentagon Framework Analyzer is also presented, a dedicated web application that facilitates interaction with the framework. It allows product data input, provides feedback on alignment with the Penta-S features, and suggests personality traits based on the OCEAN model. Complementing the web application, the Smart City Penta-S Compliance Assistant API, developed through ChatGPT, offers a more profound, personalized evaluation of products, including the life cycle phase recommendations using the IPPMD model. This paper contributes to the development of smart city solutions by providing a flexible framework that can be applied to any product type, optimizing its life cycle, and ensuring compliance with the Pentagon Framework. This approach improves product integration and fosters user satisfaction by tailoring products and their materials to meet specific user preferences and needs within the smart city environment. The proposed framework emphasizes citizen-centric design and highlights its advantages over conventional evaluation methods, ultimately enhancing urban planning and smart city development. {\copyright} 2024 by the authors.},
 author = {Ponce, P. and Rojas, M. and Mendez, J. I. and Anthony, B. and Bradley, R. and Fayek, A. R.},
 year = {2025},
 title = {Smart City Products and Their Materials Assessment Using the Pentagon Framework},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215811471&doi=10.3390%2fmti9010001&partnerID=40&md5=ac17b5c995a05e8210bdb5b349a088d2},
 keywords = {data-driven solutions;Penta-S framework;smart cities;smart citizens;smart city assessment;smart communities;user-centric design},
 volume = {9},
 number = {1},
 issn = {24144088},
 journal = {Multimodal Technologies and Interaction},
 doi = {10.3390/mti9010001}
}


@article{Patel.2025,
 abstract = {We investigate the complexities of integrating large language models (LLMs) into software products, focusing on challenges encountered for determining their readiness for release. Our review of gray literature identifies common challenges in deploying LLMs, from pretraining and fine-tuning to user experience considerations. {\copyright} 2024 IEEE.},
 author = {Patel, H. and Boucher, D. and Fallahzadeh, E. and Hassan, A. E. and Adams, B.},
 year = {2025},
 title = {A State-of-the-Practice Release-Readiness Checklist for Generative AI-Based Software Products: A Gray Literature Survey},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002680342&doi=10.1109%2fMS.2024.3440190&partnerID=40&md5=090d16c79e99ba0f2970debe2d3813f3},
 keywords = {Grey literature;Key release;Language model;Performance-monitoring;Pre-training;Software;Software products;State of the practice;Systematic Review;Users' experiences},
 pages = {74--83-74--83},
 volume = {42},
 number = {1},
 issn = {07407459},
 journal = {IEEE Software},
 doi = {10.1109/MS.2024.3440190}
}


@inproceedings{Packer.,
 abstract = {This paper explores how Large-Language Model Artificial Intelligences (LLM-AIs) can be used to support people with Attention Deficit Hyperactivity Disorder (ADHD), Autism Spectrum Disorder (ASD), and other learning differences which effect cognition and self-regulation. It examines the cognitive load associated with complex writing tasks and how it affects users who have trouble with high-order thinking and planning. OpenAI's GPT-3 API is used to analyze how AI can help with complex language-based tasks. The paper first reflects on how GPT-3 uses natural language processing to generate text, translate, summarize, answer questions, and caption images, as well as how it adapts to respond to different situations and tasks to accurately classify them. Bloom's Taxonomy and SOLO Taxonomy are highlighted as language-driven methods of assessing learner understanding and to design activities and assessments that encourage high-order thinking. Literature is reviewed which suggests that students with disorders which effect executive functions need extra help with their writing skills to do well in school, and that early and accessible interventions such as digital self-management tools already help these learners. A model of executive-cognitive capacity is proposed to assess how best to manage the cognition of tasks and workloads, and to support a design matrix for assistive tools and processes. Finally, the Social Cognitive Theory (SCT) model for writing is evaluated for use as a procedural high-order writing process by which the tools can be designed and against which their efficacy can be validated. This review illustrates a universal design method for the development and evaluation of future AI writing tools for all users, with specific consideration towards users with atypical cognitive and sensory processing needs. {\copyright} 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
 author = {Packer, B. and Keates, S. and Antona, M. and Stephanidis, C.},
 title = {Designing AI Writing Workflow UX for Reduced Cognitive Loads},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173016253&doi=10.1007%2f978-3-031-35897-5_23&partnerID=40&md5=86e2f946b9b870e0d31d9ba3166e93b7},
 keywords = {accessibility;AI pedagogy;Artificial intelligence;Cognitive load;Cognitive loads;Diseases;Higher-order;Higher-order thinkings;High-order;high-order writing;Human computer interaction;Human-centered design;Human-centred designs;Natural language processing systems;Students;Taxonomies;User experience;User interfaces;Users' experiences;Work-flows},
 pages = {306--325-306--325},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-35897-5{\textunderscore }23}
}


@inproceedings{Odesola.,
 abstract = {This study addresses the need for comprehensive feedback in academic physiotherapy programs. Existing methods often fall short of providing coherent feedback using keywords, leaving a gap in evaluating crucial clinical skills. Introducing iAtexF, a Keyword-Based AI system, it offers instant feedback during practical exams, categorized into 'Good', 'Improvement', and 'Read more', aiding students in understanding their performance. Utilizing a Seq2seq framework with diverse LSTM and attention mechanisms, iAtexF excels in relevance, achieving a high similarity score of 73{\%} and a ROUGE score of 34{\%}. It surpasses both ChatGPT and experts in providing relevant suggestions (80.7{\%}), maintaining an appropriate tone (86.7{\%}), and ensuring a logical structure order (100{\%}). User experience evaluation of the iAtexF web application yielded a favourable 92{\%} rating, indicating its usability and effectiveness. This research signifies a significant advancement in educational technology and natural language processing, enhancing physiotherapy training through personalized AI-generated feedback, thereby improving the overall learning experience. {\copyright} 2024 IEEE.},
 author = {Odesola, O. and Alsmadi, H. and {Al Kafari}, A. S. and Kandasamy, G.},
 title = {AI-Powered Instant Textual Feedback on Physiotherapist Student Practical Perfomance},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204362920&doi=10.1109%2fIMSA61967.2024.10652614&partnerID=40&md5=edc3c79d99ac3faf83f147a019c6eb4a},
 keywords = {AI systems;Artificial intelligence;Attention mechanisms;Automatic Feedback;Clinical skills;Economic and social effects;Keyword-based;Language model;Large Language Model;Perfomance;performance;Physiotherapist;Students},
 pages = {443--449-443--449},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/IMSA61967.2024.10652614}
}


@inproceedings{Nandy.,
 abstract = {Large language models (LLMs) have emerged as a powerful tool for creating personalized knowledge experiences for users, often serving as their own interface through text-based chatbots. The interpretation of user intent and generation of output occur implicitly within the model's architecture. We propose an alternative approach in a system we call Bespoke where the LLM acts as an agent to explicitly reason about user intent, plan, and generate graphical interfaces to fulfill that intent. This approach enables the creation of visually rich interactions that complement chat-based interactions. By employing a step-by-step reasoning process to reduce ambiguity and keep the model on track, we compose interfaces from a toolkit of widgets, providing a designed and tailored user experience. Our early experiment shows that the output interface differs depending on the interpreted intent. In the current version, these interactions are multimodal in the automatic generation of UI; in future versions, this paradigm can be extended to multiple modalities of input and output. This agentive approach moves the interface towards a personalized, bespoke experience with multimodal interaction that adapts to the user's intentions. See video demonstration here [2]. {\copyright} 2024 Owner/Author.},
 author = {Nandy, P. and Adalgeirsson, S. O. and Sinha, A. K. and Kraljic, T. and Cleron, M. and Shi, L. and Singh, A. and Chaudhary, A. and Ganti, A. and Melancon, C. A. and Zhang, S. and Robishaw, D. and Ciurdar, H. and Secor, J. and Robertsen, K. A. and Climer, K. and Le, M. and Venkatesan, M. and Chi, P. and Li, P. and McDermott, P. F. and Shim, R. and Onsan, S. and Vaishnav, S. and Guam{\'a}n, S.},
 title = {Bespoke: Using LLM agents to generate just-in-time interfaces by reasoning about user intent},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211118801&doi=10.1145%2f3686215.3688372&partnerID=40&md5=abc992917e4912cec33bce47913b8ada},
 keywords = {agents;Chatbots;Generated UI;Graphical interface;Graphical user interfaces;HCI;Just-in-time;Language model;Large Language Model;LLM;Model agents;Modeling architecture;Reasoning process;Users' experiences},
 pages = {78--81-78--81},
 publisher = {{Association for Computing Machinery}},
 doi = {10.1145/3686215.3688372}
}


@article{Retzlaff.2024,
 abstract = {Artificial intelligence (AI) and especially reinforcement learning (RL) have the potential to enable agents to learn and perform tasks autonomously with superhuman performance. However, we consider RL as fundamentally a Human-in-the-Loop (HITL) paradigm, even when an agent eventually performs its task autonomously. In cases where the reward function is challenging or impossible to define, HITL approaches are considered particularly advantageous. The application of Reinforcement Learning from Human Feedback (RLHF) in systems such as ChatGPT demonstrates the effectiveness of optimizing for user experience and integrating their feedback into the training loop. In HITL RL, human input is integrated during the agent's learning process, allowing iterative updates and fine-tuning based on human feedback, thus enhancing the agent's performance. Since the human is an essential part of this process, we argue that human-centric approaches are the key to successful RL, a fact that has not been adequately considered in the existing literature. This paper aims to inform readers about current explainability methods in HITL RL. It also shows how the application of explainable AI (xAI) and specific improvements to existing explainability approaches can enable a better human-agent interaction in HITL RL for all types of users, whether for lay people, domain experts, or machine learning specialists. Accounting for the workflow in HITL RL and based on software and machine learning methodologies, this article identifies four phases for human involvement for creating HITL RL systems: (1) Agent Development, (2) Agent Learning, (3) Agent Evaluation, and (4) Agent Deployment. We highlight human involvement, explanation requirements, new challenges, and goals for each phase. We furthermore identify low-risk, high-return opportunities for explainability research in HITL RL and present long-term research goals to advance the field. Finally, we propose a vision of human-robot collaboration that allows both parties to reach their full potential and cooperate effectively. {\copyright}2024 The Authors. Published by AI Access Foundation under Creative Commons Attribution License CC BY 4.0.},
 author = {Retzlaff, C. O. and Das, S. and Wayllace, C. and Mousavi, P. and Afshari, M. and Yang, T. and Saranti, A. and Angerschmid, A. and Taylor, M. E. and Holzinger, A.},
 year = {2024},
 title = {Human-in-the-Loop Reinforcement Learning: A Survey and Position on Requirements, Challenges, and Opportunities},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184656775&doi=10.1613%2fjair.1.15348&partnerID=40&md5=7d43b0336a7075eb678e93ab7d56a7bf},
 keywords = {Autonomous agents;Fine tuning;Human-in-the-loop;Iterative methods;Iterative update;Learn+;Learning process;Learning systems;Machine-learning;performance;Reinforcement learning;Reinforcement learnings;Reward function;Robots;Users' experiences},
 pages = {359--415-359--415},
 volume = {79},
 issn = {10769757},
 journal = {Journal of Artificial Intelligence Research},
 doi = {10.1613/jair.1.15348}
}


@proceedings{Mirmotahari.2024,
 abstract = {The advancement of computer-based innovations over the years has drastically altered the role of the end-user, from passive users of technology to active participants influencing technological development. Each major innovation, associated with preceding hardware and software milestones, has led to new understandings and skill sets required of end-users. This workshop position paper explores the technological progress from mainframe computers to personal computers, the internet, and the nascent age of artificial intelligence (AI) based on Large Language Models (LLMs). We examine how each technological leap has transformed the end-user experience, the evolving literacies demanded, and speculate how the evolution of user interaction with technology in the future might move in different directions and widen the technological gap. {\copyright} 2024 Copyright for this paper by its authors.},
 year = {2024},
 title = {Evolution of Technological Innovations, User Experiences, and Literacies},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194164342&partnerID=40&md5=0e91f4eee33b56d8a2f9c588b6e147ce},
 keywords = {End-user;End-users;Engineering education;evolution of technology;Hardware and software;Passive users;Personal computers;Skill sets;Technological development;technological gap;Technological innovation;User experience;User interfaces;user literacy;Users' experiences},
 volume = {3685},
 publisher = {CEUR-WS},
 editor = {Mirmotahari, O. and M{\o}rch, A. and Berg, Y. and Barricelli, B. R. and Fischer, G. and Fogli, D. and Morch, A. and Piccinno, A. and Valtolina, S.}
}


@proceedings{Metzger.2024,
 abstract = {While conversational agents based on Large Language Models (LLMs) can drive progress in many domains, they are prone to generating faulty information. To ensure an efficient, safe, and satisfactory user experience maximizing benefits of these systems, users must be empowered to judge the reliability of system outputs. In this, both disclaimers and agents' communicative style are pivotal design instances. In an online study with 594 participants, we investigated how these affect users' trust and a mock-up agent's persuasiveness, based on an established framework from social psychology. While prior information on potential inaccuracies or faulty information did not affect trust, an authoritative communicative style elicited more trust. Also, a trusted agent was more persuasive resulting in more positive attitudes regarding the subject of the conversation. Results imply that disclaimers on agents' limitations fail to effectively alter users' trust but can be supported by appropriate communicative style during interaction. {\copyright} 2024 Copyright held by the owner/author(s)},
 year = {2024},
 title = {Empowering Calibrated (Dis-)Trust in Conversational Agents: A User Study on the Persuasive Power of Limitation Disclaimers vs. Authoritative Style},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194897802&doi=10.1145%2f3613904.3642122&partnerID=40&md5=9e9740fe212eb211ff3825151da7ca83},
 keywords = {Chatbots;ChatGPT;communicative style;Computational linguistics;Conversational Agents;elaboration likelihood model;Elaboration likelihood models;Language model;Large Language Model;Large language models;Power;Social psychology;trust in automation;User interfaces;User Study},
 publisher = {{Association for Computing Machinery}},
 editor = {Metzger, L. and Miller, L. and Baumann, M. and Kraus, J.},
 doi = {10.1145/3613904.3642122}
}


@inproceedings{McCabe.,
 abstract = {The widespread availability of large language models (LLMs) has presented the opportunity for novice programmers to make use of them for the purpose of understanding and synthesising code. In this paper, we discuss a small pilot study intended to explore the user experience of doing so in a limited way, and the attitudes of a group of novice programmers towards this style of programming. We also draw parallels to the seminal work of Lisanne Bainbridge, and discuss the way in which her {\textquotedbl}ironies of automation{\textquotedbl} are also present when attempting to automate the activity of programming. {\copyright} 2024 Copyright held by the owner/author(s).},
 author = {McCabe, A. T. and Bj{\"o}rkman, M. and Engstr{\"o}m, J. and Kuang, P. and S{\"o}derberg, E. and Church, L. and Soderberg, E.},
 title = {Ironies of Programming Automation: Exploring the Experience of Code Synthesis via Large Language Models},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199036149&doi=10.1145%2f3660829.3660835&partnerID=40&md5=314584296d29ea9f2e6cadca6bd65450},
 keywords = {code comprehension;Code synthesis;Computational linguistics;Computer programming;Human computer interaction;Human-Computer Interaction;Language model;Large Language Model;Large language models;Novice programmer;Pilot studies;Prompt engineering;prompt programming;User interfaces;Users' experiences},
 pages = {12--21-12--21},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3660829.3660835}
}


@proceedings{Mathis.2024,
 abstract = {Large Language Models (LLMs) have recently been explored for a variety of tasks, most prominently for dialogue-based interactions with users. The future in-car voice assistant (VA) is envisioned as a proactive companion making suggestions to the user during the ride. We investigate the use of selected LLMs to generate proactive suggestions for a VA given different context situations by using a basic prompt design. An online study with users was conducted to evaluate the generated suggestions. We demonstrate the feasibility of generating context-based proactive suggestions with different off-the-shelf LLMs. Results of the user survey show that suggestions generated by the LLMs GPT4.0 and Bison received an overall positive evaluation regarding the user experience for response quality and response behavior over different context situations. This work can serve as a starting point to implement proactive interaction for VA with LLMs based on the recognized context situation in the car. {\copyright} 2024 Owner/Author.},
 year = {2024},
 title = {Generating Proactive Suggestions based on the Context: User Evaluation of Large Language Model Outputs for In-Vehicle Voice Assistants},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199534280&doi=10.1145%2f3640794.3665568&partnerID=40&md5=8da1c6ff2a0f1912aa009be329225049},
 keywords = {Computational linguistics;Context situations;Context-based;Language model;Model outputs;Model-based OPC;Online studies;Quality control;Response behaviour;User evaluations;User interfaces;User surveys;Users' experiences},
 publisher = {{Association for Computing Machinery, Inc}},
 editor = {Mathis, L.-A. and G{\"u}nes, C. and Entz, K. and Lerch, D. and Diederichs, F. and Widlroither, H.},
 doi = {10.1145/3640794.3665568}
}


@article{Martin.2025,
 abstract = {The last 3 years have witnessed an increasing awareness and consensus on using artificial intelligence (AI) to enhance decision-making in the construction sector. This study explores the integration of ChatGPT (Generative Pre-trained Transformer) into traditional risk management frameworks within the construction industry, contributing to the ongoing discourse on AI's role in enhancing risk identification, analysis, and mitigation. Using a mixed-method approach comparing ChatGPT-assisted to human evaluations, interviews, and a case study, the research develops a better understanding of construction risk analysis processes and discusses decision-making errors of omission, over- and underestimation of probabilities and impacts, and treatment of the residual risk after proposed mitigation strategies. Results suggest that users' experience of ChatGPT is primarily favorable, characterized by quick responses and an intuitive interface that enhances decision-making efficiency. Findings indicate that GPT may be especially beneficial for less experienced practitioners since it provides comprehensive risk awareness. However, experienced professionals contend that the software lacks contextual depth. The study contributes a ChatGPT-4 prompt to evaluate infrastructure risk for a given project scope. An evidenced case study on a road upgrade project in Ireland demonstrates a lessened dependence on the quality of user prompting skills and emphasizes the quality of project scope data input. A collaborative approach, including Chat-GPT early involvement and human refinement, promises to enhance conventional risk management speed and efficiency and reduce bias and inflexibility while maintaining the adaptability and ethical rigour required in the industry's evolving risk landscape. {\copyright} 2025 This work is made available under the terms of the Creative Commons Attribution 4.0 International license,.},
 author = {Martin, H. and James, J. and Chadee, A.},
 year = {2025},
 title = {Exploring Large Language Model AI tools in Construction Project Risk Assessment: Chat GPT Limitations in Risk Identification, Mitigation Strategies, and User Experience},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009096808&doi=10.1061%2fJCEMD4.COENG-16658&partnerID=40&md5=ecfedf54ad5c25392bb61ffdd71a18fb},
 keywords = {Artificial intelligence;Artificial Intelligence (AI);Behavioral research;ChatGPT;Construction;Construction industry;Decisions makings;Efficiency;Language model;Language processing;Large Language Model;Natural language processing;Natural language processing systems;Natural languages;Project management;Prompt;Risk analysis;Risk assessment;Risk management;Risk perception;Risks management;User experience;User interfaces},
 volume = {151},
 number = {04025119},
 issn = {07339364},
 journal = {Journal of Construction Engineering and Management},
 doi = {10.1061/JCEMD4.COENG-16658}
}


@article{Marchiori.2025,
 abstract = {The proceedings contain 13 papers. The special focus in this conference is on Web Information Systems and Technologies. The topics include: Overview of~Web Application Performance Optimization Techniques; interest and~Challenges of~Students Regarding Web and~Mobile Technologies; SWI (Soft Web Intelligence) Powered by~User-Defined Fuzzy Operators and~Aggregators; matching Pre-processed Database Records Using Natural Language Queries on~Advertisements; mapping Business Web Applications for~Web Automation; On the~Construction of~Text-to-SQL Tools Based on~Large Language Models for~Real-World Relational Databases; refining Community Boundaries in~Bee Swarm Optimization for~Enhanced Community Detection in~Social Networks; digital Citizen Rights: Accessibility of E-Government Websites in Italy; Assessing the~Validity of~the~Trust Factor Within User Experience Questionnaire Plus (UEQ+): A Comprehensive Validation Study; digital Transition to~a~Paperless Checklist Integrated into the~Industrial Information System; personalized User Experience and Engagement in Interactive Mobile Augmented Reality Software Through Fuzzy Weights.},
 author = {Marchiori, M. and {Garc{\'i}a Pe{\~n}alvo}, F.},
 year = {2025},
 title = {19th International Conference on Web Information Systems and Technologies, WEBIST 2023},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006822226&partnerID=40&md5=0635d1a3b27ef48691750ab5695ed441},
 volume = {543 LNBIP},
 issn = {18651348},
 journal = {Lecture Notes in Business Information Processing}
}


@inproceedings{Lukianova.,
 abstract = {Memory augmentation has long been a central field in Human-Computer Interaction (HCI) research. Recently, emerging multimodal large language models (MLLMs) have extended research on memory augmentation by enabling the retrieval of information stored in multiple formats (e.g., text and image) through free-form queries. However, literature has focused on text-based memory aids, there has been surprisingly limited research on image-based assistance, despite humans' superior efficiency in processing visual information. Therefore, in this work, we explore the effect of image aids on memory augmentation. To this end, we first design and implement an augmented reality (AR) memory augmentation system, informed by human evaluation of MLLM performance (GPT-4o, LLaVA, and Mini-Gemini) and insights from user interface (UI) design workshops. As a result, we found that GPT-4o is most suitable for our system, images complemented with text (i.e., Image+text) are the most preferred format of memory aids. We also identified optimal UI design parameters for AR-based memory augmentation. With a finalized version of the system prototype, we conduct a user study (N=20) consisting of two tasks that simulate real-life memory-related challenges. We found that Image+text significantly enhanced both recall performance and memory vividness. Additionally, from a user experience perspective, Image+text was considered the most helpful and easiest to use for memory augmentation. Our findings showed that images are a powerful modality for enhancing memory recall, extending beyond traditional text-based approaches. We expect that insights gained from this work will contribute to the development of practical, everyday memory augmentation systems. {\copyright} 2025 Copyright held by the owner/author(s).},
 author = {Lukianova, E. and Jeong, J.-Y. and Jeong, J.-W.},
 title = {A picture is worth a thousand words? Investigating the Impact of Image Aids in AR on Memory Recall for Everyday Tasks},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001919087&doi=10.1145%2f3708359.3712087&partnerID=40&md5=42711ba09f611ea542ee921a81a8ba4f},
 keywords = {Augmentation systems;Augmented reality;Cognitive Offloading;Human form models;Human-computer interaction researches;Image texts;Language model;Memory aids;Memory Augmentation;Memory management;Multi-modal;Systems analysis;User interface designs;Visualization in AR;Visualization in augmented reality},
 pages = {106--126-106--126},
 publisher = {{Association for Computing Machinery}},
 doi = {10.1145/3708359.3712087}
}


@proceedings{Lu.2024,
 abstract = {Design systems have become an industry standard for creating consistent, usable, and effective digital interfaces. However, detecting and correcting violations of design system guidelines, known as UI linting, is a major challenge. Manual UI linting is time-consuming and tedious, making it a prime candidate for automation. This paper presents a case study of adopting AI for UI linting. Through collaborative prototyping with UX designers, we analyzed the limitations of existing AI models and identified designers' core needs and priorities in UI linting. With such knowledge, we designed a hybrid technical pipeline that combines the deterministic nature of heuristics with the flexibility of large language models. Our case study demonstrates that AI alone is not sufficient for practical adoption and highlights the importance of a deep understanding of AI capabilities and user-centered design approaches. {\copyright} 2024 Owner/Author.},
 year = {2024},
 title = {AI Is Not Enough: A Hybrid Technical Approach to AI Adoption in UI Linting with Heuristics},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194170869&doi=10.1145%2f3613905.3637135&partnerID=40&md5=6b0a92f1630b3a4d5aaab45818a1651a},
 keywords = {Artificial intelligence;Case-studies;Collaborative prototyping;Computational linguistics;design systems;Deterministics;Digital interfaces;Industry standards;Language model;Large Language Model;Large language models;Software design;UI linting;User centered design;user interface (UI) design;User interface designs;User interface linting;User interfaces},
 publisher = {{Association for Computing Machinery}},
 editor = {Lu, Y. and Knearem, T. and Dutta, S. and Blass, J. and Kliman-Silver, C. and Bentley, F.},
 doi = {10.1145/3613905.3637135}
}


@article{Liu.2024,
 abstract = {A frequent use of conversational user interfaces (CUIs) today is improving the users' experience with online quantitative surveys. In this paper, we explore the use of CUIs in qualitative surveys. As a concrete use case, we adopt a specific, well-structured, qualitative research method called the repertory grid technique (RGT). We developed a hybrid user interface (HUI) that combines a graphical user interface (GUI) with a CUI to automate the distinct stages in a RGT survey. A pilot study was used to verify the feasibility of the approach and to fine-tune interface aspects of an initial prototype. In this paper, we report the results of a within-subject lab experiment with 24 participants that aimed to establish the performance and UX in a realistic context of a more advanced prototype. We observed a small decrease in UX in some hedonistic aspects, but also confirmed that the HUI performs similarly to a human agent in most pragmatic aspects. These results provide support for our hypothesis that automating qualitative surveys is possible with proper interface design. We hope that our work can inspire other researchers to design additional tools for qualitative survey automation, especially now that generative AI systems, such as ChatGPT, open up interesting new ways for computer systems to interact with users in natural language. {\copyright} 2024 The Authors},
 author = {Liu, Y. and Martens, J.-B.},
 year = {2024},
 title = {Conversation-based hybrid UI for the repertory grid technique: A lab experiment into automation of qualitative surveys},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183466132&doi=10.1016%2fj.ijhcs.2024.103227&partnerID=40&md5=9c4644f20ae1abe675a64043de47f49c},
 keywords = {Automation;Chatbot;Chatbots;Graphical user interfaces;Grid techniques;Hybrid UI;Hybrid User Interfaces;Lab. experiment;Qualitative survey automation;Qualitative surveys;Repertory grid technique;Repertory grids;Users' experiences},
 volume = {184},
 number = {103227},
 issn = {10715819},
 journal = {International Journal of Human Computer Studies},
 doi = {10.1016/j.ijhcs.2024.103227}
}


@article{Lim.2024,
 abstract = {This paper highlights the trip-easiness generative AI mechanism to simplify domestic and international travel planning through a comprehensive services range based on the users' locations, including itinerary management and car rental. This research focuses on building TripEase GenAI Mechanism with generative artificial intelligence (AI) for a fully-fledged AI-based trip planner web application. This mechanism would function independently in addition to the alternative of seamless integration with another platform, a car rental and travel planning system. This would enhance the overall user experience. Within our TripEase GenAI mechanism, users can effortlessly create personalized recommended itineraries after providing their essential trip details. This mechanism will generate a complete itinerary. The suggested itinerary would accompany a tailored packing list specific to the destination. We are leveraging cutting-edge tools such as LangChain, Semantic Kernel, and ChatGPT to achieve this objective. Our main aim is to revolutionize the travel planning experience by harnessing the power of AI technology. This research is envisioned to provide travelers with a seamless and personalized journey that caters to their individual preferences and needs. This paper outlines the design, evolution, and planning of the TripEase GenAI mechanism. We have laid a strong foundation for a user-friendly travel planning platform through meticulous documentation, thoughtful design, and iterative development. The ultimate goal is to enhance the overall travel planning experience by efficiently enriching imported services such as itinerary management and car rental modules. {\copyright} (2024), (Insight Society). All rights reserved.},
 author = {Lim, Z.-S. and Yulastri, A. and Ho, S.-B. and Tan, C.-H.},
 year = {2024},
 title = {Enhancing Travel Planning Efficiency with a Comprehensive TripEase GenAI Mechanism},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214292298&doi=10.18517%2fijaseit.14.6.11985&partnerID=40&md5=ee3d9c5b0be4b03d420da6667365a6de},
 keywords = {efficiency enhancement;Generative artificial intelligence;personalized journey;travel planning},
 pages = {2090--2097-2090--2097},
 volume = {14},
 number = {6},
 issn = {20885334},
 journal = {International Journal on Advanced Science, Engineering and Information Technology},
 doi = {10.18517/ijaseit.14.6.11985}
}


@article{Li.2025,
 abstract = {Software engineers have historically relied on human-powered Q{\&}A platforms like Stack Overflow (SO) as coding aids. With the rise of generative AI, developers have started to adopt AI chatbots, such as ChatGPT, in their software development process. Recognizing the potential parallels between human-powered Q{\&}A platforms and AI-powered question-based chatbots, we investigate and compare how developers integrate this assistance into their real-world coding experiences by conducting a thematic analysis of 1700+ Reddit posts. Through a comparative study of SO and ChatGPT, we identified each platform's strengths, use cases, and barriers. Our findings suggest that ChatGPT offers fast, clear, comprehensive responses and fosters a more respectful environment than SO. However, concerns about ChatGPT's reliability stem from its overly confident tone and the absence of validation mechanisms like SO's voting system. Based on these findings, we synthesized the design implications for future GenAI code assistants and recommend a workflow leveraging each platform's unique features to improve developer experiences. {\copyright} 2025 Owner/Author.},
 author = {Li, J. and Mynatt, E. D. and Mishra, V. and Bell, J.},
 year = {2025},
 title = {'Always Nice and Confident, Sometimes Wrong': Developer's Experiences Engaging Generative AI Chatbots Versus Human-Powered Q{\&}A Platforms},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004257534&doi=10.1145%2f3710927&partnerID=40&md5=d7236870adb24280656aa39755e0ae23},
 keywords = {ChatGPT;Computer software selection and evaluation;Data flow analysis;Data mining;developer support;Generative AI;Human engineering;Human-AI Collaboration;Language model;Large Language Model;programming assistance;Q{\&}A platform;reddit;social media;Software design;Software prototyping;Software reliability;Stack overflow;text mining;thematic analysis;User experience;Users' experiences},
 volume = {9},
 number = {CSCW029},
 issn = {25730142},
 journal = {Proceedings of the ACM on Human-Computer Interaction},
 doi = {10.1145/3710927}
}


@inproceedings{Li.,
 abstract = {Heads-up computing together with AI can enhance in-class learning experiences. In this position paper, we propose the development of a multimodal AI system called DeepVision that integrates Automatic Speech Recognition (ASR), Large Language Models (LLM), Large Vision Models (LVM), Information Retrieval (IR) and Inclusive User Experience Design (IUX) to convert real-time lectures into multiple knowledge representations. These will be visualized on heads-up communication devices such as Augmented Reality (AR) and Mixed Reality (MR) devices. The initiative is a collaboration between Habitat Learn Limited (HLL) and the University of Southampton, leveraging HLL's existing software and extensive data repository to address the challenges of traditional and digital learning environments, especially for students with disabilities or language differences. {\copyright} 2024 Copyright is held by the owner/author(s).},
 author = {Li, Y. and Liu, H. and Wald, M.},
 title = {DeepVision: Heads-up Computing and AI in Education},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206156694&doi=10.1145%2f3675094.3678991&partnerID=40&md5=69fa756b952717ea32716b9689db6896},
 keywords = {AI;AR;Augmented reality;Heads-up Computing;Head-up computing;In-class learning;Inclusive User Experience Design;Information access;Knowledge representation;Language model;Large Language Model;Learning experiences;Mixed Reality;Multi-modal information;Multimodal Information Access and Retrieval;User Experience Design},
 pages = {627--630-627--630},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3675094.3678991}
}


@inproceedings{Miah.,
 abstract = {With the rapid advance of machine learning (ML) technology, large language models (LLMs) are increasingly explored as an intelligent tool to generate program code from natural language specifications. However, existing evaluations of LLMs have focused on their capabilities in comparison with humans. It is desirable to evaluate their usability when deciding on whether to use a LLM in software production. This paper proposes a user centric method for this purpose. It includes metadata in the test cases of a benchmark to describe their usages, conducts testing in a multi-attempt process that mimics the uses of LLMs, measures LLM generated solutions on a set of quality attributes that reflect usability, and evaluates the performance based on user experiences in the uses of LLMs as a tool. The paper also reports a case study with the method in the evaluation of ChatGPT's usability as a code generation tool for the R programming language. Our experiments demonstrated that ChatGPT is highly useful for generating R program code although it may fail on hard programming tasks. The user experiences are good with overall average number of attempts being 1.61 and the average time of completion being 47.02 seconds. Our experiments also found that the weakest aspect of usability is conciseness, which has a score of 3.80 out of 5. {\copyright} 2024 IEEE.},
 author = {Miah, T. and Zhu, H.},
 title = {User Centric Evaluation of Code Generation Tools (Invited Paper)},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206466645&doi=10.1109%2fAITest62860.2024.00022&partnerID=40&md5=5815f4788bb17c7693c25d2809ed39e5},
 keywords = {ChatGPT;Code Generation;Code generation tools;Codegeneration;Computer software selection and evaluation;Contrastive Learning;Language model;Large Language Model;Large language models;Machine Learning;Machine-learning;Performance evaluation;Performances evaluation;R programming;R programming language;Usability},
 pages = {109--119-109--119},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/AITest62860.2024.00022}
}


@inproceedings{Rusdianto.,
 abstract = {The software industry is continuously evolving because of emerging technologies, evolving development methodologies, changing business needs, and shifting stakeholder preferences. Effectively managing daily changes is critical, especially given the complexity of requirement change management (RCM), which requires the development of adaptable systems that accurately reflect dynamic conditions. This paper explores the integration of Large Language Models (LLMs), specifically GPT-4, into software engineering to enhance the effectiveness of RCM. This paper proposes a novel methodology that leverages the sophisticated reasoning capabilities of LLM GPT-4 to analyze and predict the impacts of software requirement changes before implementation. Our approach combines LLMs with a structured analysis framework that interprets changes in software requirements and evaluates their potential impacts across multiple dimensions. The use of GPT-4 can revolutionize how software engineers understand and implement requirements changes, providing a comprehensive tool for predicting the impact of such changes and evaluating the consequences accurately. The results of this research can help requirements engineers perform automated change impact analysis, enabling them to make informed decisions regarding the acceptance or rejection of requirement change requests. This ultimately supports the creation of software products that better align with consumer needs and expectations, ensuring enhanced user experiences and satisfaction. {\copyright} 2024 IEEE.},
 author = {Rusdianto, D. S. and Fabroyir, H. and Yuhana, U. L.},
 title = {Innovative Approaches to Impact Analysis of Requirement Changes using LLM in Software Projects},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215267650&doi=10.1109%2fISCT62336.2024.10791169&partnerID=40&md5=a9c7a86abb8012703251e2925780faec},
 keywords = {Change Impact Analysis;Computer software selection and evaluation;Enterprise software;GPT-4;Impact analysis;Innovative approaches;Language model;Large Language Model;Predictive Analytics;Program processors;Requirement Change Management;Requirement change managements;Requirements change;Software project;Software requirements},
 pages = {604--610-604--610},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/ISCT62336.2024.10791169}
}


@inproceedings{SaffronDionysius.,
 abstract = {Circuit design is one of the initial stages of any electronic {\&} electrical projects. It has been a hard part of building a product since, it can be easily solved only by professional developers. In order to solve this part, a tool is build that combines both the core knowledge of electronics {\&} artificial intelligence. AI circuit builder is a tool that can be used by people who are beginners and don't really have a particular knowledge in a specific part of the circuit. The user can easily prompt the LLM in the form of natural language. The tool then generates a digital format for the desired output. The output is processed with a routing algorithm in order to sort out the routes. With the help of various modern technologies for the web the tool provides a seamless user experience overall. {\copyright} 2025 IEEE.},
 author = {{Saffron Dionysius}, T. and Rakesh, G. and {Jasmine Mystica}, K.},
 title = {AI Circuit Builder: Bridging Language {\&} Logic},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004415170&doi=10.1109%2fICVADV63329.2025.10960965&partnerID=40&md5=1b2b21620e3bb537f2102573780f53eb},
 keywords = {AI-Assisted Design;Artificial intelligence;Circuit Generation;Eclipse Layout KernelJS;Electronic design automation;GPT-3.5;Language processing;Logic circuits;Natural language processing;Natural languages;NodeJS;Printed circuit design;ReactJS;Report generators;Timing circuits;Web application;Web Applications},
 pages = {506--512-506--512},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/ICVADV63329.2025.10960965}
}


@inproceedings{Salehi.,
 abstract = {The current study aims to evaluate and compare the subjective quality of an AI-based training system developed for conducting child interviews, focusing on the distinction between immersive 3D (using virtual reality) and 2D desktop environments. To this end, a structured user study was conducted, involving 36 participants who were exposed to these two distinct environments. The study evaluated various aspects of user experience, namely presence, usability, visual fidelity, emotion, responsiveness, appropriateness, and training effectiveness. The findings reveal significant differences in user experience between the 2D and 3D environments. Notably, the 3D environment enhanced presence, visual fidelity, training effectiveness, and empathy. In contrast, the 2D environment was favored for usability. The study highlights the potential of immersive VR while also pointing out the need to improve the system response and emotional expressiveness of the avatars. {\copyright} 2024 ACM.},
 author = {Salehi, P. and Hassan, S. Z. and Baugerud, G. A. and Powell, M. and {L{\'o}pez Cano}, M. C. and Johnson, M. S. and R{\o}ed, R. K. and Johansen, D. and Sabet, S. S. and Riegler, M. A. and Halvorsen, P.},
 title = {Immersive Virtual Reality in Child Interview Skills Training: A Comparison of 2D and 3D Environments},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191427124&doi=10.1145%2f3652212.3652219&partnerID=40&md5=f20a96e1cdea7a266fa6cadc309a6d5f},
 keywords = {3-D environments;Immersion;Immersive virtual reality;Language model;Large Language Model;Large Language Model (LLM);Quality control;Quality of experience;Quality of Experience (QoE);Quality of service;Training effectiveness;User experience;User interfaces;Users' experiences;Virtual reality;Virtual Reality (VR);Visual fidelity},
 pages = {1--7-1--7},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3652212.3652219}
}


@article{Zhang.2025,
 abstract = {Graphical User Interfaces (GUIs) have long been central to human-computer interaction, providing an intuitive and visually-driven way to access and interact with digital systems. Traditionally, automating GUI interactions relied on script-based or rule-based approaches, which, while effective for fixed workflows, lacked the flexibility and adaptability required for dynamic, real-world applications. The advent of Large Language Models (LLMs), particularly multimodal models, has ushered in a new era of GUI automation. They have demonstrated exceptional capabilities in natural language understanding, code generation, task generalization, and visual processing. This has paved the way for a new generation of ``LLM-brained'' GUI agents capable of interpreting complex GUI elements and autonomously executing actions based on natural language instructions. These agents represent a paradigm shift, enabling users to perform intricate, multi-step tasks through simple conversational commands. Their applications span across web navigation, mobile app interactions, and desktop automation, offering a transformative user experience that revolutionizes how individuals interact with software. This emerging field is rapidly advancing, with significant progress in both research and industry. To provide a structured understanding of this trend, this paper presents a comprehensive survey of LLM-powered GUI agents, exploring their historical evolution, core components, and advanced techniques. We address critical research questions such as existing GUI agent frameworks, the collection and utilization of data for training specialized GUI agents, the development of fine-tuned models tailored for GUI tasks, and the evaluation metrics and benchmarks necessary to assess their effectiveness. Additionally, we examine emerging applications powered by these agents. Through a detailed analysis, this survey identifies key research gaps and outlines a roadmap for future advancements in the field. By consolidating foundational knowledge and state-of-the-art developments, this work aims to guide both researchers and practitioners in overcoming challenges and unlocking the full potential of LLM-powered GUI agents. We anticipate that this survey will serve both as a practical cookbook for constructing LLM-powered GUI agents, and as a definitive reference for advancing research in this rapidly evolving domain. The collection of papers reviewed in this survey will be hosted and regularly updated on the GitHub repository: https://github.com/vyokky/LLM-Brained-GUI-Agents-Survey. Additionally, a searchable webpage is available at https://aka.ms/gui-agent for easier access and exploration. {\copyright} 2025, Transactions on Machine Learning Research. All rights reserved.},
 author = {Zhang, C. and He, S. and Qian, J. and Li, B. and Li, L. and Qin, S. and Kang, Y. and Ma, M. and Liu, G. and Lin, Q. and Rajmohan, S. and Zhang, D. and Zhang, Q.},
 year = {2025},
 title = {Large Language Model-Brained GUI Agents: A Survey},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008342615&partnerID=40&md5=9e7a2bec87ff46c89dc5e0e862575318},
 volume = {2025-June},
 issn = {28358856},
 journal = {Transactions on Machine Learning Research}
}


@article{Yu.2025,
 abstract = {In the era of accelerating globalization, the necessity for multilingual education is increasingly prominent. This study investigates the effectiveness of the AI-based chatbot ChatGPT in multilingual teaching applications. This study employs a quasi-experimental research methodology to examine the experiences of 100 international students at a university in Western China. The investigation delves into multiple dimensions of ChatGPT's effectiveness, including user interface design, operational experience, educational interaction, student engagement, personalized learning recommendations, and the enhancement of cultural understanding. The findings indicate that ChatGPT demonstrates significant potential in multilingual teaching, particularly in providing personalized learning support and facilitating cultural comprehension. However, improvements are needed in aspects of user interface friendliness, interaction naturalness, and depth. This research not only provides empirical support for the use of ChatGPT in multilingual education but also introduces a fresh perspective on integrating AI technology into educational practices, thereby advancing its role in multilingual teaching. {\copyright} 2024 John Wiley {\&} Sons Ltd.},
 author = {Yu, H. and Guo, Y. and Yang, H. and Zhang, W. and Dong, Y.},
 year = {2025},
 title = {Can ChatGPT Revolutionize Language Learning? Unveiling the Power of AI in Multilingual Education Through User Insights and Pedagogical Impact},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207281163&doi=10.1111%2fejed.12749&partnerID=40&md5=0fc667167b4a2a367030da1c498dfb58},
 keywords = {ChatGPT;educational interaction;human machine collaboration;multilingual teaching assistance;User experience},
 volume = {60},
 number = {e12749},
 issn = {01418211},
 journal = {European Journal of Education},
 doi = {10.1111/ejed.12749}
}


@inproceedings{Yin.,
 abstract = {With the recent development of the Virtual Reality (VR) industry, the increasing number of VR users pushes the demand for the massive production of immersive and expressive VR scenes in related industries. However, creating expressive VR scenes involves the reasonable organization of various digital content to express a coherent and logical theme, which is time-consuming and labor-intensive. In recent years, Large Language Models (LLMs) such as ChatGPT 3.5 and generative models such as stable diffusion have emerged as powerful tools for comprehending natural language and generating digital contents such as text, code, images, and 3D objects. In this paper, we have explored how we can generate VR scenes from text by incorporating LLMs and various generative models into an automated system. To achieve this, we first identify the possible limitations of LLMs for an automated system and propose a systematic framework to mitigate them. Subsequently, we developed Text2VRScene, a VR scene generation system, based on our proposed framework with well-designed prompts. To validate the effectiveness of our proposed framework and the designed prompts, we carry out a series of test cases. The results show that the proposed framework contributes to improving the reliability of the system and the quality of the generated VR scenes. The results also illustrate the promising performance of the Text2VRScene in generating satisfying VR scenes with a clear theme regularized by our well-designed prompts. This paper ends with a discussion about the limitations of the current system and the potential of developing similar generation systems based on our framework. {\copyright} 2024 IEEE.},
 author = {Yin, Z. and Wang, Y. and Papatheodorou, T. and Hui, P.},
 title = {Text2VRScene: Exploring the Framework of Automated Text-driven Generation System for VR Experience},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191431035&doi=10.1109%2fVR58804.2024.00090&partnerID=40&md5=5484a5bc3939d003efe68308f56b15a6},
 keywords = {Automated systems;Automation;Digital contents;Generation systems;Generative model;Human computer interaction;human computer interaction (HCI);Human-centered computing;Interaction paradigm;Interaction paradigms;Interaction techniques;Language model;Natural language processing systems;Text input;User interfaces;Virtual reality},
 pages = {701--711-701--711},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/VR58804.2024.00090}
}


@article{Yang.2025,
 abstract = {Retrieval-augmented generation (RAG)-based applications are gaining prominence due to their ability to leverage large language models (LLMs). These systems excel at combining retrieval mechanisms with generative capabilities, resulting in contextually relevant responses that enhance user experience. In particular, Transurban, a road operation company, replaced its rule-based virtual assistant (VA) with a RAG-based VA (RAGVA) to offer flexible customer interactions and support a wider range of scenarios. This paper presents an experience report from Transurban's engineering team on building and deploying a RAGVA, offering a step-by-step guide for creating a conversational application and engineering a RAGVA. The report serves as a reference for future researchers and practitioners. While the engineering processes for traditional software applications are well-established, the development and evaluation of RAG-based applications are still in their early stages, with numerous emerging challenges remaining uncharted. To address this gap, we conduct a focus group study with Transurban practitioners regarding developing and evaluating their RAGVA. We identified eight challenges encountered by the engineering team and proposed eight future directions that should be explored to advance the development of RAG-based applications. This study contributes to the foundational understanding of a RAG-based conversational application and the emerging AI software engineering challenges it presents. {\copyright} 2025 The Authors},
 author = {Yang, R. and Fu, M. and Tantithamthavorn, C. and Arora, C. and Vandenhurk, L. and Chua, J.},
 year = {2025},
 title = {RAGVA: Engineering retrieval augmented generation-based virtual assistants in practice},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000995469&doi=10.1016%2fj.jss.2025.112436&partnerID=40&md5=f208c6532413ab90fa8e55b72756aa44},
 keywords = {AI engineering;Application programs;Computer software selection and evaluation;Engineering teams;Excel;Human engineering;Language model;LLMOp;LLMOps;Responsible AI;Retrieval augmented generation;Retrieval mechanisms;SE4AI;Search engines;Software engineering;Virtual assistants;Virtual reality},
 volume = {226},
 number = {112436},
 issn = {01641212},
 journal = {Journal of Systems and Software},
 doi = {10.1016/j.jss.2025.112436}
}


@article{Xiang.2024,
 abstract = {In software maintenance, concise summaries of bug reports are crucial, significantly enhancing developer efficiency and ultimately improving software quality and user experience. Large language models (LLMs) have become the standard method for bug report summarization due to their powerful representation capabilities. However, LLM-based approaches face two primary challenges: accurately modeling the contextual relationships between various components within a bug report and the risk of overfitting when fine-tuning LLMs on datasets of limited size. To address these challenges, we propose a novel approach, SumLLaMA, which leverages contrastive learning pre-training and parameter-efficient fine-tuning. Contrastive learning pre-training is employed to construct contextual relations between components in a single bug report, enabling SumLLaMA to learn sequence-level representations. For parameter-efficient fine-tuning, we fine-tune a smaller adapter instead of the entire LLM, reducing the number of parameters trained to about 1/1500 of the original model, effectively mitigating the risk of overfitting. To evaluate the effectiveness of SumLLaMA, we compare it against five baseline models, including a state-of-the-art model, on a publicly available dataset. The experimental results show that SumLLaMA outperforms all baselines by up to 26.66, 17.10, and 24.01 points in ROUGE-1, ROUGE-2, and ROUGE-L metrics, respectively, achieving a state-of-the-art result for automated bug report summarization. {\copyright} 2013 IEEE.},
 author = {Xiang, B. and Shao, Y.},
 year = {2024},
 title = {SumLLaMA: Efficient Contrastive Representations and Fine-Tuned Adapters for Bug Report Summarization},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192955028&doi=10.1109%2fACCESS.2024.3397326&partnerID=40&md5=f6f63d204268411f9f230faa2f168454},
 keywords = {Bug report summarization;Bug reports;Code;Computer bugs;Computer software maintenance;Computer software selection and evaluation;contrastive representation;efficient fine-tuning;Fine tuning;Job analysis;Language model;Quality control;Self-supervised learning;Semantics;Software maintenance;Task analysis},
 pages = {78562--78571-78562--78571},
 volume = {12},
 issn = {2169-3536},
 journal = {IEEE Access},
 doi = {10.1109/ACCESS.2024.3397326}
}


@inproceedings{Wit.,
 abstract = {In this paper, we explore the use of large language models, in this case the ChatGPT API, as simulated users to evaluate designed, rule-based conversations. This type of evaluation can be introduced as a low-cost method to identify common usability issues prior to testing conversational agents with actual users. Preliminary findings show that ChatGPT is good at playing the part of a user, providing realistic testing scenarios for designed conversations even if these involve certain background knowledge or context. GPT-4 shows vast improvements over ChatGPT (3.5). In future work, it is important to evaluate the performance of simulated users in a more structured, generalizable manner, for example by comparing their behavior to that of actual users. In addition, ways to fine-tune the LLM could be explored to improve its performance, and the output of simulated conversations could be analyzed to automatically derive usability metrics such as the number of turns needed to reach the goal. Finally, the use of simulated users with open-ended conversational agents could be explored, where the LLM may also be able to reflect on the user experience of the conversation. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
 author = {Wit, J. and F{\o}lstad, A. and Araujo, T. and Papadopoulos, S. and E.L.-C., Law and Luger, E. and Goodwin, M. and Hobert, S. and Brandtzaeg, P. B.},
 title = {Leveraging Large Language Models as Simulated Users for Initial, Low-Cost Evaluations of Designed Conversations},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190376004&doi=10.1007%2f978-3-031-54975-5_5&partnerID=40&md5=9a918ab3cb430c0852d139d6bf988431},
 keywords = {Automatic evaluation;Background knowledge;Computational linguistics;Conversational Agents;Cost evaluations;Costs;Language model;Large Language Model;Large language models;Low cost methods;Low-costs;performance;Rule based;User interfaces},
 pages = {77--93-77--93},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-54975-5{\textunderscore }5}
}


@article{Win.2025,
 abstract = {The proceedings contain 23 papers. The special focus in this conference is on Persuasive Technology. The topics include: Personalized Social Proof for~Persuasive Human-Robot Interaction; personalized Digital Interventions for Behavior Change: Insights from the MoM App Study; exploring the Potential and Limitations of Large Language Models to Control the Behavior of Embodied Persuasive Agents; insights into the~Design of~Ethical and~Trustworthy Persuasive Technologies; effect of Competitive and Cooperative Learning Contexts in Controversial Information Search: Preliminary Results; the Heuristic Evaluation of~Manipulative Interfaces; digital Persuasion: Understanding the~Impact of~Online Influencers on~Public Opinion; lifeLink: The Design and Evaluation of an mHealth App for Caregivers Supporting Individuals with Suicidality; bridging Research and Practice in Persuasive Mobile Stress Management Apps: A 21-Year Comparative Analysis and Novel Design Framework; designing Behavior Change Support Systems for Recovery from Addictions: Mapping Software Features with Counseling Strategies; investigation of the Eye Donor Aust App's Persuasiveness; MyHealthCore: Towards a Community-Engaged HIV Prevention Persuasive mHealth App for Black Communities in Canada; health Risk Management Using Persuasive Technology: A Scoping Review; evaluation of~an~Emotion-Aware Persuasive Framework Based on~Peripheral Interaction for~Reducing Physical Strain in~Office Environments; on People's Susceptibility to Persuasive Techniques in Social Engineering: Is It About the Technique or Their Readiness to Be Persuaded?; AMRageddon V1: The Design and Usability Evaluation of a Digital Escape Room Game for Antimicrobial Resistance Education Through Persuasive Technology; petBuddy: An Examination of Augmented Reality Mobile Health Game for Promoting Physical Activity; the Motivational Appeal of Persuasive Strategies in a Healthy Eating Behaviour Change Game; non-binary People are Harder to~Persuade: Evidence and~Insights.},
 author = {Win, K. T. and Ali, R. and Karapanos, E. and Papadopoulos, G. A. and Oyibo, K. and Vlahu-Gjorgievska, E.},
 year = {2025},
 title = {20th International Conference on Persuasive Technology, PERSUASIVE 2025},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008943439&partnerID=40&md5=c8488713fec13137e2eaddad16f955b9},
 volume = {15711 LNCS},
 issn = {03029743},
 journal = {Lecture Notes in Computer Science}
}


@inproceedings{WeitlHarms.,
 abstract = {This study explores the use of LLMs for providing quantitative zero-shot sentiment analysis of implicit software desirability, addressing a critical challenge in product evaluation where traditional review scores, though convenient, fail to capture the richness of qualitative user feedback. Innovations include establishing a method that 1) works with qualitative user experience data without the need for explicit review scores, 2) focuses on implicit user satisfaction, and 3) provides scaled numerical sentiment analysis, offering a more nuanced understanding of user sentiment, instead of simply classifying sentiment as positive, neutral, or negative. Data is collected using the Microsoft Product Desirability Toolkit (PDT), a well-known qualitative user experience analysis tool. For initial exploration, the PDT metric was given to users of two software systems. PDT data was fed through several LLMs (Claude Sonnet 3 and 3.5, GPT4, and GPT4o) and through a leading transfer learning technique, Twitter-Roberta-Base-Sentiment, and Vader, a leading sentiment analysis tool. Each system was asked to evaluate the data in two ways, by looking at the sentiment expressed in the PDT word/explanation pairs; and by looking at the sentiment expressed by the users in their grouped selection of five words and explanations, as a whole. Numerical analysis is used to provide insights into the magnitude of sentiment to drive high quality decisions regarding product desirability. Each LLM is asked to provide its confidence (low, medium, high) in its sentiment score, along with an explanation of its score. All LLMs tested were able to statistically detect user sentiment from the users' grouped data, whereas TRBS and Vader were not. The confidence and explanation of confidence provided by the LLMs assisted in understanding user sentiment. This study adds deeper understanding of evaluating user experiences, toward the goal of creating a universal tool that quantifies implicit sentiment. {\copyright} 2024 IEEE.},
 author = {Weitl-Harms, S. and Hastings, J. D. and Lum, J. and Wani, M. A. and Angelov, P. and Luo, F. and Ogihara, M. and Wu, X. and R.-E., Precup and Ramezani, R. and Gu, X.},
 title = {Using LLMs to Establish Implicit User Sentiment of Software Desirability},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000909813&doi=10.1109%2fICMLA61862.2024.00254&partnerID=40&md5=9e44562ab9ce418468054946cac2634a},
 keywords = {Adversarial machine learning;Analysis tools;Computer software reusability;Computer software selection and evaluation;Contrastive Learning;Convergence of numerical methods;Critical challenges;Federated learning;GPT;LLM;Machine Learning;Machine-learning;Product Desirability Toolkit;Product evaluation;Program processors;Sentiment analysis;Software Desirability;Software testing;Transfer learning;Users' experiences;Zero-Shot Learning},
 pages = {1645--1650-1645--1650},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/ICMLA61862.2024.00254}
}


@inproceedings{Waseem.,
 abstract = {In modern business, maintaining competitiveness and efficiency necessitates the integration of state-of-the-art technology. This paper introduces the Artificial Intelligence Procurement Assistant (AIPA), an advanced system co-developed with Solita, a Finnish software company. AIPA leverages Large Language Models (LLMs) and sophisticated data analytics to enhance the assessment of procurement call bids and funding opportunities. The system incorporates LLM agents to enhance user interactions, from intelligent search execution to results evaluation. Rigorous usability testing and real-world evaluation, conducted in collaboration with our industry partner, validated AIPA's intuitive interface, personalized search functionalities, and effective results filtering. The platform significantly streamlines the identification of optimal calls by synergizing LLMs with resources from the European Commission TED and other portals. Feedback from the company guided essential refinements, particularly in the performance of ChatGPT agents for tasks like translation and keyword extraction. Further contributing to its scalability and adaptability, AIPA has been made open-source, inviting community contributions for its ongoing refinement and enhancement. Future developments will focus on extensive case studies, iterative improvements through user feedback, and expanding data sources to further elevate its utility in streamlining and optimizing procurement processes. {\copyright} The Author(s) 2024.},
 author = {Waseem, M. and Das, T. and Paloniemi, T. and Koivisto, M. and R{\"a}s{\"a}nen, E. and Set{\"a}l{\"a}, M. and Mikkonen, T. and Hyrynsalmi, S. and M{\"u}nch, J. and Smolander, K. and Melegati, J.},
 title = {Artificial Intelligence Procurement Assistant: Enhancing Bid Evaluation},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188726315&doi=10.1007%2f978-3-031-53227-6_8&partnerID=40&md5=b9a2790dc8b77b280621d1b8baea9a49},
 keywords = {Advanced systems;Artificial intelligence;Bid evaluation;Competition;Data analytics;Finnish;Funding opportunities;Language model;Model agents;Software company;State-of-the-art technology;User Interaction},
 pages = {108--114-108--114},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-53227-6{\textunderscore }8}
}


@article{Wang.2025,
 abstract = {Within the mHealth framework, systematic research that collects and analyzes patient data to establish comprehensive digital health archives for hypertensive patients, and leverages large language models (LLMs) to assist clinicians in health management and Blood Pressure (BP) control remains limited. In this study, our aims to describe the design, development and usability evaluation process of a management platform (Hyper-DREAM) for hypertension. Our multidisciplinary team employed an iterative design approach over the course of a year to develop the Hyper-DREAM platform. This platform's primary functionalities encompass multimodal data collection (personal hypertensive digital phenotype archive), multimodal interventions (BP measurement, medication assistance, behavior modification, and hypertension education) and multimodal interactions (clinician-patient engagement and BP Coach component). In August 2024, the mHealth App Usability Questionnaire (MAUQ) was conducted involving 51 hypertensive patients recruited from three distinct centers. In parallel, six clinicians engaged in management activities and contributed feedback via the Doctor's Software Satisfaction Questionnaire (DSSQ). Concurrently, a real-world comparative experiment was conducted to evaluate the usability of the BP Coach, ChatGPT-4o Mini, ChatGPT-4o and clinicians. The comparative experiment demonstrated that the BP Coach achieved significantly higher scores in utility (mean scores 4.05, SD 0.87) and completeness (mean scores 4.12, SD 0.78) when compared to ChatGPT-4o Mini, ChatGPT-4o, and clinicians. In terms of clarity, the BP Coach was slightly lower than clinicians (mean scores 4.03, SD 0.88). In addition, the BP Coach exhibited lower performance in conciseness (mean scores 3.00, SD 0.96). Clinicians reported a marked improvement in work efficiency (2.67 vs. 4.17, P {\textless}.001) and experienced faster and more effective patient interactions (3.0 vs. 4.17, P =.004). Furthermore, the Hyper-DREAM platform significantly decreased work intensity (2.5 vs. 3.5, P =.01) and minimized disruptions to daily routines (2.33 vs. 3.55, P =.004). The Hyper-DREAM platform demonstrated significantly greater overall satisfaction compared to the WeChat-based standard management (3.33 vs. 4.17, P =.01). Additionally, clinicians exhibited a markedly higher willingness to integrate the Hyper-DREAM platform into clinical practice (2.67 vs. 4.17, P {\textless}.001). Furthermore, patient management time decreased from 11.5~min (SD 1.87) with Wechat-based standard management to 7.5~min (SD 1.84, P =.01) with Hyper-DREAM. Hypertensive patients reported high satisfaction with the Hyper-DREAM platform, including ease of use (mean scores 1.60, SD 0.69), system information arrangement (mean scores 1.69, SD 0.71), and usefulness (mean scores 1.57, SD 0.58). In conclusion, our study presents Hyper-DREAM, a novel artificial intelligence-driven platform for hypertension management, designed to alleviate clinician workload and exhibiting significant promise for clinical application. The Hyper-DREAM platform is distinguished by its user-friendliness, high satisfaction rates, utility, and effective organization of information. Furthermore, the BP Coach component underscores the potential of LLMs in advancing mHealth approaches to hypertension management. {\copyright} The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.},
 author = {Wang, Y. and Zhu, T. and Zhou, T. and Wu, B. and Tan, W. and Ma, K. and Yao, Z. and Wang, J. and Li, S. and Qin, F. and Xu, Y. and Tan, L. and Liu, J.},
 year = {2025},
 title = {Hyper-DREAM, a Multimodal Digital Transformation Hypertension Management Platform Integrating Large Language Model and Digital Phenotyping: Multicenter Development and Initial Validation Study},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001710787&doi=10.1007%2fs10916-025-02176-1&partnerID=40&md5=b70c8da7fa70b9111e6e2002897419ce},
 keywords = {adult;antihypertensive agent;Article;Artificial intelligence;behavior change;behavior modification;blood pressure measurement;ChatGPT;clinical assessment;clinical practice;clinical trial;cohort analysis;controlled study;Digital health;Digital phenotyping;Digital transformation;Female;health care management;human;Humans;Hypertension;Hypertension management;hypertensive patient;Large Language Model;Large language models;major clinical study;Male;Middle Aged;mobile application;Mobile applications;Mobile health;multicenter study;multidisciplinary team;Multimodal intervention;organization and management;patient care;patient coding;patient engagement;patient satisfaction;personalized medicine;Phenotype;Precision medicine;questionnaire;social media;telehealth;Telemedicine;Usability Testing;validation study;workload},
 volume = {49},
 number = {42},
 issn = {01485598},
 journal = {Journal of Medical Systems},
 doi = {10.1007/s10916-025-02176-1}
}


@article{Wang.2023,
 abstract = {UI animations, such as card movement and menu slide in/out, provide appealing user experience and enhance the usability of mobile applications. In the process of UI animation implementation, it is difficult for developers to identify suitable APIs for the animation to be implemented from a large number of APIs. Fortunately, the huge app market contains millions of apps, and they can provide valuable data resources for solving this problem. By summarizing the API usage for the same or similar animations in apps, reusable knowledge can be mined for the API recommendation. In this paper, we propose a novel method Animation2API, which mines the knowledge about APIs from existing apps and recommends APIs for UI animations. Different from existing text-based API recommendation approaches, Animation2API takes the UI animation in GIF/video format as query input. Firstly, we construct a database containing mappings between UI animations and APIs by analyzing a broad set of apps. Then, we build a UI animation feature extractor, which can be used to gain temporal-spatial feature vectors of UI animations. By comparing the temporal-spatial feature vectors between UI animations, we identify animations that are similar to the query animation from the database. Finally, we summarize the APIs used for implementing these animations and recommend a list of APIs for developers. The empirical evaluation results show that our method can achieve 82.66{\%} Success rate and outperform the baseline Guru by 230.77{\%} and 184.95{\%} in terms of Precision and Recall when considering twenty APIs. In the user study, we take the scenarios of using web search and ChatGPT to implement animations as baselines, and the results show that participants can complete animations faster (14.54{\%}) after using Animation2API. Furthermore, participants' positive feedbacks on the questionnaire indicate the usefulness of Animation2API. {\copyright} 1976-2012 IEEE.},
 author = {Wang, Y. and Liu, H. and Gao, S. and Tang, X.},
 year = {2023},
 title = {Animation2API: API Recommendation for the Implementation of Android UI Animations},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167811848&doi=10.1109%2fTSE.2023.3294971&partnerID=40&md5=4e171ab994e9f059240aef36b6d06a5e},
 keywords = {Animation;api recommendation;Application programming interfaces (API);Code;Codes (symbols);Data resources;Database systems;Features extraction;Information retrieval;Operating system;Query processing;Spatial feature vector;UI animation;Usability of mobile applications;user interface;User interfaces;Users' experiences;Web searches;Websites},
 pages = {4411--4428-4411--4428},
 volume = {49},
 number = {9},
 issn = {1939-3520},
 journal = {IEEE Transactions on Software Engineering},
 doi = {10.1109/TSE.2023.3294971}
}


@inproceedings{Wang.,
 abstract = {With the rapid development of web technology, more and more software applications have become web-based in the past decades. To ensure software quality and user experience, various techniques have been proposed to automatically test web applications by interacting with their GUIs. To achieve high functional coverage, web GUI testing tools often need to generate high-quality text inputs and interact with the associated GUI elements (e.g., click submit buttons). However, developing a holistic approach that solves both subtasks is challenging because the web GUI context can be complicated and highly dynamic, which is hard to process programmatically. The recent development of large vision-language models (LVLM) provides new opportunities to handle these longstanding problems. We in this paper propose VETL, the first LVLM-driven end-to-end web testing technique. With LVLM's scene understanding capabilities, VETL can generate valid and meaningful text inputs focusing on the local context, while avoiding the need to extract precise textual attributes. The selection of associated GUI elements is formulated as a visual question answering problem, allowing LVLM to capture the logical connection between the input box and the relevant element based on visual instructions. Further, the GUI exploration is guided by a multi-armed bandit module employing a curiosity-oriented strategy. Experiments show that VETL is effective in exploring web state/action spaces and detecting bugs. Compared with WebExplor, the state-of-the-art web testing technique, VETL can discover 25{\%} more unique web actions on benchmark websites. Moreover, it can expose functional bugs in top-ranking commercial websites, which have been confirmed by the website maintainers. Our work makes the first attempt of leveraging LVLM in end-to-end GUI testing, demonstrating promising results of this research direction. {\copyright} 2024 IEEE.},
 author = {Wang, S. and Fan, Y. and Li, X. and Liu, Y.},
 title = {Leveraging Large Vision-Language Model for Better Automatic Web GUI Testing},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215514657&doi=10.1109%2fICSME58944.2024.00022&partnerID=40&md5=eba9dbb0c33edd73b24a2500d79b8fb9},
 keywords = {Ability testing;Application programs;Automatic Web GUI Testing;Benchmarking;Computer debugging;Computer software selection and evaluation;End to end;Failure analysis;Graphical user interfaces;GUI testing;Input output programs;Language model;Large Language Model;Large Vision-Language Model;Model checking;Problem oriented languages;Program debugging;Software testing;Text input;Text Input Generation;Visual languages;Web testing},
 pages = {125--137-125--137},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/ICSME58944.2024.00022}
}


@article{vanderAaH..2024,
 abstract = {The proceedings contain 28 papers. The special focus in this conference is on Business Process Modeling, Development, and Support and Exploring Modeling Methods for Systems Analysis and Development. The topics include: Evaluating Large Language Models in~Process Mining: Capabilities, Benchmarks, and~Evaluation Strategies; mapping the~Landscape: Exploring Large Language Model Applications in~Business Process Management; designing a~User Interface to~Explore Collections of~Directly-Follows Graphs for~Process Mining Analysis; precision-Guided Minimization of~Arbitrary Declarative Process Models; leveraging Data Augmentation for~Process Information Extraction; a Generic Approach Towards Adapting User Preferences in~Business Process Execution; introducing Agile Controllability in~Temporal Business Processes; reviewing Conformance Checking Uses for~Run-Time Regulatory Compliance; visual Representation of~Resource Analysis Insights for~Process Mining; process Variant Analysis Across Continuous Features: A Novel Framework; a Novel Contextualization Method for~Process Discovery Using Activity Specialization Hierarchies; enhancing Our Understanding of Business Process Model Comprehension Using Biometric Data; a Method for Digital Business Ecosystem Design: Evaluation of Two Cases in the Maritime Dataspaces; technology for Automatic Usability Evaluation Using Model Driven Engineering; Building BESSER: An Open-Source Low-Code Platform; Towards Taming Large Language Models with~Prompt Templates for~Legal GRL Modeling; process Modeling with~Large Language Models; could a Large Language Model Contribute Significantly to Requirements Analysis?; fast {\&} Sound: Accelerating Synthesis-Rules-Based Process Discovery; Navigating the~Data Model Divide in~Smart Manufacturing: An Empirical Investigation for~Enhanced AI Integration; a Multi-dimensional Model for~the~Design and~Development of~Analytical Information Systems; situational Environmental, Social and~Governance Accounting: From Ethical Value Elicitation to~Sustainability Reporting; realizing the~Accountability of~Algorithms in~the~Public Sector: A Reference Method for~Managing Algorithm Registers; requirements for~a~Digital Twin for~Energy, Social, and~Governance Data of~Commercial Buildings.},
 author = {{van der Aa H.} and Bork, D. and Schmidt, R. and Sturm, A.},
 year = {2024},
 title = {25th International Working Conference on Business Process Modeling, Development, and Support, BPMDS 2024 and 29th International Working Conference on Exploring Modeling Methods for Systems Analysis and Development, EMMSAD 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197169304&partnerID=40&md5=50db9971a937fd2ce3c294e4039f4f17},
 volume = {511 LNBIP},
 issn = {18651348},
 journal = {Lecture Notes in Business Information Processing}
}


@inproceedings{Turhan.,
 abstract = {In this paper, developing an online tool for the Life Cycle Assessment (LCA) of unconventional construction materials in collaboration with Large Language Models (LLMs) is proposed. The LCA provides information on the environmental impact of a product throughout its entire life cycle, from the extraction of raw materials to disposal or recycling. The LLMs are neural network architectures, typically utilizing variants of recurrent neural networks such as the transformer, which are trained on large bodies of textual data using techniques such as pre-training and fine-tuning. This study focuses on the use of bacterial cellulose composites as a biobased unconventional construction material. The methodology of developing an LLM-aided LCA tool is divided into five stages: Defining the functional unit; identifying the life cycle stages; collecting environmental and social impact data; interpreting and evaluating; developing a web-based tool. The results of this study have shown that the designers can incorporate sustainable thinking in the design process by using LLMs integrated to LCA, ultimately contributing to a more sustainable future against the impacts of the Anthropocene. Overall, the outcomes demonstrated the value of human-computer interaction (HCI) as a tool for exploring new possibilities with biobased materials and for inspiring designers to reconsider the material evaluation in their work. Future studies can delve into the integration of this tool into building information modeling software or computational design software in order to perform LCA for 3D structures. Different scales of such applications in design practices, such as fashion design, product design or service design can also be conducted by questioning how LCA can be combined with LLMs to leverage novel sustainable design solutions. {\copyright} 2023, Education and research in Computer Aided Architectural Design in Europe. All rights reserved.},
 author = {Turhan, G. D. and Dokonal, W. and Hirschberg, U. and Wurzer, G.},
 title = {Life Cycle Assessment for the Unconventional Construction Materials in Collaboration with a Large Language Model},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172457872&doi=10.52842%2fconf.ecaade.2023.2.039&partnerID=40&md5=e0d0546b9e2ea52989980b72f979c46c},
 keywords = {Human-computer Interaction (HCI);Large language models (LLMs);Life Cycle Assessment (LCA);machine learning (ML)},
 pages = {39--48-39--48},
 publisher = {{Education and research in Computer Aided Architectural Design in Europe}},
 doi = {10.52842/conf.ecaade.2023.2.039}
}


@inproceedings{Troussas.,
 abstract = {This paper reports on the study of the integration of ChatGPT as an advice generator in custom educational software developed for Java programming. The software, in cooperation with ChatGPT API, pursues providing real-time, context-specific advice to students for better learning. This work adopted a two-fold evaluation approach to evaluating this integration. First, this study examines the effectiveness of this integration with the help of the Interrupted Time Series Analysis methodology to measure possible improvement in the performance metrics of the students in terms of error rates and task completion times. Second, this work presents a custom-designed questionnaire used to get student perceptions regarding the clarity, usefulness, and impact of ChatGPT's advice, and the level of student satisfaction with the user interface. The key takeaways from this research study are the substantial improvements in performance metrics that were noted quantitatively, with students achieving lower error rates and faster completion times after the intervention of ChatGPT. Qualitatively, learners express their satisfaction with the clarity of advice, which gives them an understanding that works on their learning and confidence in Java programming. These findings point toward the promise of integrating such advanced AI solutions in educational software toward a significant improvement in learning outcomes and the necessity of human-aided continuous user feedback for system refinement. {\copyright} 2024 IEEE.},
 author = {Troussas, C. and Krouska, A. and Papakostas, C. and Mylonas, P. and Sgouropoulou, C.},
 title = {Assessing the Impact of Integrating ChatGPT as an Advice Generator in Educational Software},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210801425&doi=10.1109%2fSEEDA-CECNSM63478.2024.00031&partnerID=40&md5=af6cc81e67bf34ea2bc7488eaaa0083d},
 keywords = {Adversarial machine learning;Advice generator;AI-powered tutoring system;AI-Powered Tutoring Systems;Artificial Intelligence in Education;ChatGPT in Education;Computer software selection and evaluation;Contrastive Learning;Custom Questionnaire Assessment;Educational Software;Interrupted time;Interrupted Time Series Analysis;Interrupted time series analyze;Java programming;Java programming language;Java Programming Learning;programming education;Programming learning;Students;Technology enhanced learning;Technology-Enhanced Learning;Time-series analysis;Tutoring system;User Experience Evaluation;User experience evaluations},
 pages = {127--133-127--133},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/SEEDA-CECNSM63478.2024.00031}
}


@inproceedings{Stutz.,
 abstract = {In all kinds of organizations, relational data is prevalent and ubiquitous in a plethora of systems. However, the integration and exchange of such data is cumbersome, time-consuming, and error-prone. Semantic technologies, such as ontologies, KGs, and linked data, were developed to facilitate this but require comprehensive technical skills and complex methods for mapping relational data to semantic formalisms. Naturally, this process lacks speed, scalability, and automation. This work presents a novel user-driven neuro-symbolic approach to transform relational data into KGs. In our approach, users are supported by neural models (in particular Large Language Models) and symbolic formalisms (ontologies and mappings) to automate various mapping tasks and thus speed up and scale up the transformation from relational to linked data. We implemented our approach in a comprehensive intelligent assistant dubbed LXS. Our experimental evaluation, conducted primarily with participants from the Robert Bosch GmbH, demonstrates enhanced mapping quality compared to manual creation, a competitive application, and AI-only generations. Additionally, it significantly reduces user interaction time by nearly half, independent of the user's experience level. Also, qualitatively, users appreciated the attractiveness and novelty of the user interface. Furthermore, the neuro-symbolic approach of LXS contributes to a more trustworthy human-AI interaction since it keeps users in the loop and provides transparency in the transformation process. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
 author = {St{\"u}tz, J.-D. and Karras, O. and Oelen, A. and Auer, S. and Comuzzi, M. and Grigori, D. and Sellami, M. and Zhou, Z.},
 title = {A User-Driven Hybrid Neuro-Symbolic Approach for Knowledge Graph Creation from Relational Data},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218937379&doi=10.1007%2f978-3-031-81375-7_10&partnerID=40&md5=419c0009ed51993e17e4503421c493ee},
 keywords = {Complex methods;Error prones;Graphical user interfaces;HCI;knowledge graph;Knowledge graph creation;Knowledge graphs;Mapping;Neuro-symbolic;Ontology's;Relational data;Semantic technologies;Technical skills;User driven;User profile},
 pages = {169--185-169--185},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-81375-7{\textunderscore }10}
}


@article{Sottilare.2025,
 abstract = {The proceedings contain 40 papers. The special focus in this conference is on Adaptive Instructional Systems. The topics include: Evaluating Adaptive Training for~Nautical Rules of~the~Road; from Standardization to~Personalization: Leveraging Learner Profiles to~Tailor Education; an Adaptive Simulated Startup Financial Modeling Mentor Using a~Large Language Model to~Address Shortages in~Skilled Advisors: Architecture and~Design Considerations; integrating Adaptive Interventions into Learning Engineering Workflows; leveraging Deterministic Algorithms to Personalize Education and Enhance Student Success: The Story of an Engineered Learning Experience; curriculum Sequencing as~a~Generalised Travelling Salesperson Problem: A Novel Perspective on~Learning Path Generation; evaluation of Difficulty-Based Adaptive Training Strategies on Simulator Flight Training Performance; designing an Adaptive Mobile Application for Learning Programming Among Computing Students from Marginalized Backgrounds; architecture for a Large Scale Learning Ecosystem; automated Response Generation Using Language Models: An Approach to~Enhancing User Interaction; Metacognition in HCI: Designing Systems for Planning and Flexibility; stress and Performance: Understanding the Effect of Appraisal and Coping on Performance in Complex Tasks; exploring the~Potential of~Large Language Models for~Estimating the~Reading Comprehension Question Difficulty; macrocognition in Simulation Based Training: A Practical Application of Learning Engineering in a Complex Training Environment; public Safety Personnel Readiness Prediction: A Hybrid Model of Neurophysiological and Psychometric Data; understanding the~Complexity of~Music Improvisation: Leveraging Cognitive Models to~Inform Adaptive Instruction Design; advancing Cognitive State Monitoring: Diagnosing Cognitive Control States Under Varying Automation Reliability Level; the Weaponization of~Critical Thinking: Understanding the~Dynamics of~Human Memory.},
 author = {Sottilare, R. A. and Schwarz, J.},
 year = {2025},
 title = {7th International Conference on Adaptive Instructional Systems, AIS 2025, held as part of the 27th HCI International Conference, HCII 2025},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007761709&partnerID=40&md5=f22bfbcd529a7aecc5f763b22dd580fe},
 volume = {15813 LNCS},
 issn = {03029743},
 journal = {Lecture Notes in Computer Science}
}


@article{Sottilare.2025b,
 abstract = {The proceedings contain 40 papers. The special focus in this conference is on Adaptive Instructional Systems. The topics include: Evaluating Adaptive Training for~Nautical Rules of~the~Road; from Standardization to~Personalization: Leveraging Learner Profiles to~Tailor Education; an Adaptive Simulated Startup Financial Modeling Mentor Using a~Large Language Model to~Address Shortages in~Skilled Advisors: Architecture and~Design Considerations; integrating Adaptive Interventions into Learning Engineering Workflows; leveraging Deterministic Algorithms to Personalize Education and Enhance Student Success: The Story of an Engineered Learning Experience; curriculum Sequencing as~a~Generalised Travelling Salesperson Problem: A Novel Perspective on~Learning Path Generation; evaluation of Difficulty-Based Adaptive Training Strategies on Simulator Flight Training Performance; designing an Adaptive Mobile Application for Learning Programming Among Computing Students from Marginalized Backgrounds; architecture for a Large Scale Learning Ecosystem; automated Response Generation Using Language Models: An Approach to~Enhancing User Interaction; Metacognition in HCI: Designing Systems for Planning and Flexibility; stress and Performance: Understanding the Effect of Appraisal and Coping on Performance in Complex Tasks; exploring the~Potential of~Large Language Models for~Estimating the~Reading Comprehension Question Difficulty; macrocognition in Simulation Based Training: A Practical Application of Learning Engineering in a Complex Training Environment; public Safety Personnel Readiness Prediction: A Hybrid Model of Neurophysiological and Psychometric Data; understanding the~Complexity of~Music Improvisation: Leveraging Cognitive Models to~Inform Adaptive Instruction Design; advancing Cognitive State Monitoring: Diagnosing Cognitive Control States Under Varying Automation Reliability Level; the Weaponization of~Critical Thinking: Understanding the~Dynamics of~Human Memory.},
 author = {Sottilare, R. A. and Schwarz, J.},
 year = {2025},
 title = {7th International Conference on Adaptive Instructional Systems, AIS 2025, held as part of the 27th HCI International Conference, HCII 2025},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007848472&partnerID=40&md5=e5128df3756c8517fa6afc67fe6c9eda},
 volume = {15812 LNCS},
 issn = {03029743},
 journal = {Lecture Notes in Computer Science}
}


@article{Siau.2025,
 abstract = {The proceedings contain 41 papers. The special focus in this conference is on HCI in Business, Government and Organizations. The topics include: Apology or Gratitude: The Impact of Verbal Recovery Strategies of AI-Powered Virtual Tourism Assistants on Tourists' Post-Recovery Satisfaction; enhancing the Omnichannel Retailing Customer Experience in the Pre-purchase Phase: Evaluation and Improvement of a Digital Grocery Brochure; investigating Users' Responses to Blurred Boundary Advertisements in Short Video Websites; RoBuddy - An Innovative Research Project on AI in Office Environments; a Method of Assembly Guidance Information Delivery in Augmented Reality Considering Users' Proficiency Levels; Once More with~(the Right) Feeling: How Historical Fiction Writing Processes of~Character Design, Plot Outline, and~Context Checking Are Affected by~Co-Writing with~ChatGPT; Using CNN Models to Predict the Future Trends of Listed Stocks on the Taiwan Stock Exchange; Integrating AI-Driven Personas and Procedural Visualization for Complete Communities Design and Urban Planning for Large-Scale Urban Development; Generative AI and~Changing Work: Systematic Review of~Practitioner-Led Work Transformations Through the~Lens of~Job Crafting; Follow My Logic: Generative AI Workflows in~Designing for~Serious Table-Top Games; AI Integration in ERP Systems: Optimizing Knowledge Management and Business Process Re-engineering for Strategic Outcomes; rethink the Way of Conducting Research: It is Time to Change to the Artificial Intelligence Era for Reliable Outcomes; augmenting Student Startups' Customer Validation Efforts Through Adaptive Coaching Using Large Language Models; skilled Labor Shortage and Artificial Intelligence: Challenges and Opportunities for the Regional Labor Market; LLM-Assisted Collaborative Change Specification of Industrial Control Software; ChatGPT and Financial Investing: The Advantages, the Disadvantages, and the Perils.},
 author = {Siau, K. L. and F.F.-H., Nah},
 year = {2025},
 title = {12th International Conference on HCI in Business, Government and Organizations, held as part of the 27th HCI International Conference, HCII 2025},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007143427&partnerID=40&md5=de4ce4c850bdc6d0606868cf982ed7f1},
 volume = {15805 LNCS},
 issn = {03029743},
 journal = {Lecture Notes in Computer Science}
}


@article{Siau.2025b,
 abstract = {The proceedings contain 41 papers. The special focus in this conference is on HCI in Business, Government and Organizations. The topics include: Apology or Gratitude: The Impact of Verbal Recovery Strategies of AI-Powered Virtual Tourism Assistants on Tourists' Post-Recovery Satisfaction; enhancing the Omnichannel Retailing Customer Experience in the Pre-purchase Phase: Evaluation and Improvement of a Digital Grocery Brochure; investigating Users' Responses to Blurred Boundary Advertisements in Short Video Websites; RoBuddy - An Innovative Research Project on AI in Office Environments; a Method of Assembly Guidance Information Delivery in Augmented Reality Considering Users' Proficiency Levels; Once More with~(the Right) Feeling: How Historical Fiction Writing Processes of~Character Design, Plot Outline, and~Context Checking Are Affected by~Co-Writing with~ChatGPT; Using CNN Models to Predict the Future Trends of Listed Stocks on the Taiwan Stock Exchange; Integrating AI-Driven Personas and Procedural Visualization for Complete Communities Design and Urban Planning for Large-Scale Urban Development; Generative AI and~Changing Work: Systematic Review of~Practitioner-Led Work Transformations Through the~Lens of~Job Crafting; Follow My Logic: Generative AI Workflows in~Designing for~Serious Table-Top Games; AI Integration in ERP Systems: Optimizing Knowledge Management and Business Process Re-engineering for Strategic Outcomes; rethink the Way of Conducting Research: It is Time to Change to the Artificial Intelligence Era for Reliable Outcomes; augmenting Student Startups' Customer Validation Efforts Through Adaptive Coaching Using Large Language Models; skilled Labor Shortage and Artificial Intelligence: Challenges and Opportunities for the Regional Labor Market; LLM-Assisted Collaborative Change Specification of Industrial Control Software; ChatGPT and Financial Investing: The Advantages, the Disadvantages, and the Perils.},
 author = {Siau, K. L. and F.F.-H., Nah},
 year = {2025},
 title = {12th International Conference on HCI in Business, Government and Organizations, held as part of the 27th HCI International Conference, HCII 2025},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007166117&partnerID=40&md5=2746445e0bb2f9cc917cdcd2fed6cbad},
 volume = {15804 LNCS},
 issn = {03029743},
 journal = {Lecture Notes in Computer Science}
}


@article{Shrestha.2025,
 abstract = {Mobile app users commonly rely on app store ratings and reviews to find apps that suit their needs. However, the sheer volume of reviews available on app stores can lead to information overload, thus impeding users' ability to make informed app selection decisions. To overcome this limitation, in this paper, we leverage Large Language Models (LLMs) to summarize mobile app reviews. In particular, we use the Chain of Density (CoD) prompt to guide OpenAI GPT-4 to generate abstractive, semantically dense, and readable summaries of mobile app reviews. The CoD prompt is engineered to iteratively extract salient entities from the source text and fuse them into a fixed-length summary. We evaluate the performance of our approach using a large dataset of mobile app reviews. We further conduct an empirical evaluation with 48 study participants to assess the readability of the generated CoD summaries. Our results show that an altered CoD prompt can correctly identify the main themes in user reviews and consolidate them into a natural language summary that is intended for end-user consumption. The prompt also manages to maintain the readability of the generated summaries while increasing their density. Our work in this paper aims to substantially improve mobile app users' experience by providing an effective mechanism for summarizing important user feedback in the review stream. {\copyright} The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025.},
 author = {Shrestha, S. and Mahmoud, A.},
 year = {2025},
 title = {Mobile application review summarization using chain of density prompting},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008805104&doi=10.1007%2fs10515-025-00533-5&partnerID=40&md5=d6389e8195d50343fbfe79ef7379b07a},
 keywords = {Abstracting;App stores;Information overloads;Language model;Large datasets;Large Language Model;LLMs;Mobile app;Mobile app review;Mobile app reviews;Mobile applications;Natural language processing systems;Selection decisions;Source text;Summarization},
 volume = {32},
 number = {62},
 issn = {09288910},
 journal = {Automated Software Engineering},
 doi = {10.1007/s10515-025-00533-5}
}


@proceedings{Shoeibi.2023,
 abstract = {This doctoral thesis explores the integration of Generative AI, specifically Large Language Models (LLMs) and diffusion models, in educational platforms. Emphasis is placed on cross-lingual transfer techniques to overcome language barriers and create personalized content. The study addresses the impact of Generative AI on personalized learning experiences and ethical concerns. A mixed-methods approach combines quantitative usage metrics with qualitative insights from interviews and surveys. Initial results indicate improved task performance and user engagement, but ongoing refinement is needed to address biases and ethics. The LATILL platform, a web search engine for German as Foreign Language teachers, is a case study. It leverages Generative AI to provide level-Appropriate texts, translations, and image generation. The research aims to determine this technology s impact and future potential on user experience, focusing on equitable access to personalized learning across diverse geolocations. {\copyright} 2023 CEUR-WS. All rights reserved.},
 year = {2023},
 title = {Cross-lingual Transfer in Generative AI-Based Educational Platforms for Equitable and Personalized Learning},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177038444&partnerID=40&md5=4e4bb27e6325f4cfb762c25218c46ff3},
 keywords = {Bias1;Cross-lingual;Diffusion;Diffusion Model;Education;Educational platforms;Equality;Ethical technology;Generative AI;language learning;Language model;Large Language Model;Learning systems;LLM;Personalized Learning;Search engines;User interfaces},
 volume = {3542},
 publisher = {CEUR-WS},
 editor = {Shoeibi, N. and Balderas, A. and Martinez-Mones, A. and Dodero, J. M. and Ros, S.}
}


@proceedings{Shin.2024,
 abstract = {Communicating design implications is common within the HCI community when publishing academic papers, yet these papers are rarely read and used by designers. One solution is to use design cards as a form of translational resource that communicates valuable insights from papers in a more digestible and accessible format to assist in design processes. However, creating design cards can be time-consuming, and authors may lack the resources/know-how to produce cards. Through an iterative design process, we built a system that helps create design cards from academic papers using an LLM and text-to-image model. Our evaluation with designers (N = 21) and authors of selected papers (N = 12) revealed that designers perceived the design implications from our design cards as more inspiring and generative, compared to reading original paper texts, and the authors viewed our system as an efective way of communicating their design implications. We also propose future enhancements for AI-generated design cards. {\copyright} 2024 Copyright held by the owner/author(s)},
 year = {2024},
 title = {From Paper to Card: Transforming Design Implications with Generative AI},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194876285&doi=10.1145%2f3613904.3642266&partnerID=40&md5=54b5a1a54cffb52fbfbe159b92c38d43},
 keywords = {Academic paper;Design;design card;Design implications;Design-process;Generative AI;Image modeling;Language model;Large Language Model;Paper;text-to-image model;translational science;User interfaces},
 publisher = {{Association for Computing Machinery}},
 editor = {Shin, D. and Wang, L. L. and Hsieh, G.},
 doi = {10.1145/3613904.3642266}
}


@inproceedings{Sergeyuk.,
 abstract = {Integrated Development Environments (IDEs) have become central to modern software development, especially with the integration of Artificial Intelligence (AI) to enhance programming efficiency and decision-making. The study of in-IDE Human-AI Experience is critical in understanding how these AI tools are transforming the software development process, impacting programmer productivity, and influencing code quality.We conducted a literature review to study the current state of in-IDE Human-AI Experience research, bridging a gap in understanding the nuanced interactions between programmers and AI assistants within IDEs. By analyzing 36 selected papers, our study illustrates three primary research branches: Design, Impact, and Quality of Interaction.The trends, challenges, and opportunities identified in this paper emphasize the evolving landscape of software development and inform future directions for research, and development in this dynamic field. Specifically, we invite the community to investigate three aspects of these interactions: designing task-specific user interface, building trust, and improving readability. {\copyright} 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
 author = {Sergeyuk, A. and Titov, S. and Izadi, M.},
 title = {In-IDE Human-AI Experience in the Era of Large Language Models; A Literature Review},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197312387&doi=10.1145%2f3643796.3648463&partnerID=40&md5=151adacb81dec63a045b134bb6a61601},
 keywords = {Artificial intelligence;Artificial intelligence tools;Computer interaction;Computer software selection and evaluation;Decision making;Decisions makings;Human-Computer Interaction;integrated development environment;Integrodifferential equations;Language model;Literature reviews;Problem oriented languages;programming;Research and development management;Software development process;User experience;user studies;User Study;Users' experiences},
 pages = {95--100-95--100},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3643796.3648463}
}


@article{SanchezBerriel.2025,
 abstract = {In recent years, Virtual Reality (VR) has emerged as a powerful tool for disseminating Cultural Heritage (CH), often incorporating Virtual Humans (VHs) to guide users through historical recreations. The advent of Large Language Models (LLMs) now enables natural, unscripted communication with these VHs, even on limited devices. This paper details a natural interaction system for VHs within a VR application of San Crist{\'o}bal de La Laguna, a UNESCO World Heritage Site. Our system integrates Speech-to-Text, LLM-based dialogue generation, and Text-to-Speech synthesis. Adhering to user-centered design (UCD) principles, we conducted two studies: a preliminary study revealing user interest in historically adapted language, and a qualitative test that identified key user experience improvements, such as incorporating feedback mechanisms and gender selection for VHs. The project successfully developed a prioritized user experience, focusing on usability evaluation, immersion, and dialogue quality. We propose a generalist methodology and recommendations for integrating unscripted VH dialogue in VR. However, limitations include dialogue generation latency and reduced quality in non-English languages. While a formative usability test evaluated the process, the small sample size restricts broad generalizations about user behavior. {\copyright} 2025 by the authors.},
 author = {S{\'a}nchez-Berriel, I. and P{\'e}rez-Nava, F. and P{\'e}rez-Rosario, L.},
 year = {2025},
 title = {Natural Interaction in Virtual Heritage: Enhancing User Experience with Large Language Models},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009087008&doi=10.3390%2felectronics14122478&partnerID=40&md5=1302a9ccafcf6d8369ca1c0dfa5751ce},
 keywords = {Behavioral research;Computational linguistics;cultural heritage;Cultural heritages;Dialogue generations;Human computer interaction;Language model;Large Language Model;Large language models;Limited devices;natural interaction;Natural interactions;Natural language processing systems;Prompt engineering;Speech communication;Speech processing;Usability Engineering;User centered design;User experience;User interfaces;Users' experiences;Virtual heritage;virtual humans;Virtual reality},
 volume = {14},
 number = {2478},
 issn = {20799292},
 journal = {Electronics (Switzerland)},
 doi = {10.3390/electronics14122478}
}


@proceedings{Lee.2024,
 abstract = {Personality assessments provide insights into understanding individual differences. In HCI, personality assessments are used to model user behavior or tailor user interfaces. However, conventional Likert-scale personality tests face issues in user engagement and capturing comprehensive personality nuances. Building upon prior work using conversational user interfaces for personality prediction, we delve deeper into personalized personality tests. Through a formative study (n=4), we identified three design goals for user engagement. Informed by these goals, we propose a novel architecture integrating multiple large language model agents to support free-form conversation-based personality assessment. Our system, ChatFive, predicts users' Big Five traits through real-Time personalized dialogue. Evaluations from our user study (n=20) revealed that ChatFive significantly improved conveying true responses and felt more engaged, though requiring longer response times and different validation. We discuss the limitations on the validity of ChatFive and its implications. {\copyright} 2024 Owner/Author.},
 year = {2024},
 title = {ChatFive: Enhancing User Experience in Likert Scale Personality Test through Interactive Conversation with LLM Agents},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199542158&doi=10.1145%2f3640794.3665572&partnerID=40&md5=a281bcbc1b0f8991e4e6477e54a87cdf},
 keywords = {Behavioral research;Computational linguistics;Conversational Agents;Conversational user interface;Conversational User Interface(CUI);Conveying;Language model;Large Language Model;Large Language Models(LLM);Likert scale;Model agents;Personality assessments;Personality Test;Personality tests;User engagement;User interfaces;Users' experiences},
 publisher = {{Association for Computing Machinery, Inc}},
 editor = {Lee, J. and Choi, Y. and Song, M. and Park, S.},
 doi = {10.1145/3640794.3665572}
}


@inproceedings{Zhao.,
 abstract = {Effective query-item relevance modeling is pivotal for enhancing user experience and safeguarding user satisfaction in e-commerce search systems. Recently, benefiting from the vast inherent knowledge, Large Language Model (LLM) approach demonstrates strong performance and long-tail generalization ability compared with previous neural-based specialized relevance learning methods. Though promising, current LLM-based methods encounter the following inadequacies in practice: First, the massive parameters and computational demands make it difficult to be deployed online. Second, distilling LLM models to online models is a feasible direction, but the LLM relevance modeling is a black box, and its rich intrinsic knowledge is difficult to extract and apply online. To improve the interpretability of LLM and boost the performance of online relevance models via LLM, we propose an Explainable LLM-driven Multi-dimensional Distillation framework for e-commerce relevance learning, which comprises two core components: (1) An Explainable LLM for relevance modeling (ELLM-rele), which decomposes the relevance learning into intermediate steps and models relevance learning as a Chain-of-Thought (CoT) reasoning, thereby enhancing both interpretability and performance of LLM. (2) A Multi-dimensional Knowledge Distillation (MKD) architecture that transfers the knowledge of ELLM-rele to current deployable interaction-based and representation-based student models from both the relevance score distribution and CoT reasoning aspects. Through distilling the probabilistic and CoT reasoning knowledge, MKD improves both the semantic interaction and long-tail generalization abilities of student models. Extensive offline evaluations and online experiments on Taobao search ad scene demonstrate that our proposed framework significantly enhances e-commerce relevance learning performance and user experience. {\copyright} 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
 author = {Zhao, G. and Zhang, X. and Lu, C. and Zhao, H. and Wu, T. and Wang, P. and Xu, J. and Zheng, B.},
 title = {Explainable LLM-driven Multi-dimensional Distillation for E-Commerce Relevance Learning},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009216090&doi=10.1145%2f3701716.3715222&partnerID=40&md5=0411b5b443e5fe1864a2ddcd44bf01fb},
 keywords = {Distillation;E- commerces;E-Commerce;E-learning;Electronic commerce;Knowledge Distillation;Language model;Large Language Model;Learning systems;Model-driven;Multi dimensional;performance;Relevance learning;Relevance models;Search engines;Semantic Matching;Semantics;User experience;User interfaces},
 pages = {631--640-631--640},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3701716.3715222}
}


@inproceedings{Lange.,
 abstract = {This study explores how AI-enabled work tools influence the Flow experiences of IT professionals, focusing on their potential to enhance or hinder states of deep focus and immersion. Drawing on interviews with 12 IT professionals, the research examines the interplay between AI tools, task characteristics, and Flow preconditions such as goal clarity, feedback, and the challenge-skill balance. The study follows ethical research design recommendations, ensuring participant privacy and informed consent. Findings reveal that AI tools generally play a supportive role, aiding productivity and creativity without consistently inducing Flow states. Their impact depends heavily on task complexity and user goals, with tools like GitHub Copilot and ChatGPT enhancing Flow-related conditions such as feedback and exploratory possibilities. However, limitations such as inaccuracies and poor adaptability to complex tasks occasionally disrupt Flow experiences. The study offers design recommendations to better align AI tools with Flow principles, including enhancing goal clarity, dynamic adaptability, and support for iterative exploration. These insights contribute to the growing discourse on AI's role in fostering psychological engagement and optimal experiences in professional settings. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
 author = {Lange, E. M. and Cajander, {\AA}. and Normark, M. and Degen, H. and Ntoa, S.},
 title = {Exploring Flow in IT Professionals' Use of AI-Integrated Tools: Insights from Interviews},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008211937&doi=10.1007%2f978-3-031-93429-2_3&partnerID=40&md5=23f2d5dcecc6b17f3dd8c5d17b8e9a97},
 keywords = {Artificial intelligence;Computer interaction;Design and evaluation methods;Design recommendations;Feedback;Flow experience;HCI design;HCI design and evaluation method;HCI design and evaluation methods;Human computer interaction;Human-Computer Interaction;Information systems;Information systems application;Information systems applications;Information use;IT professional;Natural language interfaces;User experience;User interfaces;Users' experiences},
 pages = {44--58-44--58},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-93429-2{\textunderscore }3}
}


@article{Kurosu.2024,
 abstract = {The proceedings contain 117 papers. The special focus in this conference is on Thematic Area Human Computer Interaction. The topics include: Unified UI Design System for Industrial HMI Software Development; evaluation of a Voice-Based Emotion Recognition Software in the Psycho-Oncological Care of Cancer Patients; does the Voice-Based Lifelogging Method ``Laughter Map'' of Visualizing a User's Laughter Experiences Enhance Positive Mood?; design and User Acceptance of Dynamic User Interface Adaptations Based on Situation-Awareness and Emotion-Recognition; automatically Identifying the~Human Sense of~Familiarity Using Eye Gaze Features; of Politics, Behavior and Commands: Processing Information Unspoken for Sentiment Analysis and Spoken Interaction Applications; evolution of Executive Education in Interactive Digital Design Field: A Case Study Analysis; beyond Future Skills: Developing Company Personas in Disruptive Transformation Processes; Generating Specifications from Requirements Documents for Smart Devices Using Large Language Models (LLMs); Modeling Theory of~Mind in~Multimodal HCI; designing Artificial Serendipity; Pictorial Usability Metric for User Experience LITE: Development and Psychological Measurement; a Study of the Impact of Different Teaching Methods on Students' Learning in Design Thinking Courses in Taiwan; Integrated DBR and ADDIE Model to Improve Pedagogical Practices in Mechatronic Design; the Trends and Research Progress of Mental Models in Interaction Design: A Bibliometric Study; enhancing Episodic Memory Recall Through Nostalgic Image Generation and Interactive Modification; a Bibliometric Analysis of~Eye Tracking in~User Experience Research; Through the Waves: An Auto-ethnographic Perspective on HCI Design and Research; foreword; preface; A Transformer Based Emotion Recognition Model for Social Robots Using Topographical Maps Generated from EEG Signals; spontaneous Theory of~Mind for~Artificial Intelligence.},
 author = {Kurosu, M. and Hashizume, A.},
 year = {2024},
 title = {Thematic Area Human Computer Interaction, HCI 2024, Held as Part of the 26th HCI International Conference, HCII 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195844991&partnerID=40&md5=51c0fedf8fd1499d7f3fd37e8700e113},
 volume = {14684 LNCS},
 journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}


@article{DaSilvaH..2025,
 abstract = {The proceedings contain 61 papers. The special focus in this conference is on Computer-Human Interaction Research and Applications. The topics include: How Different Blink Patterns of Pet Robots Evoke Feelings of Affection in People; arm in Motion: How Motion Modality and Erratic Behavior of a Robotic Arm Shape User Perception; An Examination of~Pre-school Children's Usage Behavior of~Augmented Reality: Traditional vs. AR-Assisted LEGO{\circledR} Building; Interviewing ChatGPT-Generated Personas to~Inform Design Decisions; an Experiment to Investigate Changes in Physiological Signals During Subtle Wind and Scent Presentation for Designing Subtle Notifications; Towards Multi-stakeholder Evaluation of~ML Models: A Crowdsourcing Study on~Metric Preferences in~Job-Matching System; current Design Practices in Applied Augmented Reality Research: A Methodological Review; emotion-Aware Interfaces: Empirical Methods for~Adaptive User Interface; bridging Medical Genetics, Genetic Counselling, and Patients: Proposing an Immersive, Interactive, and Holographic Health Information Platform with Evaluation Methods for Personalized Patient Education; why Do(n't) You Trust Us? Highlighting the~Importance of~Trust and~Transparency for~Designing B2B Platforms in~Electronics Manufacturing; enriched with Behaviour Theory Topic Guide Template for Digital Behaviour Change Interventions; evaluating Remote Communication Applications Using Student Usability Reviews; Enhancing EEG-Based User Verification with~a~Normalized Neural Network Ensemble Approach; systematic Literature Review of Gamification Design in Higher Education Programming Courses: Methodological Rigor Exposed; the Effect of~Progressive Disclosure in~the~Transparency of~Large Language Models; design and~Implementation of~a~Practice Record Visualization System Using Piano Performance Tracking Technology; User Issues and~Concerns in~Generative AI: A Mixed-Methods Analysis of~App Reviews; Caregiver Acceptability of~an~LLM-Powered Assistant Interface to~Improve Sleep Quality of~the~Elderly; user Experience and~Information Security Heuristics for~Digital Identity Wallets; how Can Heuristics Be Communicated?.},
 author = {{Da Silva H.}, Pl{\'a}cido and Cipresso, P.},
 year = {2025},
 title = {8th International Conference on Computer-Human Interaction Research and Applications, CHIRA 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000799924&partnerID=40&md5=9e56f467a79c9982ab38fb51f51baa32},
 volume = {2370 CCIS},
 issn = {18650929},
 journal = {Communications in Computer and Information Science}
}


@proceedings{Cuadra.2024,
 abstract = {From ELIZA to Alexa, Conversational Agents (CAs) have been deliberately designed to elicit or project empathy. Although empathy can help technology better serve human needs, it can also be deceptive and potentially exploitative. In this work, we characterize empathy in interactions with CAs, highlighting the importance of distinguishing evocations of empathy between two humans from ones between a human and a CA. To this end, we systematically prompt CAs backed by large language models (LLMs) to display empathy while conversing with, or about, 65 distinct human identities, and also compare how different LLMs display or model empathy. We find that CAs make value judgments about certain identities, and can be encouraging of identities related to harmful ideologies (e.g., Nazism and xenophobia). Moreover, a computational approach to understanding empathy reveals that despite their ability to display empathy, CAs do poorly when interpreting and exploring a user's experience, contrasting with their human counterparts. {\copyright} 2024 Copyright held by the owner/author(s)},
 year = {2024},
 title = {The Illusion of Empathy? Notes on Displays of Emotion in Human-Computer Interaction},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189492830&doi=10.1145%2f3613904.3642336&partnerID=40&md5=f8e16dc144ba7f57423565d7148ab39b},
 keywords = {Affective Computing;AI;Automation;Autonomous agents;Chatbots;Conversational Agents;Conversational user interface;Conversational User Interfaces;Disability;Emotion;Empathy;Ethics;Gender;Health;Human computer interaction;Human robot interaction;Human-AI Interaction;Human-Computer Interaction;Identity;Language model;Language processing;Large Language Model;LLMs;Machine design;Marginalization;Mental Health;Natural language processing;Natural language processing systems;Natural languages;Personalization;Personalizations;Power;Power and Privilege;Religion;Social Robots;Technological Harm;Ubiquitous computing;User Experience Design;User interfaces;Value in designs;Values in Design;Voice assistant;Voice Assistants;Wellbeing},
 publisher = {{Association for Computing Machinery}},
 editor = {Cuadra, A. and Wang, M. and Stein, L. A. and Jung, M. F. and Dell, N. and Estrin, D. and Landay, J. A.},
 doi = {10.1145/3613904.3642336}
}


@inproceedings{Constantinides.,
 abstract = {Mixed Reality (MR) technologies have transformed the way in which we interact and engage with digital content, offering immersive experiences that blend the physical and virtual worlds. Over the past years, there has been increasing interest in employing Artificial Intelligence (AI) technologies to improve user experience and trustworthiness in cultural contexts. However, the integration of Large Language Models (LLMs) into MR applications within the Cultural Heritage (CH) domain is relatively underexplored. In this work, we present an investigation into the integration of LLMs within MR environments, focusing on the context of virtual art exhibitions. We implemented a HoloLens MR application, which enables users to explore artworks while interacting with an LLM through voice. To evaluate the user experience and perceived trustworthiness of individuals engaging with an LLM-based virtual art guide, we adopted a between-subject study design, in which participants were randomly assigned to either the LLM-based version or a control group using conventional interaction methods. The LLM-based version allows users to pose inquiries about the artwork displayed, ranging from details about the creator to information about the artwork's origin and historical significance. This paper presents the technical aspects of integrating LLMs within MR applications and evaluates the user experience and perceived trustworthiness of this approach in enhancing the exploration of virtual art exhibitions. Results of an initial evaluation provide evidence about the positive aspect of integrating LLMs in MR applications. Findings of this work contribute to the advancement of MR technologies for the development of future interactive personalized art experiences. {\copyright} 2024 Owner/Author.},
 author = {Constantinides, N. and Constantinides, A. and Koukopoulos, D. and Fidas, C. and Belk, M.},
 title = {CulturAI: Exploring Mixed Reality Art Exhibitions with Large Language Models for Personalized Immersive Experiences},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198910809&doi=10.1145%2f3631700.3664874&partnerID=40&md5=952d82629a3fcdc6e2a960dd532b2c09},
 keywords = {Computational linguistics;Immersive;Language model;Large Language Model;Large language models;Mixed Reality;Mixed reality art;Mixed reality technologies;Model-based OPC;User Experience Evaluation;User experience evaluations;User interfaces;User Study;Users' experiences},
 pages = {102--105-102--105},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3631700.3664874}
}


@article{Coman.2025,
 abstract = {The proceedings contain 51 papers. The special focus in this conference is on Social Computing and Social Media. The topics include: A Serious Game Approach for~Teaching Requirements Engineering: User Experience Evaluation; identification of Older Adults' Characteristics that Affect the Usability of Mobile Applications: A Tertiary Study; generating Product Descriptions Using Customer Reviews on E-Commerce Sites; improving Intention Recognition Efficiency: A Study on Skeletal Data Dimensionality Reduction and Neural Architectures; first Steps Toward the Agile Integration of Information Architecture into a User-Centered Development Process; LLM-Driven Augmented Reality Puppeteer: Controller-Free Voice-Commanded Robot Teleoperation; redimensioning Visible Learning and Teaching in the Dynamics of a New Reality; Generative AI in Education: Exploring EAP Faculty Perspectives at a Multicultural UAE University; the Challenges Faced by Albanian Teachers in the Use of Media Technology During Teaching; Undergraduate Students' Journey with AI in the United Arab Emirates; Perspectives of Faculty on the Easiness and Usefulness of AI Tutoring Systems in Higher Education; exploring the Use of Paraphrasing Tools in Academic Writing and Its Potential Relation with Instances of Plagiarism; a Property Checklist for Evaluating the Student Experience with Consideration of Cultural Aspects; human-Robot Interaction in Higher Education: A Literature Review; artificial Intelligence in Higher Education: Student Perceptions of the Adoption and Integration in Ghana, West Africa; a Management Model for Evaluating Scientific Productivity in Chilean Universities: A Case Analysis; virtual Reality Meets Social Media: Transforming Skill Acquisition in Physiotherapy, Veterinary Surgery, and Driver Training; Evolution of Emotional Response of PLEA--An Embodied Virtual Being with Emotional Capabilities.},
 author = {Coman, A. and Vasilache, S.},
 year = {2025},
 title = {17th International Conference on Social Computing and Social Media, SCSM 2025, held as part of the 27th HCI International Conference, HCII 2025},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007138383&partnerID=40&md5=d549c67cd04881029d069804f24abcce},
 volume = {15787 LNCS},
 issn = {03029743},
 journal = {Lecture Notes in Computer Science}
}


@article{Coman.2025b,
 abstract = {The proceedings contain 51 papers. The special focus in this conference is on Social Computing and Social Media. The topics include: A Serious Game Approach for~Teaching Requirements Engineering: User Experience Evaluation; identification of Older Adults' Characteristics that Affect the Usability of Mobile Applications: A Tertiary Study; generating Product Descriptions Using Customer Reviews on E-Commerce Sites; improving Intention Recognition Efficiency: A Study on Skeletal Data Dimensionality Reduction and Neural Architectures; first Steps Toward the Agile Integration of Information Architecture into a User-Centered Development Process; LLM-Driven Augmented Reality Puppeteer: Controller-Free Voice-Commanded Robot Teleoperation; redimensioning Visible Learning and Teaching in the Dynamics of a New Reality; Generative AI in Education: Exploring EAP Faculty Perspectives at a Multicultural UAE University; the Challenges Faced by Albanian Teachers in the Use of Media Technology During Teaching; Undergraduate Students' Journey with AI in the United Arab Emirates; Perspectives of Faculty on the Easiness and Usefulness of AI Tutoring Systems in Higher Education; exploring the Use of Paraphrasing Tools in Academic Writing and Its Potential Relation with Instances of Plagiarism; a Property Checklist for Evaluating the Student Experience with Consideration of Cultural Aspects; human-Robot Interaction in Higher Education: A Literature Review; artificial Intelligence in Higher Education: Student Perceptions of the Adoption and Integration in Ghana, West Africa; a Management Model for Evaluating Scientific Productivity in Chilean Universities: A Case Analysis; virtual Reality Meets Social Media: Transforming Skill Acquisition in Physiotherapy, Veterinary Surgery, and Driver Training; Evolution of Emotional Response of PLEA--An Embodied Virtual Being with Emotional Capabilities.},
 author = {Coman, A. and Vasilache, S.},
 year = {2025},
 title = {17th International Conference on Social Computing and Social Media, SCSM 2025, held as part of the 27th HCI International Conference, HCII 2025},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007158998&partnerID=40&md5=5114fb7568d7bd9ecc2d2533660f44dc},
 volume = {15786 LNCS},
 issn = {03029743},
 journal = {Lecture Notes in Computer Science}
}


@inproceedings{Choe.,
 abstract = {This workshop aims to design advanced empathic user interfaces for in-vehicle displays, particularly for high-level automated vehicles (SAE level 3 or higher). Incorporating model-based approaches for understanding human emotion regulation, it seeks to enhance the user-vehicle interaction. A unique aspect of this workshop is the integration of generative artificial intelligence (AI) tools in the design process. The workshop will explore generative AI's potential in crafting contextual responses and its impact on user experience and interface design. The agenda includes brainstorming on various driving scenarios, developing emotion-oriented intervention methods, and rapid prototyping with AI tools. The anticipated outcome includes practical prototypes of affective user interfaces and insights on the role of AI in designing human-machine interactions. Through this workshop, we hope to contribute to making automated driving more accessible and enjoyable. {\copyright} 2023 Owner/Author.},
 author = {Choe, M. and Bosch, E. and Dong, J. and Alvarez, I. and Oehl, M. and Jallais, C. and Alsaid, A. and Nadri, C. and Jeon, M.},
 title = {Emotion GaRage Vol. IV: Creating Empathic In-Vehicle Interfaces with Generative AIs for Automated Vehicle Contexts},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173674777&doi=10.1145%2f3581961.3609828&partnerID=40&md5=37010600cfec5f4cd85e1ba6908eb9ce},
 keywords = {Affective Computing;Artificial intelligence tools;Automated vehicles;Automation;ChatGPT;Design;Emotion;emotions;Empathic vehicle;empathic vehicles;interaction design;Model based approach;User interfaces;Vehicle display;Vehicle interface;Vehicles},
 pages = {234--236-234--236},
 publisher = {{Association for Computing Machinery}},
 doi = {10.1145/3581961.3609828}
}


@inproceedings{Chimuco.,
 abstract = {Mobile applications and devices became widely popular~in the second decade of the 21st century, mostly driven by technologies like cloud computing, Internet of Things (IoT), blockchain, and~big data, leading to and fostering very fast paced development cycles~of cloud-based mobile apps, which offer enhanced convenience~and accessibility for end users. However, significant security challenges remain, as cybersecurity is often overlooked in favor~of a shorter time-to-market. This paper presents the Security by Design for the Cloud and Mobile Ecosystem framework, consisting of a set of tools and underlying logic aimed at helping mobile application developers build secure applications in the specific mobile and cloud ecosystem. It features a modular architecture~and includes five main tools built in Python, and its outputs~are enhanced through the use of ChatGPT. The paper also discusses real-world applications and presents usability evaluation results, showing the framework is effective and meets its goals. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
 author = {Chimuco, F. T. and Sequeiros, J. B. F. and Freire, M. M. and In{\'a}cio, P. R. M. and Pra{\c{c}}a, I. and Bernardi, S. and P.R.M., In{\'a}cio},
 title = {Framework and Roadmap for Secure Design and Development of Applications in the Cloud and Mobile Ecosystem},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009211425&doi=10.1007%2f978-3-031-94855-8_12&partnerID=40&md5=1929c079c7109b84a5a572959f5e0870},
 keywords = {Application programs;Attack modeling;Best practice guidelines;Big Data;Cloud computing;Cloud security;Cloud-computing;Cryptography;Internet of Things;Mobile applications;Mobile cloud computing;Mobile computing;Mobile security;Mobile-computing;Network security;Requirements elicitation;Requirements engineering;secD4CloudMobile;Security;Security attack model;Security Attack Models;Security attacks;Security best practice guideline;Security Best Practice Guidelines;Security Best Practices;Security Framework;Security frameworks;Security mechanism;Security Mechanisms;Security Requirement Elicitation;Security requirements;Security systems;Security test specification and tool;Security tests;Security Tests Specification and Tools;Software Implementation;Software testing;Test specifications;Test tools},
 pages = {182--200-182--200},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-94855-8{\textunderscore }12}
}


@article{Chen.2024,
 abstract = {The quality of user interface (UI) design directly impacts product usability and user experience. Designers often face challenges related to consistency and accessibility during the UI design process, increasing cognitive load for users reducing efficiency. Despite awareness of these issues, they currently lack comprehensive knowledge and tools or automatic identification and resolution. To address this challenge, a comprehensive set of UI design evaluation criteria was proposed, covering five key aspects: color, text, layout, control, and icon, specifically targeting consistency and accessibility issues in UI design. Based on these evaluation criteria, a prompt template for evaluating UI consistency and accessibility was developed to enhance the accuracy of large language models (LLMs) like GPT-4 in UI evaluation tasks. Furthermore, a UI evaluation system based on the GPT-4 model was developed. This [26] deeply understood UI design content, automatically detected UI design issues according to the evaluation criteria, and provided targeted improvement suggestions to help designers optimize their UI designs. Experimental results demonstrated that using the prompt template significantly improved the accuracy of GPT-4 in UI evaluations. User studies indicated that employing this UI evaluation system in design practice can significantly enhance the quality of UI designs, thereby boosting product usability and user experience. This system provided designers with an automated UI evaluation tool, offering a new approach to enhancing UI design quality. {\copyright} 2024 Editorial of Board of Journal of Graphics. All rights reserved.},
 author = {Chen, X. and Shu, Y. and Wang, R. and Zhou, J. and Chen, W.},
 year = {2024},
 title = {Large language model powered UI evaluation system},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213856596&doi=10.11996%2fJG.j.2095-302X.2024061178&partnerID=40&md5=88e99621e21e6b346c181f240d0f1534},
 keywords = {accessibility;consistency;graphical user interface;Large Language Model;UI evaluation},
 pages = {1178--1187-1178--1187},
 volume = {45},
 number = {6},
 issn = {2095302X},
 journal = {Journal of Graphics},
 doi = {10.11996/JG.j.2095-302X.2024061178}
}


@inproceedings{Caslini.,
 abstract = {Smartifier is a conversational platform that leverages Large Language Models (LLMs) to help non-technical users design, implement, and manage smart objects. It addresses persistent challenges in the Internet of Things (IoT) domain, where the ``making community'' and End-User Development approaches have yet to empower novices fully. The system features two distinct chat interfaces: one dedicated to creating customized devices, and another for generating automation rules. Building on an iterative design model, Smartifier translates high-level, daily-life needs into hardware selections and automatically compiled software, ensuring correct APIs for seamless integration. A technical evaluation compared different ChatGPT-based models and temperature values, revealing an optimal configuration that curbs hallucinations and maximizes reliability. In a user study with 17 participants lacking ICT expertise, Smartifier achieved high correctness (averaging over 91{\%} across all tasks) and high scores regarding usability and user satisfaction. A thematic analysis of conversations revealed insights around user need expression, iterative negotiation, and system feedback. These findings will inform future refinements, especially regarding user experience design and the handling of advanced functionalities in complex real-world settings. While the study's sample size is limited, findings confirm that Smartifier effectively bridges complex technical tasks and everyday needs, reducing cognitive load and streamlining the creation of IoT solutions. These results highlight the potential of LLM-driven platforms to simplify and democratize technology development, suggesting new directions for future research on EUD and software generation for non-expert users. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
 author = {Caslini, G. and Gianotti, M. and Garzotto, F. and Santoro, C. and Schmidt, A. and Matera, M. and Bellucci, A.},
 title = {From User Needs to Smart Ecosystems Through LLMs: The Smartifier Case Study},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009001857&doi=10.1007%2f978-3-031-95452-8_5&partnerID=40&md5=07c561ce2f811e5ff4f888a71747bbc4},
 keywords = {Automation;Case-studies;Conversational Agents;Development approach;End-User Development;Human computer interaction;Internet of Things;IoT;Iterative methods;Language model;Large Language Model;LLMs;Non-technical users;Smart Objects;Smart space;Smart Spaces;User centered design;User experience;User interfaces;User need},
 pages = {80--98-80--98},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-95452-8{\textunderscore }5}
}


@article{Casheekar.2024,
 abstract = {This review paper offers an in-depth analysis of AI-powered virtual conversational agents, specifically focusing on OpenAI's ChatGPT. The main contributions of this paper are threefold: (i) an exhaustive review of prior literature on chatbots, (ii) a background of chatbots including existing chatbots/conversational agents like ChatGPT, and (iii) a UI/UX design analysis of prominent chatbots. Another contribution of this review is the comprehensive exploration of ChatGPT's applications across a multitude of sectors, including education, business, public health, and more. This review highlights the transformative potential of ChatGPT, despite the challenges it faces such as hallucination, biases in training data, jailbreaks, and anonymous data collection. The review paper then presents a comprehensive survey of prior literature reviews on chatbots, identifying gaps in the prior work and highlighting the need for further research in areas such as chatbot evaluation, user experience, and ethical considerations. The paper also provides a detailed analysis of the UI/UX design of prominent chatbots, including their conversational flow, visual design, and user engagement. The paper also identifies key future research directions, including mitigating language bias, enhancing ethical decision-making capabilities, improving user interaction and personalization, and developing robust governance frameworks. By solving these issues, we can ensure that AI chatbots like ChatGPT are used responsibly and effectively across a broad variety of applications. This review will be a valuable resource for researchers and practitioners in understanding the current state and future potential of AI chatbots like ChatGPT. {\copyright} 2024 Elsevier Inc.},
 author = {Casheekar, A. and Lahiri, A. and Rath, K. and Prabhakar, K. S. and Srinivasan, K.},
 year = {2024},
 title = {A contemporary review on chatbots, AI-powered virtual conversational agents, ChatGPT: Applications, open challenges and future research directions},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189750212&doi=10.1016%2fj.cosrev.2024.100632&partnerID=40&md5=7b682286ea2343c194b1e0dff4fba85b},
 keywords = {Artificial intelligence;Chatbots;ChatGPT;Computational intelligence;Conversational Agents;Data collection;Decision making;Design Analysis;Ethical technology;Future research directions;In-depth analysis;Literature reviews;Review papers;Training data;User interfaces},
 volume = {52},
 number = {100632},
 issn = {15740137},
 journal = {Computer Science Review},
 doi = {10.1016/j.cosrev.2024.100632}
}


@proceedings{Cannavo.2024,
 abstract = {Traditional graphic suites such as Blender and Autodesk Maya are widely used for 3D graphics creation, but their steep learning curve poses challenges for novice users. This complexity can make content creation time-consuming and mentally demanding. To address these issues, there is a growing interest in innovative approaches that integrate Artificial Intelligence (AI) tools into the traditional workflow. These tools promise to enhance user experience and facilitate tasks such as 3D modeling, automation, texturing, lighting setup, animation, and storytelling, This paper investigates the feasibility and potential strengths and weaknesses of integrating OpenAI's ChatGPT 3.5 with Blender, i.e., a prominent 3D modeling software. By combining advanced natural language processing (NLP) capabilities with the robust features of Blender, this work aims to enhance user interaction and facilitate the 3D design workflow. The paper proposes use cases that could benefit from the combination of these two technologies and warns about some limitations of this approach. {\copyright} 2024 IEEE.},
 year = {2024},
 title = {Exploring the Advantages and Challenges of Combining ChatGPT with Blender},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004788276&doi=10.1109%2fICIR64558.2024.10976975&partnerID=40&md5=c95190cefcb29a15446ae1d530bbd1d0},
 keywords = {3D graphics;3D modeling;3D models;3d-modeling;Animation;Autodesk mayas;Blender;ChatGPT;Language processing;Natural language processing;Natural languages;scripting},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 editor = {Cannavo, A. and Visconti, A. and Lamberti, F.},
 doi = {10.1109/ICIR64558.2024.10976975}
}


@article{DaSilvaH..2025b,
 abstract = {The proceedings contain 61 papers. The special focus in this conference is on Computer-Human Interaction Research and Applications. The topics include: How Different Blink Patterns of Pet Robots Evoke Feelings of Affection in People; arm in Motion: How Motion Modality and Erratic Behavior of a Robotic Arm Shape User Perception; An Examination of~Pre-school Children's Usage Behavior of~Augmented Reality: Traditional vs. AR-Assisted LEGO{\circledR} Building; Interviewing ChatGPT-Generated Personas to~Inform Design Decisions; an Experiment to Investigate Changes in Physiological Signals During Subtle Wind and Scent Presentation for Designing Subtle Notifications; Towards Multi-stakeholder Evaluation of~ML Models: A Crowdsourcing Study on~Metric Preferences in~Job-Matching System; current Design Practices in Applied Augmented Reality Research: A Methodological Review; emotion-Aware Interfaces: Empirical Methods for~Adaptive User Interface; bridging Medical Genetics, Genetic Counselling, and Patients: Proposing an Immersive, Interactive, and Holographic Health Information Platform with Evaluation Methods for Personalized Patient Education; why Do(n't) You Trust Us? Highlighting the~Importance of~Trust and~Transparency for~Designing B2B Platforms in~Electronics Manufacturing; enriched with Behaviour Theory Topic Guide Template for Digital Behaviour Change Interventions; evaluating Remote Communication Applications Using Student Usability Reviews; Enhancing EEG-Based User Verification with~a~Normalized Neural Network Ensemble Approach; systematic Literature Review of Gamification Design in Higher Education Programming Courses: Methodological Rigor Exposed; the Effect of~Progressive Disclosure in~the~Transparency of~Large Language Models; design and~Implementation of~a~Practice Record Visualization System Using Piano Performance Tracking Technology; User Issues and~Concerns in~Generative AI: A Mixed-Methods Analysis of~App Reviews; Caregiver Acceptability of~an~LLM-Powered Assistant Interface to~Improve Sleep Quality of~the~Elderly; user Experience and~Information Security Heuristics for~Digital Identity Wallets; how Can Heuristics Be Communicated?.},
 author = {{Da Silva H.}, Pl{\'a}cido and Cipresso, P.},
 year = {2025},
 title = {8th International Conference on Computer-Human Interaction Research and Applications, CHIRA 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006569161&partnerID=40&md5=20fa202ac181886699ad7ed4df91c799},
 volume = {2371 CCIS},
 issn = {18650929},
 journal = {Communications in Computer and Information Science}
}


@inproceedings{Brusilovsky.,
 abstract = {The primary goal of Recommender Systems is to suggest the most suitable items to a user, aligning them with the user's interests and needs. RSs are essential for modern e-commerce, helping users discover content and products by predicting suitable items based on their past behavior. However, their success isn't just about advanced algorithms. The design of the user interface and a good integration with the human decision-making process are equally crucial. A well-designed interface enhances the user experience and makes recommendations more effective, while a poor interface can lead to frustration. Recognizing this limitation, recent trends in Recommender Systems (RSs) are increasingly focusing on integrating Symbiotic Human-Machine Decision-Making models. These models aim to offer users a dynamic and persuasive interface that helps them better understand and engage with recommendations. This shift is a crucial step toward developing recommender systems that truly connect with users and offer a more enjoyable, trustworthy, explainable, and user-friendly experience. Although early efforts concentrated on creating systems that could proactively predict user preferences and needs, modern RSs also emphasize the importance of providing users with control and transparency over their recommendations. Finding the right balance between proactivity and user control is essential to ensure that the system supports users without being too intrusive, thus improving their overall satisfaction. As Large Language Models (LLMs) become more integrated into recommender systems, the importance of user-centric interfaces and a deep understanding of decision-making becomes even more critical. Effective integration of LLMs requires interfaces that are both visually and cognitively engaging. These aspects are the main discussion topics of the Joint Workshop on Interfaces and Human Decision Making for Recommender Systems at RecSys'24. In this summary, we introduce the motivation and perspective of the workshop, review its history, and discuss the most critical issues that deserve attention for future research directions. {\copyright} 2024 Copyright held by the owner/author(s).},
 author = {Brusilovsky, P. and Gemmis, M. and Felfernig, A. and Polignano, M. and Semeraro, G. and Willemsen, M. C.},
 title = {11th Joint Workshop on Interfaces and Human Decision Making for Recommender Systems (IntRS'24)},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210497185&doi=10.1145%2f3640457.3687098&partnerID=40&md5=47b69ec053cfb42c07f0689c132368cc},
 keywords = {Cognitive systems;Computer interaction;Decision bias;Decision Biases;Decision support systems;Evaluation Methods;Human Decision Making;Human decision-making;Human engineering;Human-Computer Interaction;Language model;Large Language Model;Large language models;LLMs;Man machine systems;Recommender systems;Symbiotic-AI;Symbiotics;User interfaces},
 pages = {1253--1257-1253--1257},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3640457.3687098}
}


@inproceedings{Biyani.,
 abstract = {Evaluating conversational assistants, such as GitHub Copilot Chat, poses a significant challenge for tool builders in the domain of Software Engineering. These assistants rely on language models and chat-based user experiences, rendering their evaluation with respect to the quality of the Human-AI conversations complicated. Existing general-purpose metrics for measuring conversational quality found in literature are inadequate for appraising domain-specific dialogues due to their lack of contextual sensitivity. In this paper, we present RUBICON, a technique for evaluating domain-specific Human-AI conversations. RUBICON leverages large language models to generate candidate rubrics for assessing conversation quality and employs a selection process to choose the subset of rubrics based on their performance in scoring conversations. In our experiments, RUBICON effectively learns to differentiate conversation quality, achieving higher accuracy and yield rates than existing baselines. {\copyright} 2024 Owner/Author.},
 author = {Biyani, P. and Bajpai, Y. and Radhakrishna, A. and Soares, G. and Gulwani, S. and Adams, B. and Zimmermann, T. and Ozkaya, I. and Lin, D. and Zhang, J. M.},
 title = {RUBICON: Rubric-Based Evaluation of Domain-Specific Human AI Conversations},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199862151&doi=10.1145%2f3664646.3664778&partnerID=40&md5=f9b178be0e3799985251112d8dc738c2},
 keywords = {AI-assisted Programming;Computational linguistics;Conversation Evaluation;Conversational AI;Domain specific;Evaluation Metrics;Human-AI Interaction;Language model;performance;Quality control;Software engineering;User interfaces;User Satisfaction;Users' experiences;Users' satisfactions},
 pages = {161--169-161--169},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3664646.3664778}
}


@proceedings{Bisante.2024,
 abstract = {This paper introduces CWGPT, a ChatGPT-4-based tool designed for Cognitive Walkthrough (CW) inspired evaluations of web interfaces. The primary goal is to assist users, particularly students and inexperienced designers, in evaluating web interfaces. Our tool, operating as a conversational agent, provides detailed evaluations of a user-specified task by intelligently guessing the subtasks and actions required to accomplish them, answering the standard CW questions, and providing helpful feedback and practical suggestions to improve the usability of the analyzed interface. For our study, we selected a group of web applications designed by students from a Web and Software Architecture course. We compare the outcome of the CWs we executed on ten web apps against the corresponding CWGPT analyses. We then describe the study we conducted involving five author-students to assess the tool's efficacy in helping them recognize and solve usability issues. In addition to introducing a novel adaptation of ChatGPT, the outcomes of the described experience underscore the promising potential of AI in usability evaluations. {\copyright} 2024 Owner/Author.},
 year = {2024},
 title = {Enhancing Interface Design with AI: An Exploratory Study on a ChatGPT-4-Based Tool for Cognitive Walkthrough Inspired Evaluations},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195382725&doi=10.1145%2f3656650.3656676&partnerID=40&md5=3b4edad92d9079a7cc6c28a441bd4402},
 keywords = {AI;Application programs;ChatGPT;Cognitive Walkthrough;Conversational Agents;Exploratory studies;GPT;HCI;Interface designs;Students;Subtask;Usability Engineering;Web application;Web Applications;Web interface},
 publisher = {{Association for Computing Machinery}},
 editor = {Bisante, A. and Datla, V. S. V. and Panizzi, E. and Trasciatti, G. and Zeppieri, S.},
 doi = {10.1145/3656650.3656676}
}


@article{Bandi.2023,
 abstract = {Generative artificial intelligence (AI) has emerged as a powerful technology with numerous applications in various domains. There is a need to identify the requirements and evaluation metrics for generative AI models designed for specific tasks. The purpose of the research aims to investigate the fundamental aspects of generative AI systems, including their requirements, models, input-output formats, and evaluation metrics. The study addresses key research questions and presents comprehensive insights to guide researchers, developers, and practitioners in the field. Firstly, the requirements necessary for implementing generative AI systems are examined and categorized into three distinct categories: hardware, software, and user experience. Furthermore, the study explores the different types of generative AI models described in the literature by presenting a taxonomy based on architectural characteristics, such as variational autoencoders (VAEs), generative adversarial networks (GANs), diffusion models, transformers, language models, normalizing flow models, and hybrid models. A comprehensive classification of input and output formats used in generative AI systems is also provided. Moreover, the research proposes a classification system based on output types and discusses commonly used evaluation metrics in generative AI. The findings contribute to advancements in the field, enabling researchers, developers, and practitioners to effectively implement and evaluate generative AI models for various applications. The significance of the research lies in understanding that generative AI system requirements are crucial for effective planning, design, and optimal performance. A taxonomy of models aids in selecting suitable options and driving advancements. Classifying input-output formats enables leveraging diverse formats for customized systems, while evaluation metrics establish standardized methods to assess model quality and performance. {\copyright} 2023 by the authors.},
 author = {Bandi, A. and {Adapa, P. V. S. R.} and {Kuchi, Y. E. V. P. K.}},
 year = {2023},
 title = {The Power of Generative AI: A Review of Requirements, Models, Input-Output Formats, Evaluation Metrics, and Challenges},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169062394&doi=10.3390%2ffi15080260&partnerID=40&md5=371a8a3f70afb5c8dc6038278a12c1b2},
 keywords = {AIGC;AIGC model;AIGC models;ChatGPT;generative adversarial networks;generative AI models;generative AI survey;Generative artificial intelligence model;Generative artificial intelligence survey;GPT-3;GPT-4;Intelligence models;Quality control;Taxonomies;Transformer;Transformers;User experience;Users' experiences},
 volume = {15},
 number = {260},
 issn = {19995903},
 journal = {Future Internet},
 doi = {10.3390/fi15080260}
}


@article{Bale.2023,
 abstract = {Through the use of natural language processing (NLP) to analyze and synthesize data, ChatGPT has the potential to advance Software Engineering (SE) studies. Yet, it may provide moral challenges such as the possibility for data bias, leakage of private information, and the compromise of sensitive information. Utilizing ChatGPT, we highlight such current developments in SE. We also explore ChatGPT's potential outside of the gaming industry. Finally, we suggest leveraging ChatGPT to simplify UI and UX interaction. This article will provide an established protocol for using ChatGPT applications within SE investigation while keeping ethical concerns in mind. {\copyright} 2023, Ismail Saritas. All rights reserved.},
 author = {Bale, A. S. and Vada, Y. R. and Oshiojum, B. E. and Lakkineni, U. K. and Rao, C. and Venkatesh, K. and Rani, I.},
 year = {2023},
 title = {ChatGPT in Software Development: Methods and Cross-Domain Applications},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171329846&partnerID=40&md5=4283848fd2a7f64e2f54575369e84b6a},
 keywords = {AI;Automation;Generative images;Generative videos;UI;UX},
 pages = {636--643-636--643},
 volume = {11},
 number = {9s},
 issn = {21476799},
 journal = {International Journal of Intelligent Systems and Applications in Engineering}
}


@inproceedings{BalazsNeszlenyi.,
 abstract = {As user interface technologies evolve, integrating voice and text commands becomes crucial for enhancing interaction with operating systems. AssistantGPT leverages OpenAI's GPT API to enable natural language-driven system functionalities, improving productivity through precise task interpretation and execution. The application supports a diverse range of operations, including web searches, API interactions via OpenAPI schemas, voice conversations, and command execution through the shell, demonstrating adaptability and scalability across various use cases and environments. Implemented using Electron.js, React, Python, and FastAPI, AssistantGPT demonstrates high efficiency, reliability, and user-friendliness. By bridging complex system functionalities and intuitive user interfaces, AssistantGPT significantly advances human-computer interaction, offering practical solutions for both professional and personal applications. {\copyright} 2024 IEEE.},
 author = {{Balazs Neszlenyi}, K. and Milos, A. and Kiss, A.},
 title = {AssistantGPT: Enhancing User Interaction with LLM Integration},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210890681&doi=10.1109%2fSISY62279.2024.10737548&partnerID=40&md5=29cce2eb86deed982a48b10b1fbe2f9c},
 keywords = {accessibility;Application programming interfaces (API);Automation;Command and Control Systems;Command-and-control systems;Computer interaction;Human computer interaction;Human-Computer Interaction;Information retrieval;Job analysis;Language model;Language processing;Large Language Model;Large language models;Man machine systems;Modeling languages;Natural language processing;Natural language processing systems;Natural languages;Problem oriented languages;System functionality;Systems analysis;User experience;User interfaces;Users' experiences;Voice Recognition},
 pages = {619--624-619--624},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/SISY62279.2024.10737548}
}


@inproceedings{AshishTarun.,
 abstract = {Conversational AI technologies have transformed human- machine interactions in educational settings, such as the SRM Institute of Science and Technology, where intelligent chatbots play pivotal roles in supporting students, faculty, and staff. This research presents a sophisticated chatbot system tailored for the SRM Institute, leveraging cutting-edge technologies like the LangChain framework and Large Language Models (LLMs), including OpenAI's GPT-3.5 Turbo, to enhance language understanding and generation capabilities. The methodology emphasizes meticulous data preparation, including data collection, preprocessing, and embedding creation, integrated with vector databases to establish a robust knowledge base. The chatbot's user interface, built with Flask, ensures an intuitive user experience with a visually appealing and responsive layout. Evaluation results demonstrate a 95{\%} accuracy rate and high reliability in handling diverse user inquiries, highlighting the chatbot's capacity to manage growing volumes of queries while maintaining consistent accuracy. These outcomes underscore significant improvements in user engagement and satisfaction, marking a substantial advancement in educational chatbot technology. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
 author = {{Ashish Tarun}, R. and Priyadarshini, B. and Sneha, M. and Akila, K. and Sivakumar, P. D. and Pasupathi, C. and Balakrishnan, P. and Ramachandran, R.},
 title = {Leveraging LangChain Framework and Large Language Models for Conversational Chatbot Development},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85219189838&doi=10.1007%2f978-3-031-82386-2_19&partnerID=40&md5=9937d6f30863826142fb77ad82bc0b1b},
 keywords = {AI Technologies;Chatbot system;Chatbots;Conversational AI;Educational settings;Human machine interaction;LangChain framework;Language model;Large Language Model;Large Language Models(LLMs);OpenAI's GPT-3.5 Turbo},
 pages = {244--255-244--255},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-82386-2{\textunderscore }19}
}


@article{Angyal.2025,
 abstract = {Background: The rapid advancement of artificial intelligence, driven by Generative Pre-trained Transformers (GPT), has transformed natural language processing. Prompt engineering plays a key role in guiding model outputs effectively. Our primary objective was to explore the possibilities and limitations of a custom GPT, developed via prompt engineering, as a patient education tool, which delivers publicly available information through a user-friendly design that facilitates more effective access to cervical cancer screening knowledge. Method: The system was developed using the OpenAI GPT-4 model and Python programming language, with the interface built on Streamlit for cloud-based accessibility and testing. It initially presented questions to testers for preliminary assessment. For cervical cancer-related information, we referenced medical guidelines. Iterative testing optimized the prompts for quality and relevance; techniques like context provision, question chaining, and prompt-based constraints were used. Human-in-the-loop and two independent medical doctor evaluations were employed. Additionally, system performance metrics were measured. Result: The web application was tested 115 times over a three-week period in 2024, with 87 female (76{\%}) and 28 male (24{\%}) participants. A total of 112 users completed the user experience questionnaire. Statistical analysis showed a significant association between age and perceived personalization (p = 0.047) and between gender and system customization (p = 0.037). Younger participants reported higher engagement, though not significantly. Females valued guidance on screening schedules and early detection, while males highlighted the usefulness of information regarding HPV vaccination and its role in preventing HPV-related cancers. Independent evaluations by medical doctors demonstrated consistent assessments of the system's responses in terms of accuracy, clarity, and usefulness. Discussion: While the system demonstrates potential to enhance public health awareness and promote preventive behaviors, encouraging individuals to seek information on cervical cancer screening and HPV vaccination, its conversational capabilities remain constrained by the inherent limitations of current language model technology. Conclusions: Although custom GPTs can not substitute a healthcare consultations, these tools can streamline workflows, expedite information access, and support personalized care. Further research should focus on conducting well-designed randomized controlled trials to establish definitive conclusions regarding its impact and reliability. Clinical trial number: Not applicable. {\copyright} The Author(s) 2025.},
 author = {Angyal, V. and Bertalan, {\'A}. and Domj{\'a}n, P. and Dinya, E.},
 year = {2025},
 title = {Exploring the possibilities and limitations of customized large language model to support and improve cervical cancer screening},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009609973&doi=10.1186%2fs12911-025-03088-3&partnerID=40&md5=b272eaa0d0235390aa9b74ba81eb21ac},
 keywords = {Artificial intelligence;Cervical cancer;Custom GPT;Natural language processing;Prevention;Prompt engineering},
 volume = {25},
 number = {242},
 issn = {14726947},
 journal = {BMC Medical Informatics and Decision Making},
 doi = {10.1186/s12911-025-03088-3}
}


@inproceedings{Andrews.,
 abstract = {Traditionally, sports commentators provide viewers with diverse information, encompassing in-game developments and player performances. Yet young adult football viewers increasingly use mobile devices for deeper insights during football matches. Such insights into players on the pitch and performance statistics support viewers' understanding of game stakes, creating a more engaging viewing experience. Inspired by commentators' traditional roles and to incorporate information into a single platform, we developed AiCommentator, a Multimodal Conversational Agent (MCA) for embedded visualization and conversational interactions in football broadcast video. AiCommentator integrates embedded visualization, either with an automated non-interactive or with a responsive interactive commentary mode. Our system builds upon multimodal techniques, integrating computer vision and large language models, to demonstrate ways for designing tailored, interactive sports-viewing content. AiCommentator's event system infers game states based on a multi-object tracking algorithm and computer vision backend, facilitating automated responsive commentary. We address three key topics: evaluating young adults' satisfaction and immersion across the two viewing modes, enhancing viewer understanding of in-game events and players on the pitch, and devising methods to present this information in a usable manner. In a mixed-method evaluation (n=16) of AiCommentator, we found that the participants appreciated aspects of both system modes but preferred the interactive mode, expressing a higher degree of engagement and satisfaction. Our paper reports on our development of AiCommentator and presents the results from our user study, demonstrating the promise of interactive MCA for a more engaging sports viewing experience. Systems like AiCommentator could be pivotal in transforming the interactivity and accessibility of sports content, revolutionizing how sports viewers engage with video content. {\copyright} 2024 Owner/Author.},
 author = {Andrews, P. and Nordberg, O. E. and {Zubicueta Portales}, S. and Borch, N. and Guribye, F. and Fujita, K. and Fjeld, M.},
 title = {AiCommentator: A Multimodal Conversational Agent for Embedded Visualization in Football Viewing},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190975308&doi=10.1145%2f3640543.3645197&partnerID=40&md5=abe893eab477a5941b653c4942a530fc},
 keywords = {Computer games;Computer Vision;Conversational user interface;Deep Learning;Embedded Visualization;Game development;Game players;Human computer interaction;Human-Computer Interaction;Multimodal Conversational Agent;Multimodal conversational agents;Multi-Object Tracking;performance;Sports;Tracking (position);Usability Testing;User interfaces;Visualization;Young adults},
 pages = {14--34-14--34},
 publisher = {{Association for Computing Machinery}},
 doi = {10.1145/3640543.3645197}
}


@inproceedings{Anastasiou.,
 abstract = {Augmented Reality (AR) technology has been proven a valuable tool for establishing seamless human-machine interaction systems in manufacturing. Considering the constraints and best practices of past implementations, this paper provides a set of guidelines for designing user-centric AR applications, focusing on intuitive human-machine interaction. The proposed methodology includes smart interfaces, intelligent interaction techniques, and AI-based large language models (LLMs) for natural language communication. Additionally, AI-driven vision systems are proposed for identifying user actions and providing feedback automatically to the machine system. The guidelines apply to all AR frameworks, aiming to reduce operational effort while enhancing user experience. {\copyright} 2025 Elsevier B.V.. All rights reserved.},
 author = {Anastasiou, E. and Gkouvas, K. and Papavasileiou, A. and Michalos, G. and Makris, S. and Thiede, S. and Damgrave, R. and Vanekar, T. and Lutters, E.},
 title = {A User-Centric AI-Enhanced Approach to AR frameworks in Manufacturing},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009409219&doi=10.1016%2fj.procir.2025.02.235&partnerID=40&md5=0d7f91d81627a03ca1deafa786489ccc},
 keywords = {Artificial intelligence;Augmented reality;Augmented reality applications;Augmented reality technology;Best practices;Human computer interaction;Human machine interaction;Human machine interaction system;Language model;Large Language Model;Large language models;Man machine systems;Manufacturing Systems;Smart interface;Smart manufacturing;User centered design;User interfaces;User-Centered;User-centred;User-centric},
 pages = {1071--1076-1071--1076},
 publisher = {{Elsevier B.V}},
 doi = {10.1016/j.procir.2025.02.235}
}


@article{Alonso.2023,
 abstract = {The proceedings contain 32 papers. The special focus in this conference is on International Conference on Theory and Practice of Digital Libraries. The topics include: On Retraction Cascade? Citation Intention Analysis as a Quality Control Mechanism in Digital Libraries; using Semi-automatic Annotation Platform to~Create Corpus for~Argumentative Zoning; CORE-GPT: Combining Open Access Research and~Large Language Models for~Credible, Trustworthy Question Answering; a Robust Approach for Hybrid Personalized Recommender Systems; readability Measures as~Predictors of~Understandability and~Engagement in~Searching to~Learn; classification of~Visualization Types and~Perspectives in~Patents; it's Not Just GitHub: Identifying Data and~Software Sources Included in~Publications; a Graph Neural Network Approach for~Evaluating Correctness of~Groups of~Duplicates; synthesizing Web Archive Collections into~Big Data: Lessons from~Mining Data from~Web Archives; a Multilingual Dashboard to~Analyse Intercultural Knowledge Circulation; a Comparison of~Automated Journal Recommender Systems; Making PDFs Accessible for~Visually Impaired Users (and Findable for~Everybody Else); multi-view Graph-Based Text Representations for~Imbalanced Classification; Large Synthetic Data from~the~ar \textgreek{q} iv for~OCR Post Correction of~Historic Scientific Articles; from Textual to Visual Image Searching: User Experience of Advanced Image Search Tool; ranking for~Learning: Studying Users' Perceptions of~Relevance, Understandability, and~Engagement; image Modification Modeled as~a~Storytelling Process; From ISAD(G) to~Linked Data Archival Descriptions; detection of~Redacted Text in~Legal Documents; the First Tile for the Digital Onomastic Repertoire of the French Medieval Romance: Problems and Perspectives; known by~the~Company It Keeps: Proximity-Based Indexing for~Physical Content in~Archival Repositories; fostering Access to Cultural Heritage Knowledge: Iterative Design for the Visit of Historical Monuments; persistent Identifier Usage by Cultural Heritage Institutions: A Study on the Europeana.eu Dataset; aspect-Driven Structuring of~Historical Dutch Newspaper Archives.},
 author = {Alonso, O. and Cousijn, H. and Silvello, G. and Marchesin, S. and Marrero, M. and {Teixeira Lopes}, C.},
 year = {2023},
 title = {27th International Conference on Theory and Practice of Digital Libraries, TPDL 2023},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174636639&partnerID=40&md5=a5c04568c258591876e5b540bdd31858},
 volume = {14241 LNCS},
 journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}


@article{Algahtani.2024,
 abstract = {This study provides a comprehensive analysis of AI-based educational tools, focusing on their impact on user experience and education. It explores the capabilities of AI tools in transforming the teaching and learning process through specialized AI tool-based learning, intelligent educational AI systems, Automation in the grading process, and predictive analytics. This research helps investigate the role of large language models (LLMs) in educational assessment, including test planning, item generation, test administration, and scoring. It involves teachers with STEM-related teaching experience who were introduced to an AI-enhanced scaffolding system for scientific writing. The study also includes a systematic review of AI applications in higher education, highlighting the ethical implications, challenges, and risks associated with AI in education. The findings provide a deep dive for educators, management, and stakeholders working on maximizing the outputs of AI in education while eliminating the associated risks. The study emphasizes the importance of understanding teachers' attitudes and experiences with AI in education to effectively integrate AI into teaching and learning practices. It also highlights the need to further explore ethical and educational approaches to applying AI in education. The research underscores the benefits and challenges of AI integration in education, emphasizing the need for transparent and ethical AI algorithms, personalized and adaptive assessment approaches, and the importance of human judgment in AI-powered education. {\copyright} Little Lion Scientific.},
 author = {Algahtani, A.},
 year = {2024},
 title = {A COMPARATIVE STUDY OF AI-BASED EDUCATIONAL TOOLS: EVALUATING USER INTERFACE EXPERIENCE AND EDUCATIONAL IMPACT},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188191183&partnerID=40&md5=c9c129240fe881684f80fbaa0669730b},
 keywords = {AI In Education;Availability;Educational Tools;Reliability;Skills},
 pages = {1746--1758-1746--1758},
 volume = {102},
 number = {5},
 issn = {19928645},
 journal = {Journal of Theoretical and Applied Information Technology}
}


@inproceedings{Bong.,
 abstract = {Surveys are essential in various fields to gather feedback and information. Efficient data processing is thus crucial for quick, informed decision-making. As the volume of data continues to grow, automation in survey analysis has become increasingly important. This paper proposes a new software tool, SurveySense, which aims to streamline the survey analysis process. A~study involving 26 participants was also conducted to evaluate the~tool across six dimensions - Insight Quality, Efficiency, Consistency, User satisfaction and Trustworthiness, Human-AI Collaboration~and Usability and Interaction. Results showed that SurveySense would~be a helpful assistant for survey analysis but human inputs remain crucial in the process to further refine the AI-generated insights to align with personal goals. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
 author = {Bong, J. H. and Cai, C. and Toh, S. Y. and Liu, S. and Fan, X. and Sottilare, R. A. and Schwarz, J.},
 title = {Interactive Sensemaking with SurveySense: Enhancing Survey Insights Through Human-AI Collaboration on an LLM-Based Platform},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007853443&doi=10.1007%2f978-3-031-92970-0_11&partnerID=40&md5=8a5d41879b0f960ccc1cc1c0113568a4},
 keywords = {Ambient intelligence;Analysis process;Automated Survey Analysis;Automated survey analyze;Decisions makings;Human-AI Collaboration;Informed decision;Sense making;Software-tools;Stockpile surveys;Survey analysis;Usability Engineering;Usability Evaluation;Users' satisfactions},
 pages = {153--170-153--170},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-92970-0{\textunderscore }11}
}


@article{Degen.2024,
 abstract = {The proceedings contain 90 papers. The special focus in this conference is on Artificial Intelligence in HCI. The topics include: What Makes People Say Thanks to~AI; PyFlowML: A Visual Language Framework to~Foster Participation in~ML-Based Decision Making; A Three-Year Analysis of~Human Preferences in~Delegating Tasks to~AI; qualitative User-Centered Requirements Analysis for~a~Recommender System for~a~Project Portfolio Platform in~Higher Education Institutions; foreword; surveying Computational Theory of~Mind and~a~Potential Multi-agent Approach; What Is the~Focus of~XAI in~UI Design? Prioritizing UI Design Principles for~Enhancing XAI User Experience; Evaluation of~Generative AI-Assisted Software Design and~Engineering: A User-Centered Approach; time Series Representation Learning: A Survey on~Deep Learning Techniques for~Time Series Forecasting; uncertainty of Information Applied to Network Monitoring Metrics; semi-supervised Sorting via~Deep Feature Extraction and~Density Based Clustering with~User Feedback; towards a~Framework for~Interdisciplinary Studies in~Explainable Artificial Intelligence; exploring the~Impact of~Explainability on~Trust and~Acceptance of~Conversational Agents - A Wizard of~Oz Study; WisCompanion: Integrating the~Socratic Method with~ChatGPT-Based AI for~Enhanced Explainability in~Emotional Support for~Older Adults; how to~Explain It to~System Testers?; A Multidisciplinary Heuristic Evaluation of~AI-Enhanced Web Tools: Insights and~Implications for~Legal Contract Management Systems; Evaluating the~Effectiveness of~the~Peer Data Labelling System (PDLS); preface; reducing Human Annotation Effort Using Self-supervised Learning for~Image Segmentation; Enhancing Historical Understanding in~School Students: Designing a~VR Application with~AI-Animated Characters; Examining User Perceptions to Vocal Interaction with AI Bots in Virtual Reality and Mobile Environments: A Focus on Foreign Language Learning and Communication Dynamics; Human-Aligned GAI Driven by Conceptual Knowledge: System, Framework, and Co-creation; iterative Visual Interaction with~Latent Diffusion Models; evidential Representation Proposal for~Predicate Classification Output Logits in~Scene Graph Generation.},
 author = {Degen, H. and Ntoa, S.},
 year = {2024},
 title = {5th International Conference on Artificial Intelligence in HCI, AI-HCI 2024, held as part of the 26th HCI International Conference, HCII 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196175152&partnerID=40&md5=9fd70c107a18fbbb6b0e415af061749f},
 volume = {14734 LNAI},
 journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}


@article{Degen.2024b,
 abstract = {The proceedings contain 90 papers. The special focus in this conference is on Artificial Intelligence in HCI. The topics include: What Makes People Say Thanks to~AI; PyFlowML: A Visual Language Framework to~Foster Participation in~ML-Based Decision Making; A Three-Year Analysis of~Human Preferences in~Delegating Tasks to~AI; qualitative User-Centered Requirements Analysis for~a~Recommender System for~a~Project Portfolio Platform in~Higher Education Institutions; foreword; surveying Computational Theory of~Mind and~a~Potential Multi-agent Approach; What Is the~Focus of~XAI in~UI Design? Prioritizing UI Design Principles for~Enhancing XAI User Experience; Evaluation of~Generative AI-Assisted Software Design and~Engineering: A User-Centered Approach; time Series Representation Learning: A Survey on~Deep Learning Techniques for~Time Series Forecasting; uncertainty of Information Applied to Network Monitoring Metrics; semi-supervised Sorting via~Deep Feature Extraction and~Density Based Clustering with~User Feedback; towards a~Framework for~Interdisciplinary Studies in~Explainable Artificial Intelligence; exploring the~Impact of~Explainability on~Trust and~Acceptance of~Conversational Agents - A Wizard of~Oz Study; WisCompanion: Integrating the~Socratic Method with~ChatGPT-Based AI for~Enhanced Explainability in~Emotional Support for~Older Adults; how to~Explain It to~System Testers?; A Multidisciplinary Heuristic Evaluation of~AI-Enhanced Web Tools: Insights and~Implications for~Legal Contract Management Systems; Evaluating the~Effectiveness of~the~Peer Data Labelling System (PDLS); preface; reducing Human Annotation Effort Using Self-supervised Learning for~Image Segmentation; Enhancing Historical Understanding in~School Students: Designing a~VR Application with~AI-Animated Characters; Examining User Perceptions to Vocal Interaction with AI Bots in Virtual Reality and Mobile Environments: A Focus on Foreign Language Learning and Communication Dynamics; Human-Aligned GAI Driven by Conceptual Knowledge: System, Framework, and Co-creation; iterative Visual Interaction with~Latent Diffusion Models; evidential Representation Proposal for~Predicate Classification Output Logits in~Scene Graph Generation.},
 author = {Degen, H. and Ntoa, S.},
 year = {2024},
 title = {5th International Conference on Artificial Intelligence in HCI, AI-HCI 2024, held as part of the 26th HCI International Conference, HCII 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196310333&partnerID=40&md5=edee6b85077e31bd4407f6a6ce93897c},
 volume = {14735 LNAI},
 journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}


@article{Degen.2024c,
 abstract = {The proceedings contain 32 papers. The special focus in this conference is on Artificial Intelligence in HCI. The topics include: Using a~LLM-Based Conversational Agent in~the~Social Robot Mini; a Proposal to~Extend the~Modeling Language for~Interaction as~Conversation for~the~Design of~Conversational Agents; optimizing Conversational Commerce Involving Multilingual Consumers Through Large Language Models' Natural Language Understanding Abilities; A Map of~Exploring Human Interaction Patterns with~LLM: Insights into~Collaboration and~Creativity; The Use of~Large Language Model in~Code Review Automation: An Examination of~Enforcing SOLID Principles; LLM Based Multi-agent Generation of~Semi-structured Documents from~Semantic Templates in~the~Public Administration Domain; enabling Human-Centered Machine Translation Using Concept-Based Large Language Model Prompting and Translation Memory; enhancing Large Language Models Through External Domain Knowledge; ChatGPT and~Language Translation; large Language Models for Tracking Reliability of Information Sources; the Heuristic Design Innovation Approach for~Data-Integrated Large Language Model; FER-Pep: A Deep Learning Based Facial Emotion Recognition Framework for~Humanoid Robot Pepper; you Got the~Feeling: Attributing Affective States to~Dialogical Social Robots; enhancing Usability of~Voice Interfaces for~Socially Assistive Robots Through Deep Learning: A German Case Study; enhancing User Experience: Designing Intuitive Interfaces for Sumo Robot Operations; Adaptive Robotics: Integrating Robotic Simulation, AI, Image Analysis, and Cloud-Based Digital Twin Simulation for Dynamic Task Completion; Building Information Model (BIM) and Robotic Systems Integration for Construction: A Comprehensive Workflow Analysis and Future Perspectives; emphasizing with~a~Robot with~a~Personality; embodying Intelligence: Humanoid Robot Advancements and Future Prospects; people and~Technology: An Investigation of~the~Adoption of~Artificial Intelligence in~the~Kinesiology Context; Logical Interference: Using AI to Correct Flaws in Human Judgment; text Analysis Software Using Topic Modeling Techniques for~the~Extraction of~Knowledge from~Cases Related to~Vulnerability and~Access to~Justice.},
 author = {Degen, H. and Ntoa, S.},
 year = {2024},
 title = {5th International Conference on Artificial Intelligence in HCI, AI-HCI 2024, held as part of the 26th International Conference on Human-Computer Interaction, HCI International 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195462297&partnerID=40&md5=99422dfcb8af2fd67ac8407aeb0f3633},
 volume = {14736 LNAI},
 journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}
}


@inproceedings{Kuo.,
 abstract = {In a changing and connected world, people are surrounded by an increasing number of smart devices in a complex system. Intelligent technology has revolutionised the way we interact with these devices, and has resulted in improved user experiences through the integration of physical status and digital applications. However, this transition has also presented new challenges and demands for transdisciplinary adaptation in traditional approaches to design education. Many existing design methods and frameworks have not kept pace with the level of automation now seen in intelligent interactive products, nor have they addressed human-machine interdependence in a system-thinking context. The aim of this study is to gain insights from the younger generation of design students to inform the development of a more suitable design course. Using smart home products as the case scenario, 39 industrial design students evaluated the user experience with the products through hands-on interaction. The individual product reviews of the robot cleaner, smart speaker and smart lightbulb were then analysed and consolidated. Thus, this study contributes to the elucidation of design students' perspectives on intelligent user interfaces. Furthermore, a comparative analysis of user insights was conducted through peer assessments, focus groups and large language models to explore their potential and difference in terms of the design process. Overall, the goal of this analysis is to advance the field of design practice and education. {\copyright} 2023 The Authors.},
 author = {Kuo, J.-Y. and Xia, Z. and Cooper, A. and Koomsap, P. and Stjepandic, J.},
 title = {Exploring Intelligent User Interfaces from Design Students' Perspectives on Smart Home Products Through Peer Assessment, Focus Group and ChatGPT},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184295754&doi=10.3233%2fATDE230608&partnerID=40&md5=4bec51ebb4db7457c9d332c6f1c38e18},
 keywords = {Automation;Curricula;Design Education;Digital devices;Education computing;Focus groups;Home products;Intelligent technology;Intelligent User Interfaces;Peer assessment;Product design;Smart devices;Smart homes;Student perspectives;Students;Systems thinking;User interfaces;Users' experiences},
 pages = {161--170-161--170},
 publisher = {{IOS Press BV}},
 doi = {10.3233/ATDE230608}
}


@article{Kruchten.2024,
 abstract = {The proceedings contain 22 papers. The special focus in this conference is on Agile Software Development. The topics include: Towards a X-as-a-Service Application in Industrial Laundry - A Case Study of Information Requirement Engineering in Emerging Data Ecosystems; software Startup Ecosystem in Namibia; industry Expectations for~Product Ops Professionals: A Review of~Job Advertisements; unveiling the~Spectrum of~Hybrid Work in~Software Engineering: Research Directions; defining a Remote Work Policy: Aligning Actions and Intentions; business Development in~Large-Scale Agile Software Development: Barriers and~Enablers; ChatGPT as~a~Tool for~User Story Quality Evaluation: Trustworthy Out of~the~Box?; Survey of~AI Tool Usage in~Programming Course: Early Observations; Turning Large Language Models into~AI Assistants for~Startups Using Prompt Patterns; enhancing Agile Software Development Sustainability Through the Integration of User Experience and Gamification; ChatGPT as~a~Fullstack Web Developer - Early Results; reviewing Crypto-Agility and~Quantum Resistance in~the~Light of~Agile Practices; empirical Investigation of Quantum Computing on Solving Complex Problems; Sustainable IT in an Agile DevOps Setup Leads to a Shift Left in Sustainability Engineering; improving the~Implementation of~Microservice-Based Systems with~Static Code Analysis; towards an~Architecture-Centric Methodology for~Migrating to~Microservices; being Agile in~a~Data Science Project; the Future of Work: Agile in a Hybrid World; organizational Debt in~Large-Scale Hybrid Agile Software Development: A Case Study on~Coordination Mechanisms; the Know-How of~Agile Retrospectives in~Software Startups.},
 author = {Kruchten, P. and Gregory, P.},
 year = {2024},
 title = {workshops presented at 23rd International Conferences on Agile Software Development, XP 2022 and 24th International Conferences on Agile Software Development, XP 2023},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182005065&partnerID=40&md5=d01a03e73129169357f5c2e826e1cdea},
 volume = {489 LNBIP},
 issn = {18651348},
 journal = {Lecture Notes in Business Information Processing}
}


@proceedings{Krogstie.2024,
 abstract = {Educating the next generation of students on pathways toward sustainability is important and highly relevant for various disciplines, including HCI and CSCW. HCI research has contributed much to the field of sustainability, though mainly taking user-centric and environmental perspectives, missing a holistic view of sustainability. By incorporating sustainability goals into design and development processes, students can learn that they can have a significant impact and improve the longevity and durability of digital tools. This workshop will present and explore the SusAF framework as a tool for the sustainability analysis of digital tools in university courses. SusAF is an established framework that enables exploring the different dimensions of sustainability. In this workshop, we will apply this framework to AI-based tools, such as ChatGPT and DALL-E. The goal is to present SusAF as a framework for sustainability analysis of software systems used in higher education and to explore, with the participants, the different sustainability challenges of using AI-based tools. In this full-day workshop, we want to engage an interdisciplinary group of researchers, lecturers, and practitioners in sustainability analysis and we will explore the relevance of SusAF in various educational settings. {\copyright} 2024 Copyright held by the owner/author(s).},
 year = {2024},
 title = {Sustainability analysis of AI-based tools in higher education},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206584554&doi=10.1145%2f3677045.3685461&partnerID=40&md5=414191aff8e78e1a7c88ab3c7ae5b12d},
 keywords = {Artificial intelligence;Design and development process;Digital tools;High educations;Higher Education;Holistic view;Learn+;Software-systems;Sustainability Analysis;Sustainability Awareness Framework;Sustainable development goals;University course;User-centric},
 publisher = {{Association for Computing Machinery}},
 editor = {Krogstie, J. and Krogstie, B. R. and {van der Velden}, M. and Gasparini, A. A. and Chasanidou, D.},
 doi = {10.1145/3677045.3685461}
}


@proceedings{Kretzer.2025,
 abstract = {Graphical user interfaces (GUIs) are at the heart of almost every software we encounter. GUIs are often created through a collaborative effort involving UX designers, product owners, and software developers, constantly facing changing requirements. Historically, problems in GUI development include a fragmented, poorly integrated tool landscape and high synchronization efforts between stakeholders. Recent approaches suggest using large language models (LLMs) to recognize requirements fulfillment in GUIs and automatically propose new GUI components. Based on ten interviews with practitioners, this paper proposes an LLM-based assistant as a Figma plug-in that bridges the gap between user stories and GUI prototyping. We evaluated the prototype with 40 users and 40 crowd-workers, showing that the effectiveness of GUI creation is improved by using LLMs to detect requirements' completion and generate new GUI components. We derive design rationales to support cross-functional integration in software development, ensuring that our plug-in integrates well into established processes. {\copyright} 2025 Copyright held by the owner/author(s).},
 year = {2025},
 title = {Closing the Loop between User Stories and GUI Prototypes: An LLM-Based Assistant for Cross-Functional Integration in Software Development},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005760101&doi=10.1145%2f3706598.3713932&partnerID=40&md5=361b9039f774e41212071b20a937e60f},
 keywords = {Assistance;Computer operating systems;Computer software selection and evaluation;Cross functional integration;Graphical user interface prototype;GUI Prototypes;Language model;Model-based OPC;Open source software;Plug-ins;Requirement;Requirements;Requirements engineering;Software design;Software packages;Software prototyping;User interface components;User interface prototypes;User Stories},
 publisher = {{Association for Computing Machinery}},
 editor = {Kretzer, F. and Kolthoff, K. and Bartelt, C. and Ponzetto, S. P. and Maedche, A.},
 doi = {10.1145/3706598.3713932}
}


@inproceedings{Krauss.,
 abstract = {The paper explores the opportunities and challenges for metaverse learning environments with AI-Assistants based on Large Language Models. A proof of concept based on popular but proprietary technologies is presented that enables a natural language exchange between the user and an AI-based medical expert in a highly immersive environment based on the Unreal Engine. The answers generated by ChatGPT are not only played back lip-synchronously, but also visualized in the VR environment using a 3D model of a skeleton. Usability and user experience play a particularly important role in the development of the highly immersive AI-Assistant. The proof of concept serves to illustrate the opportunities and challenges that lie in the merging of large language models, metaverse applications and educational ecosystems, which are self-contained research areas. Development strategies, tools and interoperability standards will be presented to facilitate future developments in this triangle of tension. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
 author = {Krauss, C. and Bassbouss, L. and Upravitelev, M. and An, T.-S. and Altun, D. and Reray, L. and Balitzki, E. and {El Tamimi}, T. and Karag{\"u}lle, M. and Sottilare, R. A. and Schwarz, J.},
 title = {Opportunities and Challenges in Developing Educational AI-Assistants for the Metaverse},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196214138&doi=10.1007%2f978-3-031-60609-0_16&partnerID=40&md5=9a66876cb30e9e5d287a86e6cfa66e05},
 keywords = {3D modeling;AI-assistant;AI-Assistants;Computational linguistics;Computer aided instruction;Concept-based;Education;E-learning;Interoperability;Language model;Large Language Model;Large language models;Learning environments;Learning systems;Learning Technologies;Learning technology;LLM;Metaverse;Metaverses;Natural language processing systems;Proof of concept;User interfaces;Virtual assistants;Virtual reality},
 pages = {219--238-219--238},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-60609-0{\textunderscore }16}
}


@proceedings{Khurana.2025,
 abstract = {Large Language Model (LLM)-based in-application assistants, or copilots, can automate software tasks, but users often prefer learning by doing, raising questions about the optimal level of automation for an effective user experience. We investigated two automation paradigms by designing and implementing a fully automated copilot (AutoCopilot) and a semi-automated copilot (GuidedCopilot) that automates trivial steps while offering step-by-step visual guidance. In a user study (N=20) across data analysis and visual design tasks, GuidedCopilot outperformed AutoCopilot in user control, software utility, and learnability, especially for exploratory and creative tasks, while AutoCopilot saved time for simpler visual tasks. A follow-up design exploration (N=10) enhanced GuidedCopilot with task-and state-aware features, including in-context preview clips and adaptive instructions. Our findings highlight the critical role of user control and tailored guidance in designing the next generation of copilots that enhance productivity, support diverse skill levels, and foster deeper software engagement. {\copyright} 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
 year = {2025},
 title = {Do It For Me vs. Do It With Me: Investigating User Perceptions of Different Paradigms of Automation in Copilots for Feature-Rich Software},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005740844&doi=10.1145%2f3706598.3713431&partnerID=40&md5=bca5e2f7a1c0c5282da1ba007cea7fd4},
 keywords = {Computer software selection and evaluation;Enterprise software;feature-rich software;High level languages;Human-AI Collaboration;Language model;Large Language Model;Large language models;Mobile applications;Model-based OPC;Search engines;semi-automation;Software copilot;software copilots;Software tasks;user control;User perceptions;Utility programs},
 publisher = {{Association for Computing Machinery}},
 editor = {Khurana, A. and Su, X. and Wang, A. Y. and Chilana, P. K.},
 doi = {10.1145/3706598.3713431}
}


@article{Kessel.2025,
 abstract = {Citizen science (CS) projects, which engage the general public in scientific research, often face challenges in ensuring high-quality data collection and maintaining user engagement. Recent advancements in Large Language Models (LLMs) present a promising solution by providing automated, real-time assistance to users, reducing the need for extensive human intervention, and offering instant support. The CS project Les Herbonautes, dedicated to mass digitization of the French National Herbarium, serves as a case study for this paper, which details the development and evaluation of a network of open source LLM agents to assist users during data collection. The research involved the review of related work, stakeholder meetings with the Mus{\'e}um National d'Histoire Naturelle, and user and context analyses to formalize system requirements. With these, a prototype with a user interface in the form of a chatbot was designed and implemented using LangGraph, and afterward evaluated through expert evaluation to assess its effect on usability and user experience (UX). The findings indicate that such a chatbot can enhance UX and improve data quality by guiding users and providing immediate feedback. However, limitations due to the non-deterministic nature of LLMs exist, suggesting that workflows must be carefully designed to mitigate potential errors and ensure reliable performance. {\copyright} 2025 by the authors.},
 author = {Kessel, A.-L. and Sahri, S. and Groppe, S. and Groppe, J. and Khorashadizadeh, H. and Pignal, M. and {Perez Pimpar{\'e}}, E. and Vignes-Lebbe, R.},
 year = {2025},
 title = {Impact of Chatbots on User Experience and Data Quality on Citizen Science Platforms},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216250466&doi=10.3390%2fcomputers14010021&partnerID=40&md5=6b8304e292c518199fc379ff02d2e8d3},
 keywords = {Chatbot;citizen science;data quality;Large Language Model (LLM);LLM application;user interface},
 volume = {14},
 number = {21},
 issn = {2073431X},
 journal = {Computers},
 doi = {10.3390/computers14010021}
}


@inproceedings{Kang.,
 abstract = {As software systems expand in complexity, managing the vast and varied collection of test cases becomes increasingly difficult with traditional manual testing methods. This paper presents a new approach for automating the generation of structured test cases, named Test Element Extraction and Restructuring (TEER), which leverages the advanced natural language processing capabilities of large language models (LLMs). Specifically targeting human-computer interaction (HCI) software, TEER employs prompt tuning techniques to extract critical elements from natural language test cases and systematically reassemble them into structured formats. The study evaluates the effectiveness of TEER by applying it to common test cases from desktop HCI applications. The experimental results demonstrate that this method successfully produces structured test cases that meet predefined requirements. {\copyright} 2024 IEEE.},
 author = {Kang, L. and Ai, J. and Lu, M.},
 title = {Automated Structural Test Case Generation for Human-Computer Interaction Software Based on Large Language Model},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216918617&doi=10.1109%2fDSA63982.2024.00027&partnerID=40&md5=29ebf94f26cd19c947bf696664f8aba2},
 keywords = {Application programs;Automatic test pattern generation;Computer interaction;Computer simulation languages;Computer software selection and evaluation;Element extraction;Language model;Large Language Model;LLM;Man machine systems;Modeling languages;Natural language processing systems;Natural languages;Software Test;Software testing;Structural tests;Structured tests;Test Case;Test elements},
 pages = {132--140-132--140},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/DSA63982.2024.00027}
}


@inproceedings{KailashVarma.,
 abstract = {The current college library system is hindered by inefficiencies in book searching, availability updates, identity verification, and checkout processes, resulting in delays and errors that negatively impact student experiences. This research paper presents an Al-based librarian system designed to address these challenges through automation and digital transformation. Leveraging a Large Language Model (LLM), the proposed system facilitates personalized interactions between students and library resources. Upon student verification, the AI librarian provides real-time information on book availability, location, and tailored recommendations, significantly reducing the time spent on manual searches. The streamlined checkout process allows for automated book issuance and instant confirmation notifications, minimizing human error and enhancing record- keeping. This innovative solution not only improves operational efficiency but also enriches the user experience by offering a user-friendly interface and timely assistance. Future enhancements, such as voice integration and mobile application support, are suggested to further modernize library services. This research underscores the potential of AI technologies to revolutionize library management and improve service delivery in academic settings. {\copyright} 2025 IEEE.},
 author = {{Kailash Varma}, N. M. and Aryan, A. and Dhanush, P. and Manikanta, R. and Chandhu, N. and Arora, G. D.},
 title = {Developing an AI-Based Library Assistant: Enhancing Book Retrieval with Natural Language Processing and Machine Learning},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002677633&doi=10.1109%2fCICTN64563.2025.10932399&partnerID=40&md5=7131a308b2665dcf9ff9954e577e65cf},
 keywords = {Al-based librarian;Efficiency;Information management;Language model;Language processing;Large Language Model;Large Language Model (LLM);library automation;Library management;library management system;Management systems;Natural language processing;Natural languages;Personalized recommendation;personalized recommendations;Records management;Search engines;student identification;Students},
 pages = {136--140-136--140},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/CICTN64563.2025.10932399}
}


@proceedings{JuarezRamirez.2024,
 abstract = {The proceedings contain 42 papers. The topics discussed include: systematic literature review of low-code and its future trends; a novel framework for ai-integrated electronic manifest generation; agile user-centered development of mobile applications: a systematic literature review; digital assistant to improve user experience on websites: innovative support and efficient communication strategies; cluster analysis in the identification of patterns in software development with agile methodologies: a systematic literature review; price and quote index prediction with deep learning; agile user-centered development of mobile applications: a systematic literature review; and transforming software development: a study on the integration of multi-agent systems and large language models for automatic code generation.},
 year = {2024},
 title = {Proceedings - 2024 12th International Conference in Software Engineering Research and Innovation, CONISOFT 2024},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216741409&partnerID=40&md5=2596d8d369279626fe1befd8c8c33347},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 editor = {Juarez-Ramirez, R. and {y Fernandez C.A.}, Fernandez and {Jimenez Calleros}, S. P. and Ramirez-Noriega, A. and Guerra-Garcia, C. A. and Sandoval, G. L. and Menendez-Ortiz, M. A. and Hernandez-Ocharan, J. O.}
}


@inproceedings{Joshi.,
 abstract = {Ensuring large language models' (LLMs) responses align with prompt instructions is crucial for application development. Based on our formative study with industry professionals, the alignment requires heavy human involvement and tedious trial-and-error especially when there are many instructions in the prompt. To address these challenges, we introduce CoPrompter, a framework that identifies misalignment based on assessing multiple LLM responses with criteria. It proposes a method to generate evaluation criteria questions derived directly from prompt requirements and an interface to turn these questions into a user-editable checklist. Our user study with industry prompt engineers shows that CoPrompter improves the ability to identify and refine instruction alignment with prompt requirements over traditional methods, helps them understand where and how frequently models fail to follow user's prompt requirements, and helps in clarifying their own requirements, giving them greater control over the response evaluation process. We also present the design lessons to underscore our system's potential to streamline the prompt engineering process. {\copyright} 2025 Copyright held by the owner/author(s).},
 author = {Joshi, I. and Shahid, S. and Venneti, S. M. and Vasu, M. and Zheng, Y. and Li, Y. and Krishnamurthy, B. and Chan, G. Y.-Y.},
 title = {CoPrompter: User-Centric Evaluation of LLM Instruction Alignment for Improved Prompt Engineering},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001919599&doi=10.1145%2f3708359.3712102&partnerID=40&md5=67365ab7c58c465450c5ee36728082ac},
 keywords = {Application development;HCI;Industry professionals;Language model;Large language model' evaluation;LLM Evaluation;Model evaluation;Model response;Optimisations;Prompt Optimization;Requirements engineering;Trial and error;User interfaces;User-centric evaluations},
 pages = {341--365-341--365},
 publisher = {{Association for Computing Machinery}},
 doi = {10.1145/3708359.3712102}
}


@inproceedings{Jiang.,
 abstract = {Large-scale cloud systems play a pivotal role in modern IT infrastructure. However, incidents occurring within these systems can lead to service disruptions and adversely affect user experience. To swiftly resolve such incidents, on-call engineers depend on crafting domain-specific language (DSL) queries to analyze telemetry data. However, writing these queries can be challenging and time-consuming. This paper presents a thorough empirical study on the utilization of queries of KQL, a DSL employed for incident management in a large-scale cloud management system at MICROSOFT. The findings obtained underscore the importance and viability of KQL queries recommendation to enhance incident management. Building upon these valuable insights, we introduce XPERT, an end-to-end machine learning framework that automates KQL recommendation process. By leveraging historical incident data and large language models, XPERT generates customized KQL queries tailored to new incidents. Furthermore, XPERT incorporates a novel performance metric called XCORE, enabling a thorough evaluation of query quality from three comprehensive perspectives. We conduct extensive evaluations of XPERT, demonstrating its effectiveness in offline settings. Notably, we deploy XPERT in the real production environment of a large-scale incident management system in MICROSOFT, validating its efficiency in supporting incident management. To the best of our knowledge, this paper represents the first empirical study of its kind, and XPERT stands as a pioneering DSL query recommendation framework designed for incident management. {\copyright} 2024 ACM.},
 author = {Jiang, Y. and Zhang, C. and He, S. and Yang, Z. and Ma, M. and Qin, S. and Kang, Y. and Dang, Y. and Rajmohan, S. and Lin, Q. and Zhang, D.},
 title = {XPERT: Empowering Incident Management with Query Recommendations via Large Language Models},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196785986&doi=10.1145%2f3597503.3639081&partnerID=40&md5=92fbb9462eefbde5ee641e637459173b},
 keywords = {Cloud systems;Computational linguistics;Digital subscriber lines;Domains specific languages;Empirical studies;Incident management;IT infrastructures;Language model;Large Language Model;Large-scales;Problem oriented languages;Quality control;Query Generation;Query recommendations;Recommender systems;User interfaces},
 pages = {1121--1133-1121--1133},
 publisher = {{IEEE Computer Society}},
 doi = {10.1145/3597503.3639081}
}


@inproceedings{Ito.,
 abstract = {Bidders often take a long time to read and understand tender documents because they require specialized knowledge, and tender documents are generally long. Bidders first overview the specific items, such as payment and warranty, in a tender document and then check the overall document. Therefore, the function that can extract specific items (i.e., item extractor) and the function that can highlight words or phrases related to specific items (i.e., word-phrase highlighter) are in great demand. To develop the above two types of functions, we need to solve two problems. The first problem is the problem related to the annotated data set. The second problem concerns the BERT NER-based prediction approach in a small training dataset setting. To solve the first problem, we created two types of sequence labeling datasets related to Item Extractor and Word-Phrase Highlighter. To solve the second problem, we propose the Information Extraction (IE) method, which combines (1) a supervised learning approach using Bidirectional Encoder Representations from Transformers (BERT) and (2) a large language model (LLM)-based improver. We then developed the web application system called Tender Document Analyzer (TDDA), which includes {\textquotedbl}Item Extractor{\textquotedbl} and {\textquotedbl}Word-Phrase Highlighter{\textquotedbl}. Experimental evaluation shows that our approach is practical. Firstly, the evaluation for extraction ability shows that the performance of our proposed method is much higher than the baseline approach that uses GPT 3.5, as well as demonstrates that the proposed LLM-based improver can improve the IE ability. In addition, the usability evaluation shows that bidders can solve the task in less time using our system. {\copyright} 2024 Copyright held by the owner/author(s).},
 author = {Ito, T. and Nakagawa, S.},
 title = {Tender Document Analyzer with the Combination of Supervised Learning and LLM-based Improver},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194497077&doi=10.1145%2f3589335.3651233&partnerID=40&md5=e7ebcc7137127650795bdbcd0e40bb41},
 keywords = {Data mining;Data set;Function evaluation;Language model;Model-based OPC;Petroleum reservoir evaluation;Sequence Labeling;Small training;Specialized knowledge;Supervised learning;support system;Support systems;tender document;Tender documents;text mining;Text-mining;Training dataset},
 pages = {995--998-995--998},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3589335.3651233}
}


@inproceedings{Iong.,
 abstract = {We introduce OpenWebAgent, an open toolkit designed to optimize web automation by integrating both large language models (LLMs) and large multimodal models (LMMs). This toolkit focuses on enhancing human-computer interactions on the web, simplifying complex tasks through an advanced HTML parser, a rapid action generation module, and an intuitive user interface. At the core of OpenWebAgent is an innovative web agent framework that uses a modular design to allow developers to seamlessly integrate a variety of models and tools to process web information and automate tasks on the web. This enables the development of powerful, task-oriented web agents, significantly enhancing user experience and operational efficiency on the web. The OpenWebAgent framework, Chrome plugin, and demo video are available at https://github.com/THUDM/OpenWebAgent/. {\copyright} 2024 Association for Computational Linguistics.},
 author = {Iong, I. L. and Liu, X. and Chen, Y. and Lai, H. and Yao, S. and Shen, P. and Yu, H. and Dong, Y. and Tang, J. and Cao, Y. and Feng, Y. and Xiong, D.},
 title = {OpenWebAgent: An Open Toolkit to Enable Web Agents on Large Language Models},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203808884&doi=10.18653%2fv1%2f2024.acl-demos.8&partnerID=40&md5=a2ccbc58538d94aef7a813ad416a8d7e},
 keywords = {Agent Framework;Chatbots;Complex task;Computational linguistics;Computer interaction;Computer simulation languages;HTML;HTML parsers;Intelligent agents;Intuitive user interface;Language model;Modular designs;Multimodal models;User interfaces;Web Agents;Web automation;Web browsers;Web Design},
 pages = {72--81-72--81},
 publisher = {{Association for Computational Linguistics (ACL)}},
 doi = {10.18653/v1/2024.acl-demos.8}
}


@inproceedings{Ilagan.,
 abstract = {Due to the emergence of natural language processing (NLP) interfaces, there has been growing intent to use conversational channels for commerce. Beyond customer service, NLP-enabled AI agents are being integrated into various steps of the order-to-cash (OTC) process. Social media and messaging platforms such as Facebook Messenger have become pivotal for businesses, especially during and after the COVID-19 pandemic, but adoption has been limited. In addition, attitudes towards fully-automated conversational agents (CA) have been mixed, and there is room for human involvement in transactional conversations. A distinguishing contribution of this research is leveraging the inherent capabilities of Large Language Models (LLMs) in handling multilingual conversations and extracting transactional details through named entity recognition (NER). The study describes a hybrid human-AI setup augmenting agents with an auto-agent leveraging LLMs' natural language understanding (NLU) capabilities, designed using the OTC process pattern applied to conversational UX frameworks. A prototype of the setup aims to streamline operations and reduce errors by enhancing the user experience during key OTC steps through improved conversational design. Recognizing the irreplaceable essence of human interaction, the hybrid human-in-the-loop approach was chosen, mitigating the impersonal nature of full automation. A prototype handling customers and humans augmented by LLMs for NER handling of transaction, customer, and product information was built. Sample synthetic bilingual conversations between customers and sales agents were generated using ChatGPT and fed into the system for evaluation. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
 author = {Ilagan, J. B. and Ilagan, J. R. and Zulueta, P. Y. and Rodrigo, M. M. and Degen, H. and Ntoa, S.},
 title = {Optimizing Conversational Commerce Involving Multilingual Consumers Through Large Language Models' Natural Language Understanding Abilities},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195474442&doi=10.1007%2f978-3-031-60615-1_4&partnerID=40&md5=07118c28a512264b485c935771f73a04},
 keywords = {Commerce;Computational linguistics;conversational commerce;Conversational user experience;Co-pilot;Co-pilots;Generative AI;Language model;Large Language Model;Large language models;Named entity recognition;Natural language processing systems;Natural language understanding;Natural languages;Sales;Social networking (online);User interfaces;Users' experiences},
 pages = {47--59-47--59},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-60615-1{\textunderscore }4}
}


@inproceedings{Huo.,
 abstract = {In the business automation world, APIs are everywhere. They provide access to enterprise tools such as customer relationship management solutions, or custom automations such as unattended RPA bots that automate repetitive tasks. Unfortunately, they may not be accessible to the business users who need them but are not equipped with the necessary technical skills to leverage them. Most recently, chatbots are becoming the go-to medium to make automation software accessible to business users. Since API specifications aren't written with a chatbot use in mind, additional work is needed to make APIs accessible through a natural language interface. Making this process scalable to many APIs requires an automated data training pipeline for intent recognition models, a crucial component within chatbots to understand natural language utterances from users. More accurate intent recognition models lead to better user experience and satisfaction. Prior work proposed approaches to extracting intents from OpenAPI specifications. However, the resulting models tend to be brittle due to weaknesses in training data. In this work, we propose a data augmentation approach based on paraphrasing using large language models and propose a system to generate sentences to train intent recognition models. Experimental results highlight the effectiveness of our approach. Our system is deployed in a real world setting. {\copyright} The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
 author = {Huo, S. and Mukherjee, K. and Bandlamudi, J. and Isahagian, V. and Muthusamy, V. and Rizk, Y. and K{\"o}pke, J. and L{\'o}pez-Pintado, O. and Plattfaut, R. and J.-R., Rehse and Gdowska, K. and Gonzalez-Lopez, F. and Munoz-Gama, J. and Smit, K. and {van der Werf J.M.E.M.}},
 title = {Accelerating the Support of Conversational Interfaces for RPAs Through APIs},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173586436&doi=10.1007%2f978-3-031-43433-4_11&partnerID=40&md5=d158f7da1fd079229b07528bae782071},
 keywords = {API Specification;API specifications;Application programming interfaces (API);Business-users;Chatbots;Computational linguistics;Conversational Assistant;Intent recognition;Language model;Natural language processing systems;Paraphrase Generation;Process Automation;Public relations;Recognition models;Robotic Process Automation;Robotics;Specifications},
 pages = {165--180-165--180},
 publisher = {{Springer Science and Business Media Deutschland GmbH}},
 doi = {10.1007/978-3-031-43433-4{\textunderscore }11}
}


@inproceedings{Hu.,
 abstract = {In industrial practice, many bugs in commercial mobile apps manifest as self-conflicts of data presented in the GUI (Graphical User Interface). Such data inconsistency bugs can bring confusion to the users and deteriorate user experiences. They are a major target of industrial testing practice. However, due to the complication and diversity of GUI implementation and data presentation (e.g., the ways to present the data in natural language), detecting data inconsistency bugs is a very challenging task. It still largely relies on manual efforts. To reduce such human efforts, we proposed AutoConsis, an automated data inconsistency testing tool we designed for Meituan. one of the largest E-commerce providers with over 600 million transacting users. AutoConsis can automatically analyze GUI pages via a multi-modal deep-learning model and extract target data from textual phrases leveraging LLMs (Large Language Models). With these extracted data, their inconsistencies can then be detected. We evaluate the design of AutoConsis via a set of ablation experiments. Moreover, we demonstrate the effectiveness of AutoConsis when applying it to real-world commercial mobile apps with eight representative cases. Copyright {\copyright} 2024 held by the owner/author(s).},
 author = {Hu, Y. and Jin, H. and Wang, X. and Gu, J. and Guo, S. and Chen, C. and Zhou, Y.},
 title = {AutoConsis: Automatic GUI-driven Data Inconsistency Detection of Mobile Apps},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195312035&doi=10.1145%2f3639477.3639748&partnerID=40&md5=601c04f3b87ed32c4b241a3a1ef067c4},
 keywords = {Automatic testing;Context learning;Data inconsistencies;Data mining;Deep Learning;functional bug;Graphical user interfaces;In contexts;Inconsistency detection;in-context learning;Industrial practices;Industrial testing;Mobile app;mobile apps;Natural language processing systems;Users' experiences},
 pages = {137--146-137--146},
 publisher = {{Association for Computing Machinery}},
 doi = {10.1145/3639477.3639748}
}


@article{Hsueh.2024,
 abstract = {The maturation of internet usage environments has elevated User Experience (UX) to a critical factor in system success. However, traditional manual UX testing methods are hampered by subjectivity and lack of standardization, resulting in time-consuming and costly processes. This study explores the potential of Large Language Models (LLMs) to address these challenges by developing an automated UX testing tool. Our innovative approach integrates the Rapi web recording tool to capture user interaction data with the analytical capabilities of LLMs, utilizing Nielsen's usability heuristics as evaluation criteria. This methodology aims to significantly reduce the initial costs associated with UX testing while maintaining assessment quality. To validate the tool's efficacy, we conducted a case study featuring a tennis-themed course reservation system. The system incorporated multiple scenarios per page, allowing users to perform tasks based on predefined goals. We employed our automated UX testing tool to evaluate screenshots and interaction logs from user sessions. Concurrently, we invited participants to test the system and complete UX questionnaires based on their experiences. Comparative analysis revealed that varying prompts in the automated UX testing tool yielded different outcomes, particularly in detecting interface elements. Notably, our tool demonstrated superior capability in identifying issues aligned with Nielsen's usability principles compared to participant evaluations. This research contributes to the field of UX evaluation by leveraging advanced language models and established usability heuristics. Our findings suggest that LLM-based automated UX testing tools can offer more consistent and comprehensive assessments. {\copyright} 2024 by the authors.},
 author = {Hsueh, N.-L. and Lin, H.-J. and Lai, L.-C.},
 year = {2024},
 title = {Applying Large Language Model to User Experience Testing},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212091038&doi=10.3390%2felectronics13234633&partnerID=40&md5=b7bcfbd456080ddfdbb2167843e50db3},
 keywords = {AI in software development;Human-computer Interaction (HCI)},
 volume = {13},
 number = {4633},
 issn = {20799292},
 journal = {Electronics (Switzerland)},
 doi = {10.3390/electronics13234633}
}


@inproceedings{Gunathilaka.,
 abstract = {Large Language Models (LLMs) have shown promise in various natural language processing tasks, but their effectiveness for app review classification to support software evolution remains unexplored. This study evaluates commercial and open-source LLMs for classifying mobile app reviews into bug reports, feature requests, user experiences, and ratings. We compare the zero-shot performance of GPT-3.5 and Gemini Pro 1.0, finding that GPT-3.5 achieves superior results with an F1 score of 0.849. We then use GPT-3.5 to autonomously annotate a dataset for fine-tuning smaller open-source models. Experiments with Llama 2 and Mistral show that instruction fine-tuning significantly improves performance, with results approaching commercial models. We investigate the trade-off between training data size and the number of epochs, demonstrating that comparable results can be achieved with smaller datasets and increased training iterations. Additionally, we explore the impact of different prompting strategies on model performance. Our work demonstrates the potential of LLMs to enhance app review analysis for software engineering while highlighting areas for further improvement in open-source alternatives. {\copyright} 2025 by SCITEPRESS - Science and Technology Publications, Lda.},
 author = {Gunathilaka, S. and Silva, N. and Rocha, A. P. and Steels, L. and {van den Herik H.J.}},
 title = {Automatic Analysis of App Reviews Using LLMs},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001692633&doi=10.5220%2f0013375600003890&partnerID=40&md5=cd54669e0220f69e2d298771177eaffb},
 keywords = {App Review Analysis;fine-tuning;GPT-3.5;Large language models;Mobile applications;Natural language processing;Open-Source Models;Review Classification;Software Evolution;Zero-Shot Learning},
 pages = {828--839-828--839},
 publisher = {{Science and Technology Publications, Lda}},
 doi = {10.5220/0013375600003890}
}


@proceedings{Goldi.2024,
 abstract = {Student peer review writing is prevalent and important in education for fostering critical thinking and learning motivation. However, it often entails challenges such as high effort and writer's block. Leaving students unsupported may thus diminish the efficacy of the process. Large Language Models (LLMs) offer a potential remedy, but their utility hinges on user-centered design. Guided by design-determining constructs from the Cognitive Process Theory of Writing, we developed an intelligent writing support tool to alleviate these challenges, aiding 1) ideation and 2) evaluation. A randomized experiment (n=120) confirmed users were less inclined to utilize the tool's intelligent features when offered pre-supplied ideas or evaluations, validating our approach. Moreover, students engaged not less but more with their writing if support was available, indicating an enhanced experience. Our research illuminates design choices for enhancing LLM-based tools' usability and user experience, specifically optimizing intelligent writing support tools to facilitate student peer review. {\copyright} 2024 Copyright held by the owner/author(s)},
 year = {2024},
 title = {Intelligent Support Engages Writers Through Relevant Cognitive Processes},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194891492&doi=10.1145%2f3613904.3642549&partnerID=40&md5=2b3065fb23c70a9be6ef6b4ded1c3fa1},
 keywords = {Artifact or System;Cognitive process;Cognitive systems;Creativity Support;Education computing;Education/Learning;Educational settings;Intelligent support;Language model;Peer review;School/educational setting;Schools/Educational Setting;Students;Support tool;User centered design;User interfaces},
 publisher = {{Association for Computing Machinery}},
 editor = {G{\"o}ldi, A. and Wambsganss, T. and Neshaei, S. P. and Rietsche, R.},
 doi = {10.1145/3613904.3642549}
}


@proceedings{Gao.2024,
 abstract = {With ChatGPT's release, conversational prompting has become the most popular form of human-LLM interaction. However, its effectiveness is limited for more complex tasks involving reasoning, creativity, and iteration. Through a systematic analysis of HCI papers published since 2021, we identified four key phases in the human-LLM interaction flow-planning, facilitating, iterating, and testing-to precisely understand the dynamics of this process. Additionally, we have developed a taxonomy of four primary interaction modes: Mode 1: Standard Prompting, Mode 2: User Interface, Mode 3: Context-based, and Mode 4: Agent Facilitator. This taxonomy was further enriched using the {\textquotedbl}5W1H{\textquotedbl} guideline method, which involved a detailed examination of definitions, participant roles (Who), the phases that happened (When), human objectives and LLM abilities (What), and the mechanics of each interaction mode (How). We anticipate this taxonomy will contribute to the future design and evaluation of human-LLM interaction. {\copyright} 2024 Association for Computing Machinery. All rights reserved.},
 year = {2024},
 title = {A Taxonomy for Human-LLM Interaction Modes: An Initial Exploration},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194143130&doi=10.1145%2f3613905.3650786&partnerID=40&md5=e6c6fa12035db195c92ced21ebb9456f},
 keywords = {Complex task;Flow planning;Flow testing;Human engineering;Human-LLM Interaction;Initial exploration;Interaction modes;Interface mode;Iterative methods;Language model;Large Language Model;Large language models;Systematic analysis;Taxonomies;Taxonomy;User interfaces},
 publisher = {{Association for Computing Machinery}},
 editor = {Gao, J. and Gebreegziabher, S. A. and Choo, K. T. W. and Li, T. J.-J. and Perrault, S. T. and Malone, T. W.},
 doi = {10.1145/3613905.3650786}
}


@inproceedings{Fontana.,
 abstract = {Intent-based networking has attracted interest in the academic research for enhancing network management operations with user-oriented features. One of the main challenge in this field is the acquisition of the user intents and subsequently the relative translation into policies for the automatic management of the network. Concerning this task, the primary technique employed is relying on Graphical User Interfaces (GUI)s. In addition, the use of Natural Language Processing techniques has been extensively adopted for improved user experience. Recently, some preliminary studies have shown that using Large Language Models (LLMs) for this purpose leads to achieve interesting results. However, based on a comprehensive analysis of the state of the art, it has emerged that the works utilizing the LLMs do not fully exploit all the capabilities these tools could potentially offer. For this reason, the doctoral work aims to address the following challenges: enhancing user experience through the utilization of intelligent chatbots, improving the correct understanding of user intents and ensuring the translation of user intentions into a coherent set of network configurations, which are generated automatically. {\copyright} 2024 IEEE.},
 author = {Fontana, M. and Martini, B. and Sciarrone, F.},
 title = {Exploring Large Language Models in Intent Acquisition and Translation},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199554368&doi=10.1109%2fNetSoft60951.2024.10588924&partnerID=40&md5=44f172f8c0b8b2c47353994679fb394e},
 keywords = {Academic research;Automatic management;Computational linguistics;Graphical user interfaces;Language model;Language processing techniques;Management operation;Natural language processing systems;Natural languages;Networks management;Oriented features;Translation (languages);User oriented;Users' experiences},
 pages = {231--234-231--234},
 publisher = {{Institute of Electrical and Electronics Engineers Inc}},
 doi = {10.1109/NetSoft60951.2024.10588924}
}


@article{Florindi.2024,
 abstract = {In today's business landscape, Chatbots play a pivotal role in innovation and process optimization. In this paper, we introduced a novel advanced Emotional Chatbot AI, introducing sentiment analysis for human chatbot conversations. Adding an emotional component within the human-computer interaction, can in fact dramatically improve the quality of the final conversation between Chatbots and humans. More specifically, in our paper, we provided a practical evaluation of the EmoROBERTA software, introducing it into a novel implementation of an Emotional Chatbot. The pipeline we present is novel, and we developed it within a business context in which the use of sentimental and emotional responses can act in a significant and fundamental way toward the final success and use of the Chatbot itself. The architecture enriches user experience with real-time updates on the topic of interest, maintaining a user-centric design, toward an affective-response enhancement of the interaction established between the Chatbot and the user. The source code is fully available on GitHub: https://github.com/filippoflorindi/F-One. {\copyright} The Author(s) 2024.},
 author = {Florindi, F. and Fedele, P. and Dimitri, G. M.},
 year = {2024},
 title = {A novel solution for the development of a sentimental analysis chatbot integrating ChatGPT},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197273605&doi=10.1007%2fs00779-024-01824-6&partnerID=40&md5=28636645f019297a8ea72ecc7003bab5},
 keywords = {Business contexts;Chatbots;Emotion recognition;Emotional response;Human computer interaction;Implementation;Novel solutions;Optimization;Process optimisation;Real-time updates;Sentiment analysis;User interfaces;Users' experiences},
 pages = {947--960-947--960},
 volume = {28},
 number = {6},
 issn = {16174909},
 journal = {Personal and Ubiquitous Computing},
 doi = {10.1007/s00779-024-01824-6}
}


@inproceedings{Fischer.,
 abstract = {NodeGrade tries to provide a suitable solution for the problem of time-intensive short answer grading. This research focuses simultaneously on performance, functionality and user experience, which is underlined by a triangulated approach. The evaluation results show comparable performance of NodeGrade on public datasets, even outperforming GPT-4 on the SemEval 2013 Task 7. Matching of NodeGrade's output with multiple human expert raters reveals some weaknesses regarding cases at the lower and upper boundary. In terms of user experience, the interviewed and observed students recognized both positive facets, like better learning support and helpful feedback, and negative sides, including technical limitations and lack of transparency. Overall, NodeGrade promises high potential for further practical use and testing in the field of software engineering education and automatic short answer grading. {\copyright} 2025 Copyright held by the owner/author(s).},
 author = {Fischer, D. V. and Haug, J. and Schoppel, P. and Abke, J. and Becker, M. and Hagel, G.},
 title = {Evaluation of a Node-based Automatic Short Answer Tool ``NodeGrade''},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008422181&doi=10.1145%2f3723010.3723021&partnerID=40&md5=390800fa65e519dd72c307c7d1370ecf},
 keywords = {AI In Education;Artificial intelligence;ASAG;Automatic Short Answer Grading;Automatic testing;Education computing;Engineering education;Grading;Language model;Language processing;Large Language Model;Large language models;Natural language processing;Natural language processing systems;Natural languages;Short Answer Scoring;Software Engineering Education;Software testing;User experience;User interfaces},
 pages = {20--29-20--29},
 publisher = {{Association for Computing Machinery, Inc}},
 doi = {10.1145/3723010.3723021}
}


@inproceedings{Donato.,
 abstract = {The integration of AI into software development is transforming coding practices, with tools like GitHub Copilot marking the beginning of AI-assisted development. However, the interaction between developers and AI assistants is not yet well understood, presenting both opportunities and challenges. This PhD thesis addresses three core objectives: (1) improving the effectiveness of developer-AI interactions, (2) redefining development practices to incorporate AI as an essential collaborator, and (3) exploring collaborative dynamics within mixed teams of developers and AI agents. The aim is to establish methodologies that can boost productivity and software quality, paving the way for seamless human-AI collaboration in development. {\copyright} 2025 IEEE.},
 author = {Donato, B.},
 title = {Rethinking Software Development Considering Collaboration with AI Assistants},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498477&doi=10.1109%2fICSE-Companion66252.2025.00045&partnerID=40&md5=e358399ebbc93af95250861f44b1c716},
 keywords = {AI assistant;AI Assistants;Artificial intelligence;Computer programming;Computer software selection and evaluation;Development practices;Groupware;HCI;LLM;LLMs;PhD thesis;Software design;Software quality},
 pages = {154--156-154--156},
 publisher = {{IEEE Computer Society}},
 doi = {10.1109/ICSE-Companion66252.2025.00045}
}


@inproceedings{Lambert.,
 abstract = {In design research there is a deep interest in how designers solve complex problems using design methods and heuristic shortcuts and in particular how this might relate to Machine Language (ML) to simulate the design process. With the introduction of Large Language Model (LLMs) such as Chat GPT we can appreciate how software with the remarkable capability of Generative AI (Gen AI) and generative design can be used to assist designers in the three-dimensional design of their products. In this paper, we will focus on how AI will impact designing in computing, identify what is relevant and suggest a new development opportunity. Our interest is in examining the potential for better and novel software solutions, making them easier to use during the design synthesis process and capable of adjustment throughout the 3D CAD development stage. The specific problem we aim to resolve is how to optimise a designer's time spent from concept to production using Gen AI {\&} 3D CAD software without affecting the quality of design thinking, methodology and practical process. Gen AI as an evolving platform has the potential to create a design to production productivity shift that industry and academic groups have long predicted. Designing will remain creative and inventive, individualistic or team based and using what we have termed an AI design assistant, AIDA. {\copyright} 2024 Proceedings of the 26th International Conference on Engineering and Product Design Education: Rise of the Machines: Design Education in the Generative AI Era, E and PDE 2024. All rights reserved.},
 author = {Lambert, S. and Mathews, C. and Jaddoa, A. and Bohemia, E. and Buck, L. and Grierson, H. and Kim, J. and Storer, I. and Whitehead, T.},
 title = {CONCEPT TO PRODUCTION WITH A GEN AI DESIGN ASSISTANT: AIDA},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003908119&doi=10.35199%2fepde.2024.40&partnerID=40&md5=81df8bb901d7d2182c2dfeed199c308b},
 keywords = {3D CAD;3-d cads;Artificial intelligence;Artificial Intelligence (AI);Computer aided logic design;Computer interaction;Computer software selection and evaluation;Curricula;design automation;Design automations;Design for manufacturability;engineering design;generative design;High level synthesis;Human computer interaction;human computer interaction (HCI);Integrated circuit layout;Intellectual property core;Language model;Large Language Model;Large language models (LLMs);Machine design;Machine language;machine language (ML);Machine languages;Printed circuit design;Process design;Product design;Software design},
 pages = {235--240-235--240},
 publisher = {{The Design Society}},
 doi = {10.35199/epde.2024.40}
}


@misc{Zhou.2025,
 abstract = {Cross-site scripting attacks represent one of the major security threats facing web applications, with Stored XSS attacks becoming the predominant form. Compared to reflected XSS, stored XSS attack payloads exhibit temporal and spatial asynchrony between injection and execution, rendering traditional browserside defenses based on request-response differential analysis ineffective. This paper presents XSShield, the first detection framework that leverages a Large Language Model to understand JavaScript semantics to defend against Stored XSS attacks. Through a Prompt Optimizer based on gradient descent and UCB-R selection algorithms, and a Data Adaptor based on program dependence graphs, the framework achieves real-time and fine-grained code processing. Experimental evaluation shows that XSShield achieves 93{\%} accuracy and an F1 score of 0.9266 on the GPT-4 model, improving accuracy by an average of 88.8{\%} compared to existing solutions. The processing time, excluding model communication overhead, averages only 0.205 s, demonstrating practical deployability without significantly impacting user experience. {\copyright} 2025 by the authors.},
 author = {Zhou, Y. and Wang, E. and Yang, W. and Ge, W. and Yang, S. and Zhang, Y. and Qu, W. and Xie, W.},
 year = {2025},
 title = {XSShield: Defending Against Stored XSS Attacks Using LLM-Based Semantic Understanding},
 url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000837418&doi=10.3390%2fapp15063348&partnerID=40&md5=e3d108cac2208e0bea7766301e2ebaf0},
 keywords = {Asynchrony;Computer software selection and evaluation;Cross Site Scripting Attacks;Java programming language;LLM;Network security;prompt learning;Security threats;Semantics;Semantics understanding;stored XSS;Temporal and spatial;Web application;Web Applications},
 volume = {15},
 number = {3348},
 publisher = {{Multidisciplinary Digital Publishing Institute (MDPI)}},
 journal = {Applied Sciences (Switzerland)},
 doi = {10.3390/app15063348}
}


